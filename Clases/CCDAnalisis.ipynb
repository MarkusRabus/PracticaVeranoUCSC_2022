{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd6e76-85ed-47f1-a955-942302c3fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis de datos de un CCD\n",
    "\n",
    "Una imagen astronómica es un array de 2 dimensiones, un píxel es un elemento del array. En un mundo ideal, el valor de cada píxel es directamente proporcional a la cantidad de luz que cayó sobre el píxel durante el.\n",
    "\n",
    "El número almacenado en una imagen astronómica en crudo denominamos unidad digital analógica (Analog Digitla Unit, ADU) o \"counts\". El número de fotones (o equivalentes, electrones) que llegan al píxel está relacionado con los \"counts\" en el píxel a traves del factor de la ganancia \"gain\".\n",
    "\n",
    "Otros contribuciones que aumenta los \"counts\", pero no estan relacionados con la luz son:\n",
    "- **BIAS** Hay pequeñas variaciones en los valor del bias a lo largo del chip, y puede haber pequeñas variaciones en el nivel del bias con el tiempo.\n",
    "- **Dark current** (Corriente oscuro) Causado en un píxel debido al movimiento térmico de los electrones en el CCD; la refrigeración de un CCD reduce, aunque no elimina del todo. La corriente oscuro depende en gran medida de la temperatura.\n",
    "- **Read noise** (ruide de lectura) Causado un un píxel debido a la lecture. No se puede eliminar, pero reducir.\n",
    "- **Flat** La sensidividad de la CCD varia a lo largo de la CCD causado por viñeteo en las escinas, particulas de polvo en los elementos opticos, cada pixel tiene su propio sensitividad, pixeles muertos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd870f-d5ee-47b9-88a9-d566671b16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pylab as plt\n",
    "from astropy.visualization import ImageNormalize\n",
    "from astropy.visualization import simple_norm, MinMaxInterval, PercentileInterval, ZScaleInterval\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56468eb-2854-4d31-83cc-a1dccba108fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.figsize\"] = (15, 7)\n",
    "rcParams[\"font.size\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479cb1b-88b1-4bab-addb-9a9e3990c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/home/mrabus/LCO_data/M55_LCO/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e635e30-727c-4b43-8fac-ef4ccdbb5fc7",
   "metadata": {},
   "source": [
    "## Imagenes de bias\n",
    "\n",
    "Las imagenes de bias se toma con la CCD totalmente tapada sin luz ilumina la ccd y con un tiempo de exposicion 0s o sea simplemente leer la ccd instantanea. Ahora vamos a ver un ejemplo de un imagen de bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db9af2-6eaa-4dd8-920b-2a1af1acdf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_name = \"tfn0m414-kb95-20211231-0301-b00.fits.fz\"\n",
    "\n",
    "bias_hdu = fits.open( os.path.join(datapath,bias_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255b0c6-b3e0-461e-ae1d-4f4947a90404",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeda66c-b863-4bc7-adc2-fb1243b1abf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_hdu[1].header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59336f4b-d281-415f-89c6-1148ee482dac",
   "metadata": {},
   "source": [
    "En vez de imprimir todo el header, podemos eligir solo la informacion que nos importa. Queremos verificar si se trata de una imagen de bias. Usamos el descriptor \"Header keyword\" `OBSTYPE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9670b8-9ea0-4035-a5b9-df645f755323",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bias_hdu[1].header[\"OBSTYPE\"])\n",
    "print(bias_hdu[1].header[\"EXPTIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe2fa3-30ce-4078-ac58-4ffa60b49db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_image = bias_hdu[1].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bffb6c-29bf-49cf-9015-527309570612",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ZScaleInterval()\n",
    "norm = ImageNormalize(bias_image, interval=ZScaleInterval())\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot = ax.imshow(bias_image, cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a68c6-cbdc-4d45-960b-84b1fd7fb562",
   "metadata": {},
   "source": [
    "## Imagenes de dark\n",
    "\n",
    "Las imagenes de bias se toma con la CCD totalmente tapada sin luz ilumina la ccd. Con la diferencia respeto al bias el dark tiene un tiempo de exposisicion diferente a 0, similar a la tiempo de exposicion. Ahora vamos a ver un ejemplo de un imagen de dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880e576-910c-4f04-a61d-521340801104",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_name = \"tfn0m414-kb95-20211231-0318-d00.fits.fz\"\n",
    "dark_hdu = fits.open( os.path.join(datapath, dark_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a8771-e62f-44e9-a127-0c93488b8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dark_hdu[1].header[\"OBSTYPE\"])\n",
    "print(dark_hdu[1].header[\"EXPTIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa8d0b-9909-4c05-bf3f-3ba90268a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_image = dark_hdu[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a24089-fb8e-4945-bc31-5ea181086609",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ZScaleInterval()\n",
    "norm = ImageNormalize(dark_image, interval=ZScaleInterval())\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot = ax.imshow(dark_image, cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4c0e0-bcc5-4621-a887-7cec5e664e3b",
   "metadata": {},
   "source": [
    "## Imagenes de flat\n",
    "\n",
    "Las imagenes de bias se toma observando una superficie uniforme iluminado por ejemplo el cielo durante el dia o una pantalla blanco illuminado con una luz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f077b37-7a47-41ad-a6a2-427e5b3b4440",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_name = \"tfn0m414-kb95-20220101-0033-f00.fits.fz\"\n",
    "flat_hdu = fits.open( os.path.join(datapath, flat_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a627d-bc96-4203-8551-2ffea385902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flat_hdu[1].header[\"OBSTYPE\"])\n",
    "print(flat_hdu[1].header[\"FILTER\"])\n",
    "print(flat_hdu[1].header[\"EXPTIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fce7b2-de17-4496-be23-5dbd0ca966cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_image = flat_hdu[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7ccb8-fa84-4eb9-bf77-c319430b590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ZScaleInterval()\n",
    "norm = ImageNormalize(flat_image, interval=ZScaleInterval())\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot = ax.imshow(flat_image, cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07096d4e-722c-4a55-b1d7-7dbb8d30e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_name = \"tfn0m414-kb95-20211230-0305-f00.fits.fz\"\n",
    "flat_hdu = fits.open( os.path.join(datapath, flat_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007b3eb-928c-4463-ac55-7b23e360afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flat_hdu[1].header[\"OBSTYPE\"])\n",
    "print(flat_hdu[1].header[\"FILTER\"])\n",
    "print(flat_hdu[1].header[\"EXPTIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e2968-3a79-481e-96a3-6a5a270ebc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_image = flat_hdu[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f447c97-cbf9-45f9-9ea5-1dd8a4440ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ZScaleInterval()\n",
    "norm = ImageNormalize(flat_image, interval=ZScaleInterval())\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot = ax.imshow(flat_image, cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1804cf6e-9cfe-4802-aac4-7319ca184bfe",
   "metadata": {},
   "source": [
    "Las imagenes de bias, dark y flat llamamos generalmente imgenes de calibracion. Las usamos en un primer paso para mejorar nuestra imagen de ciencia. La imagen de ciencia es nuestro objeto que observamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc22fc-5af0-483e-9063-45c3e5b7c730",
   "metadata": {},
   "source": [
    "## Imagenes de ciencia\n",
    "\n",
    "Las imagenes de ciencia contiene nuestro objeto de interes. A las imagenes de ciencia aplicamos los imagenes de calibracion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7bbd8e-89ff-41a4-8455-319c62bf4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_name = \"tfn0m414-kb95-20211231-0227-e00.fits.fz\"\n",
    "science_hdu = fits.open( os.path.join(datapath, science_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf100d-ae65-4067-8687-2eca5d6f0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(science_hdu[1].header[\"OBSTYPE\"])\n",
    "print(science_hdu[1].header[\"FILTER\"])\n",
    "print(science_hdu[1].header[\"EXPTIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cd3d9-07f1-4f5a-ab94-642640e3e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_image = science_hdu[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2ed7e-dd29-475c-a476-c7bfacf3e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ZScaleInterval()\n",
    "norm = ImageNormalize(science_image, interval=ZScaleInterval())\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot = ax.imshow(science_image, cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd642b3d-d8b0-45e0-8c34-cda44ff55cd9",
   "metadata": {},
   "source": [
    "Ejercicio: Un programa que cuente los imagenes de cada uno (bias, dark, flat, ciencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161303d-0291-489d-8cce-0c355bcfd9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_name = \"tfn0m414-kb95-20211231-0227-e00.fits.fz\"\n",
    "science_hdu = fits.open( os.path.join(datapath, science_name) )\n",
    "science_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f154c-2d82-442b-adab-ecdc0b1fd544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "TodosImagenes = glob.glob( os.path.join(datapath, '*.fz') )\n",
    "\n",
    "for imagen in TodosImagenes:\n",
    "    cabecera = fits.getheader( imagen, ext=1 )\n",
    "    print(cabecera['OBSTYPE'], cabecera['FILTER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eaa445-c750-4dbe-b87d-832f0bef770f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TodosImagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe831b3-d09b-43e9-b725-378266db7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "\n",
    "listaBias = []\n",
    "listaDark = []\n",
    "listaCiencia_V = []\n",
    "listaCiencia_rp = []\n",
    "listaCiencia_B = []\n",
    "listaFlat_V = []\n",
    "listaFlat_rp = []\n",
    "listaFlat_B = []\n",
    "\n",
    "TodosImagenes = glob.glob( os.path.join(datapath, '*.fz') )\n",
    "\n",
    "for imagen in TodosImagenes:\n",
    "    cabecera = fits.getheader( imagen, ext=1 )\n",
    "    \n",
    "    if cabecera['OBSTYPE'] == 'BIAS':\n",
    "        listaBias.append(imagen)\n",
    "        \n",
    "    elif cabecera['OBSTYPE'] == 'DARK':\n",
    "        listaDark.append(imagen)\n",
    "        \n",
    "    elif cabecera['OBSTYPE'] == 'SKYFLAT':\n",
    "        if cabecera['FILTER'] == 'V':\n",
    "            listaFlat_V.append(imagen)\n",
    "        elif cabecera['FILTER'] == 'rp':\n",
    "            listaFlat_rp.append(imagen)\n",
    "        elif cabecera['FILTER'] == 'B':\n",
    "            listaFlat_B.append(imagen)\n",
    "        \n",
    "    elif cabecera['OBSTYPE'] == 'EXPOSE':\n",
    "        if cabecera['FILTER'] == 'V': \n",
    "            listaCiencia_V.append(imagen)\n",
    "        elif cabecera['FILTER'] == 'rp':\n",
    "            listaCiencia_rp.append(imagen)\n",
    "        elif cabecera['FILTER'] == 'B':\n",
    "            listaCiencia_B.append(imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169c1bc-2729-4427-8663-687acd714e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390ead5-80c2-41b4-9b5d-50fee0527dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f09af-0b21-4fe1-b6d4-b92fe6cf6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen1 = fits.open(listaBias[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b45c21-342e-49c1-b0c8-cca173dffc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f09555-29c5-4470-9cf6-d6a45d361b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datosimagen1 = fits.getdata(listaBias[0], ext=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e57d9b-f90f-4c5c-bdb4-85250cbd3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "datosimagen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686531af-2aa1-4cfb-ba4d-c249bd71caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ef14d-910b-4b23-9e6d-ff2186fc7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tarea stack de imagenes de cada grupo de imagens, por ejemplot un stack de bias, un stack de dark, ...\n",
    "# combinar los 17 bias en una imagen, para combinar usar el promedio y median, los mismo con los darks, los flats (NO se combina la ciencia!!!)\n",
    "# Resultando archivo un master (masterbias, masterdark, masterflat_V,....)\n",
    "# Operacion: (Ciencia_V - masterbias)/masterflat_V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006af14-6737-423d-a182-3a37c704dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8909a1f-5fb0-49d0-94c4-f9c68d7491bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_array = np.zeros( ( len(listaBias), bias_image.shape[0], bias_image.shape[1]  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8fe5f-b00f-4243-aaaf-b50c0b7936ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967125f2-aba6-4f2a-8b4b-81d9cd95f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af1d75-7ea9-4737-a39c-17dd0fb1ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nr_bias, file_bias in enumerate(listaBias):\n",
    "    #print(nr_bias, file_bias)\n",
    "    bias_array[nr_bias, :, :] = fits.getdata(file_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eca931-f4e3-4911-b426-3fec0e9103d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60f244-30e3-430e-a333-523fd1459462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist( bias_array.ravel(), 500, [950,1100] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f48ac-3e71-43f3-b7dc-559b68d199f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Promedio: %5.2f,    Mediano: %5.2f,  Deviacion Estandard: %5.2f' \\\n",
    "      %( np.mean(bias_array.ravel()), np.median(bias_array.ravel()), np.std(bias_array.ravel()) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88897d72-74ba-48a7-be9d-61cf9afa47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterBias_promedio = np.mean( bias_array, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79e616-0e9b-4162-9c69-9d7771f3be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterBias_promedio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2ebb8-0aa9-469a-bac4-88e5bffcf3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterBias_mediano = np.median( bias_array, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aae06-22cb-47f9-8302-0ebf03806a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterBias_devest = np.std( bias_array, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe246ab0-7d1b-4e75-af40-9396378826ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_imagen_promedio = ImageNormalize( masterBias_promedio, interval = ZScaleInterval() )\n",
    "norm_imagen_devest = ImageNormalize( masterBias_devest, interval = ZScaleInterval() )\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(1,2,1)\n",
    "plt.imshow( masterBias_promedio, cmap='gray', origin='lower', norm=norm_imagen_promedio )\n",
    "plt.colorbar()\n",
    "f.add_subplot(1,2,2)\n",
    "plt.imshow( masterBias_devest, cmap='gray', origin='lower', norm=norm_imagen_devest )\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd722734-b0ed-42d1-99b0-5e6fbab136bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_rp_array = np.zeros( ( len(listaFlat_rp), flat_image.shape[0], flat_image.shape[1]  ) )\n",
    "for nr_flat, file_flat in enumerate(listaFlat_rp):\n",
    "    #print(nr_bias, file_bias)\n",
    "    flat_rp_array[nr_flat, :, :] = fits.getdata(file_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ee448-818b-4ee8-8d4d-f8cf613a9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Promedio: %5.2f,    Mediano: %5.2f,  Deviacion Estandard: %5.2f' \\\n",
    "      %( np.mean(flat_rp_array.ravel()), np.median(flat_rp_array.ravel()), np.std(flat_rp_array.ravel()) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb2679-a2e9-495c-8292-9298bdfddc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist( flat_rp_array.ravel(), 500, [15000,25000] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d74b97-2aac-46b3-a7ea-a7e201e9227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterFlat_promedio = np.mean( flat_rp_array, axis=0 )\n",
    "masterFlat_mediano = np.median( flat_rp_array, axis=0 )\n",
    "masterFlat_devest = np.std( flat_rp_array, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169f1bc-41cb-47f3-b4dc-82d0932c746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar el master flat para sus valores estan alrededor de 1\n",
    "\n",
    "valor_promedio_flat = np.mean(masterFlat_promedio.ravel())\n",
    "masterFlat_normalizado = masterFlat_promedio/valor_promedio_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38481ad-108a-4045-8234-846f3cd37aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_masterflat = ImageNormalize( masterFlat_promedio, interval = ZScaleInterval() )\n",
    "norm_masterflat_normalizado = ImageNormalize( masterFlat_normalizado, interval = ZScaleInterval() )\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(1,2,1)\n",
    "plt.imshow( masterFlat_promedio, cmap='gray', origin='lower', norm=norm_masterflat )\n",
    "plt.colorbar()\n",
    "f.add_subplot(1,2,2)\n",
    "plt.imshow( masterFlat_normalizado, cmap='gray', origin='lower', norm=norm_masterflat_normalizado )\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874cc90-1229-4cc6-9156-77e2fba8419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibardo_ciencia = (science_image - masterBias_promedio)/masterFlat_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883db43c-ee69-4c87-b0e8-02d5372ee7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_imagen_antes = ImageNormalize( science_image, interval = ZScaleInterval() )\n",
    "norm_imagen_despues = ImageNormalize( calibardo_ciencia, interval = ZScaleInterval() )\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(1,2,1)\n",
    "plt.title('Sin calibracion')\n",
    "plt.imshow( science_image[750:1000,1500:2000], cmap='gray', origin='lower', norm=norm_imagen_antes )\n",
    "plt.colorbar()\n",
    "f.add_subplot(1,2,2)\n",
    "plt.title('Con calibracion')\n",
    "plt.imshow( calibardo_ciencia[750:1000,1500:2000], cmap='gray', origin='lower', norm=norm_imagen_despues )\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc35918-dfd9-4cc3-a491-f118a25e6e30",
   "metadata": {},
   "source": [
    "## Tareas: \n",
    "\n",
    "- Entender la diferencia entre promedio, mediano, modo y deviacion estandard\n",
    "- Entender que es un histograma\n",
    "- hacer el tutorial en un notebook aparte: http://www.astropy.org/ccd-reduction-and-photometry-guide/v/dev/notebooks/00-00-Preface.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5c974-b8a1-4a50-8ae4-8575c6d53349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
