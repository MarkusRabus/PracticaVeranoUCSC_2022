{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f411137-5a22-44be-8fd2-5ec8a2f814b7",
   "metadata": {},
   "source": [
    "# Introduccion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e5b55-d5ca-4ffd-a7bd-158bd1222582",
   "metadata": {},
   "source": [
    "Primer paso para trabajar con imagenes es importar los paquetes que usamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc24e937-2c8d-4875-a951-3b104896622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#paquete que nos permite trabjar en el sistema operativo con archivos y carpetas, crear un path, ...\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "# paquete que nos permite plotear\n",
    "\n",
    "from astropy.io import fits \n",
    "# permite leer los fits files, formate del archivo donde estan guardados los imagenes.\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d86966-5062-4af3-8e3d-77fbb69a3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros para plotear:\n",
    "\n",
    "from matplotlib import rcParams\n",
    "#rcParams[\"savefig.dpi\"] = 300\n",
    "#rcParams[\"figure.dpi\"] = 300\n",
    "rcParams[\"figure.figsize\"] = (15, 7)\n",
    "rcParams[\"font.size\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a0a9ba-e7c4-4be6-80ea-f33a2b0d8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el valor de este variable !!!\n",
    "datapath = '/home/mrabus/DECam_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c160b440-d017-4716-907f-e097b384e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# el nombre de la imagen que queremos leer.\n",
    "fitsimage = 'c4d_210418_025650_ori.fits.fz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803d053-0912-409f-a90d-092df76ac5c4",
   "metadata": {},
   "source": [
    "Si queremos obtener informacion sobre un paquete existe una funcion muy util."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94b60d2-845b-426c-96e2-052ebda66426",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package astropy.io.fits in astropy.io:\n",
      "\n",
      "NAME\n",
      "    astropy.io.fits\n",
      "\n",
      "DESCRIPTION\n",
      "    A package for reading and writing FITS files and manipulating their\n",
      "    contents.\n",
      "    \n",
      "    A module for reading and writing Flexible Image Transport System\n",
      "    (FITS) files.  This file format was endorsed by the International\n",
      "    Astronomical Union in 1999 and mandated by NASA as the standard format\n",
      "    for storing high energy astrophysics data.  For details of the FITS\n",
      "    standard, see the NASA/Science Office of Standards and Technology\n",
      "    publication, NOST 100-2.0.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _utils\n",
      "    card\n",
      "    column\n",
      "    compression\n",
      "    connect\n",
      "    convenience\n",
      "    diff\n",
      "    file\n",
      "    fitsrec\n",
      "    fitstime\n",
      "    hdu (package)\n",
      "    header\n",
      "    scripts (package)\n",
      "    setup_package\n",
      "    tests (package)\n",
      "    util\n",
      "    verify\n",
      "\n",
      "CLASSES\n",
      "    astropy.config.configuration.ConfigNamespace(builtins.object)\n",
      "        Conf\n",
      "    astropy.io.fits.hdu.base.ExtensionHDU(astropy.io.fits.hdu.base._ValidHDU)\n",
      "        astropy.io.fits.hdu.image.ImageHDU(astropy.io.fits.hdu.image._ImageBaseHDU, astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "    astropy.io.fits.hdu.base.NonstandardExtHDU(astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "        astropy.io.fits.hdu.nonstandard.FitsHDU\n",
      "    astropy.io.fits.hdu.image._ImageBaseHDU(astropy.io.fits.hdu.base._ValidHDU)\n",
      "        astropy.io.fits.hdu.image.ImageHDU(astropy.io.fits.hdu.image._ImageBaseHDU, astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "        astropy.io.fits.hdu.image.PrimaryHDU\n",
      "            astropy.io.fits.hdu.groups.GroupsHDU(astropy.io.fits.hdu.image.PrimaryHDU, astropy.io.fits.hdu.table._TableLikeHDU)\n",
      "    astropy.io.fits.hdu.table._TableBaseHDU(astropy.io.fits.hdu.base.ExtensionHDU, astropy.io.fits.hdu.table._TableLikeHDU)\n",
      "        astropy.io.fits.hdu.table.BinTableHDU\n",
      "            astropy.io.fits.hdu.compressed.CompImageHDU\n",
      "        astropy.io.fits.hdu.table.TableHDU\n",
      "    astropy.io.fits.util.NotifierMixin(builtins.object)\n",
      "        astropy.io.fits.column.ColDefs\n",
      "        astropy.io.fits.column.Column\n",
      "    astropy.io.fits.verify._Verify(builtins.object)\n",
      "        astropy.io.fits.card.Card\n",
      "        astropy.io.fits.hdu.hdulist.HDUList(builtins.list, astropy.io.fits.verify._Verify)\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        astropy.io.fits.verify.VerifyError\n",
      "    builtins.list(builtins.object)\n",
      "        astropy.io.fits.hdu.hdulist.HDUList(builtins.list, astropy.io.fits.verify._Verify)\n",
      "    builtins.object\n",
      "        astropy.io.fits.card.Undefined\n",
      "        astropy.io.fits.column.Delayed\n",
      "        astropy.io.fits.fitsrec.FITS_record\n",
      "            astropy.io.fits.hdu.groups.Group\n",
      "        astropy.io.fits.hdu.image.Section\n",
      "        astropy.io.fits.hdu.streaming.StreamingHDU\n",
      "        astropy.io.fits.header.Header\n",
      "    numpy.recarray(numpy.ndarray)\n",
      "        astropy.io.fits.fitsrec.FITS_rec\n",
      "            astropy.io.fits.hdu.groups.GroupData\n",
      "    \n",
      "    class BinTableHDU(_TableBaseHDU)\n",
      "     |  BinTableHDU(data=None, header=None, name=None, uint=False, ver=None, character_as_bytes=False)\n",
      "     |  \n",
      "     |  Binary table HDU class.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : array, `FITS_rec`, or `~astropy.table.Table`\n",
      "     |      Data to be used.\n",
      "     |  header : `Header`\n",
      "     |      Header to be used.\n",
      "     |  name : str\n",
      "     |      Name to be populated in ``EXTNAME`` keyword.\n",
      "     |  uint : bool, optional\n",
      "     |      Set to `True` if the table contains unsigned integer columns.\n",
      "     |  ver : int > 0 or None, optional\n",
      "     |      The ver of the HDU, will be the value of the keyword ``EXTVER``.\n",
      "     |      If not given or None, it defaults to the value of the ``EXTVER``\n",
      "     |      card of the ``header`` or 1.\n",
      "     |      (default: None)\n",
      "     |  character_as_bytes : bool\n",
      "     |      Whether to return bytes for string columns. By default this is `False`\n",
      "     |      and (unicode) strings are returned, but this does not respect memory\n",
      "     |      mapping and loads the whole column in memory when accessed.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BinTableHDU\n",
      "     |      _TableBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      _TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, uint=False, ver=None, character_as_bytes=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  dump(self, datafile=None, cdfile=None, hfile=None, overwrite=False)\n",
      "     |      Dump the table HDU to a file in ASCII format.  The table may be dumped\n",
      "     |      in three separate files, one containing column definitions, one\n",
      "     |      containing header parameters, and one for table data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : path-like or file-like, optional\n",
      "     |          Output data file.  The default is the root name of the\n",
      "     |          fits file associated with this HDU appended with the\n",
      "     |          extension ``.txt``.\n",
      "     |      \n",
      "     |      cdfile : path-like or file-like, optional\n",
      "     |          Output column definitions file.  The default is `None`, no\n",
      "     |          column definitions output is produced.\n",
      "     |      \n",
      "     |      hfile : path-like or file-like, optional\n",
      "     |          Output header parameters file.  The default is `None`,\n",
      "     |          no header parameters output is produced.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` if ``False`` and the output file exists. Default is\n",
      "     |          ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `dump` method is to allow viewing and editing\n",
      "     |      the table data and parameters in a standard text editor.\n",
      "     |      The `load` method can be used to create a new table from the three\n",
      "     |      plain text (ASCII) files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  load(datafile, cdfile=None, hfile=None, replace=False, header=None) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Create a table from the input ASCII files.  The input is from up to\n",
      "     |      three separate files, one containing column definitions, one containing\n",
      "     |      header parameters, and one containing column data.\n",
      "     |      \n",
      "     |      The column definition and header parameters files are not required.\n",
      "     |      When absent the column definitions and/or header parameters are taken\n",
      "     |      from the header object given in the header argument; otherwise sensible\n",
      "     |      defaults are inferred (though this mode is not recommended).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : path-like or file-like\n",
      "     |          Input data file containing the table data in ASCII format.\n",
      "     |      \n",
      "     |      cdfile : path-like or file-like, optional\n",
      "     |          Input column definition file containing the names,\n",
      "     |          formats, display formats, physical units, multidimensional\n",
      "     |          array dimensions, undefined values, scale factors, and\n",
      "     |          offsets associated with the columns in the table.  If\n",
      "     |          `None`, the column definitions are taken from the current\n",
      "     |          values in this object.\n",
      "     |      \n",
      "     |      hfile : path-like or file-like, optional\n",
      "     |          Input parameter definition file containing the header\n",
      "     |          parameter definitions to be associated with the table.  If\n",
      "     |          `None`, the header parameter definitions are taken from\n",
      "     |          the current values in this objects header.\n",
      "     |      \n",
      "     |      replace : bool, optional\n",
      "     |          When `True`, indicates that the entire header should be\n",
      "     |          replaced with the contents of the ASCII file instead of\n",
      "     |          just updating the current header.\n",
      "     |      \n",
      "     |      header : `~astropy.io.fits.Header`, optional\n",
      "     |          When the cdfile and hfile are missing, use this Header object in\n",
      "     |          the creation of the new table and HDU.  Otherwise this Header\n",
      "     |          supersedes the keywords from hfile, which is only used to update\n",
      "     |          values not present in this Header, unless ``replace=True`` in which\n",
      "     |          this Header's values are completely replaced with the values from\n",
      "     |          hfile.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `load` method is to allow the input of ASCII\n",
      "     |      data that was edited in a standard text editor of the table data and\n",
      "     |      parameters.  The `dump` method can be used to create the initial ASCII\n",
      "     |      files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      This is an abstract type that implements the shared functionality of\n",
      "     |      the ASCII and Binary Table HDU types, which should be used instead of\n",
      "     |      this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the table HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  update(self)\n",
      "     |      Update header keywords to reflect recent changes of columns.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from _TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, character_as_bytes=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs` -like\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      character_as_bytes : bool\n",
      "     |          Whether to return bytes for string columns when accessed from the\n",
      "     |          HDU. By default this is `False` and (unicode) strings are returned,\n",
      "     |          but for large tables this may use up a lot of memory.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self)\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self)\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file-like\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Card(astropy.io.fits.verify._Verify)\n",
      "     |  Card(keyword=None, value=None, comment=None, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Card\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |  \n",
      "     |  __init__(self, keyword=None, value=None, comment=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromstring(image) from builtins.type\n",
      "     |      Construct a `Card` object from a (raw) string. It will pad the string\n",
      "     |      if it is not the length of a card image (80 columns).  If the card\n",
      "     |      image is longer than 80 columns, assume it contains ``CONTINUE``\n",
      "     |      card(s).\n",
      "     |  \n",
      "     |  normalize_keyword(keyword) from builtins.type\n",
      "     |      `classmethod` to convert a keyword value that may contain a\n",
      "     |      field-specifier to uppercase.  The effect is to raise the key to\n",
      "     |      uppercase and leave the field specifier in its original case.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : or str\n",
      "     |          A keyword value or a ``keyword.field-specifier`` value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  image\n",
      "     |      The card \"image\", that is, the 80 byte character string that represents\n",
      "     |      this card in an actual FITS header.\n",
      "     |  \n",
      "     |  is_blank\n",
      "     |      `True` if the card is completely blank--that is, it has no keyword,\n",
      "     |      value, or comment.  It appears in the header as 80 spaces.\n",
      "     |      \n",
      "     |      Returns `False` otherwise.\n",
      "     |  \n",
      "     |  rawkeyword\n",
      "     |      On record-valued keyword cards this is the name of the standard <= 8\n",
      "     |      character FITS keyword that this RVKC is stored in.  Otherwise it is\n",
      "     |      the card's normal keyword.\n",
      "     |  \n",
      "     |  rawvalue\n",
      "     |      On record-valued keyword cards this is the raw string value in\n",
      "     |      the ``<field-specifier>: <value>`` format stored in the card in order\n",
      "     |      to represent a RVKC.  Otherwise it is the card's normal value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  comment\n",
      "     |      Get the comment attribute from the card image if not already set.\n",
      "     |  \n",
      "     |  field_specifier\n",
      "     |      The field-specifier of record-valued keyword cards; always `None` on\n",
      "     |      normal cards.\n",
      "     |  \n",
      "     |  keyword\n",
      "     |      Returns the keyword name parsed from the card image.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value associated with the keyword stored in this card.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  length = 80\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ColDefs(astropy.io.fits.util.NotifierMixin)\n",
      "     |  ColDefs(input, ascii=False)\n",
      "     |  \n",
      "     |  Column definitions class.\n",
      "     |  \n",
      "     |  It has attributes corresponding to the `Column` attributes\n",
      "     |  (e.g. `ColDefs` has the attribute ``names`` while `Column`\n",
      "     |  has ``name``). Each attribute in `ColDefs` is a list of\n",
      "     |  corresponding attribute values from all `Column` objects.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ColDefs\n",
      "     |      astropy.io.fits.util.NotifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other, option='left')\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |      Automatically returns the values for the given keyword attribute for\n",
      "     |      all `Column`s in this list.\n",
      "     |      \n",
      "     |      Implements for example self.units, self.formats, etc.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |  \n",
      "     |  __init__(self, input, ascii=False)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      input : sequence of `Column` or `ColDefs` or ndarray or `~numpy.recarray`\n",
      "     |          An existing table HDU, an existing `ColDefs`, or any multi-field\n",
      "     |          Numpy array or `numpy.recarray`.\n",
      "     |      \n",
      "     |      ascii : bool\n",
      "     |          Use True to ensure that ASCII table columns are used.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |  \n",
      "     |  add_col(self, column)\n",
      "     |      Append one `Column` to the column definition.\n",
      "     |  \n",
      "     |  change_attrib(self, col_name, attrib, new_value)\n",
      "     |      Change an attribute (in the ``KEYWORD_ATTRIBUTES`` list) of a `Column`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str or int\n",
      "     |          The column name or index to change\n",
      "     |      \n",
      "     |      attrib : str\n",
      "     |          The attribute name\n",
      "     |      \n",
      "     |      new_value : object\n",
      "     |          The new value for the attribute\n",
      "     |  \n",
      "     |  change_name(self, col_name, new_name)\n",
      "     |      Change a `Column`'s name.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str\n",
      "     |          The current name of the column\n",
      "     |      \n",
      "     |      new_name : str\n",
      "     |          The new name of the column\n",
      "     |  \n",
      "     |  change_unit(self, col_name, new_unit)\n",
      "     |      Change a `Column`'s unit.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str or int\n",
      "     |          The column name or index\n",
      "     |      \n",
      "     |      new_unit : str\n",
      "     |          The new unit for the column\n",
      "     |  \n",
      "     |  del_col(self, col_name)\n",
      "     |      Delete (the definition of) one `Column`.\n",
      "     |      \n",
      "     |      col_name : str or int\n",
      "     |          The column's name or index\n",
      "     |  \n",
      "     |  info(self, attrib='all', output=None)\n",
      "     |      Get attribute(s) information of the column definition.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attrib : str\n",
      "     |          Can be one or more of the attributes listed in\n",
      "     |          ``astropy.io.fits.column.KEYWORD_ATTRIBUTES``.  The default is\n",
      "     |          ``\"all\"`` which will print out all attributes.  It forgives plurals\n",
      "     |          and blanks.  If there are two or more attribute names, they must be\n",
      "     |          separated by comma(s).\n",
      "     |      \n",
      "     |      output : file-like, optional\n",
      "     |          File-like object to output to.  Outputs to stdout by default.\n",
      "     |          If `False`, returns the attributes as a `dict` instead.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This function doesn't return anything by default; it just prints to\n",
      "     |      stdout.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, input, ascii=False)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  formats\n",
      "     |  \n",
      "     |  names\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Exclude listeners when saving the listener's state, since they may be\n",
      "     |      ephemeral.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Column(astropy.io.fits.util.NotifierMixin)\n",
      "     |  Column(name=None, format=None, unit=None, null=None, bscale=None, bzero=None, disp=None, start=None, dim=None, array=None, ascii=None, coord_type=None, coord_unit=None, coord_ref_point=None, coord_ref_value=None, coord_inc=None, time_ref_pos=None)\n",
      "     |  \n",
      "     |  Class which contains the definition of one column, e.g.  ``ttype``,\n",
      "     |  ``tform``, etc. and the array containing values for the column.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Column\n",
      "     |      astropy.io.fits.util.NotifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Two columns are equal if their name and format are the same.  Other\n",
      "     |      attributes aren't taken into account at this time.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Like __eq__, the hash of a column should be based on the unique column\n",
      "     |      name and format, and be case-insensitive with respect to the column\n",
      "     |      name.\n",
      "     |  \n",
      "     |  __init__(self, name=None, format=None, unit=None, null=None, bscale=None, bzero=None, disp=None, start=None, dim=None, array=None, ascii=None, coord_type=None, coord_unit=None, coord_ref_point=None, coord_ref_value=None, coord_inc=None, time_ref_pos=None)\n",
      "     |      Construct a `Column` by specifying attributes.  All attributes\n",
      "     |      except ``format`` can be optional; see :ref:`column_creation` and\n",
      "     |      :ref:`creating_ascii_table` for more information regarding\n",
      "     |      ``TFORM`` keyword.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : str, optional\n",
      "     |          column name, corresponding to ``TTYPE`` keyword\n",
      "     |      \n",
      "     |      format : str\n",
      "     |          column format, corresponding to ``TFORM`` keyword\n",
      "     |      \n",
      "     |      unit : str, optional\n",
      "     |          column unit, corresponding to ``TUNIT`` keyword\n",
      "     |      \n",
      "     |      null : str, optional\n",
      "     |          null value, corresponding to ``TNULL`` keyword\n",
      "     |      \n",
      "     |      bscale : int-like, optional\n",
      "     |          bscale value, corresponding to ``TSCAL`` keyword\n",
      "     |      \n",
      "     |      bzero : int-like, optional\n",
      "     |          bzero value, corresponding to ``TZERO`` keyword\n",
      "     |      \n",
      "     |      disp : str, optional\n",
      "     |          display format, corresponding to ``TDISP`` keyword\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |          column starting position (ASCII table only), corresponding\n",
      "     |          to ``TBCOL`` keyword\n",
      "     |      \n",
      "     |      dim : str, optional\n",
      "     |          column dimension corresponding to ``TDIM`` keyword\n",
      "     |      \n",
      "     |      array : iterable, optional\n",
      "     |          a `list`, `numpy.ndarray` (or other iterable that can be used to\n",
      "     |          initialize an ndarray) providing initial data for this column.\n",
      "     |          The array will be automatically converted, if possible, to the data\n",
      "     |          format of the column.  In the case were non-trivial ``bscale``\n",
      "     |          and/or ``bzero`` arguments are given, the values in the array must\n",
      "     |          be the *physical* values--that is, the values of column as if the\n",
      "     |          scaling has already been applied (the array stored on the column\n",
      "     |          object will then be converted back to its storage values).\n",
      "     |      \n",
      "     |      ascii : bool, optional\n",
      "     |          set `True` if this describes a column for an ASCII table; this\n",
      "     |          may be required to disambiguate the column format\n",
      "     |      \n",
      "     |      coord_type : str, optional\n",
      "     |          coordinate/axis type corresponding to ``TCTYP`` keyword\n",
      "     |      \n",
      "     |      coord_unit : str, optional\n",
      "     |          coordinate/axis unit corresponding to ``TCUNI`` keyword\n",
      "     |      \n",
      "     |      coord_ref_point : int-like, optional\n",
      "     |          pixel coordinate of the reference point corresponding to ``TCRPX``\n",
      "     |          keyword\n",
      "     |      \n",
      "     |      coord_ref_value : int-like, optional\n",
      "     |          coordinate value at reference point corresponding to ``TCRVL``\n",
      "     |          keyword\n",
      "     |      \n",
      "     |      coord_inc : int-like, optional\n",
      "     |          coordinate increment at reference point corresponding to ``TCDLT``\n",
      "     |          keyword\n",
      "     |      \n",
      "     |      time_ref_pos : str, optional\n",
      "     |          reference position for a time coordinate column corresponding to\n",
      "     |          ``TRPOS`` keyword\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Return a copy of this `Column`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  ascii\n",
      "     |      Whether this `Column` represents a column in an ASCII table.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  array\n",
      "     |      The Numpy `~numpy.ndarray` associated with this `Column`.\n",
      "     |      \n",
      "     |      If the column was instantiated with an array passed to the ``array``\n",
      "     |      argument, this will return that array.  However, if the column is\n",
      "     |      later added to a table, such as via `BinTableHDU.from_columns` as\n",
      "     |      is typically the case, this attribute will be updated to reference\n",
      "     |      the associated field in the table, which may no longer be the same\n",
      "     |      array.\n",
      "     |  \n",
      "     |  bscale\n",
      "     |  \n",
      "     |  bzero\n",
      "     |  \n",
      "     |  coord_inc\n",
      "     |  \n",
      "     |  coord_ref_point\n",
      "     |  \n",
      "     |  coord_ref_value\n",
      "     |  \n",
      "     |  coord_type\n",
      "     |  \n",
      "     |  coord_unit\n",
      "     |  \n",
      "     |  dim\n",
      "     |  \n",
      "     |  disp\n",
      "     |  \n",
      "     |  format\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  null\n",
      "     |  \n",
      "     |  start\n",
      "     |  \n",
      "     |  time_ref_pos\n",
      "     |  \n",
      "     |  unit\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Exclude listeners when saving the listener's state, since they may be\n",
      "     |      ephemeral.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class CompImageHDU(astropy.io.fits.hdu.table.BinTableHDU)\n",
      "     |  CompImageHDU(data=None, header=None, name=None, compression_type='RICE_1', tile_size=None, hcomp_scale=0, hcomp_smooth=0, quantize_level=16.0, quantize_method=-1, dither_seed=0, do_not_scale_image_data=False, uint=False, scale_back=False, **kwargs)\n",
      "     |  \n",
      "     |  Compressed Image HDU class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CompImageHDU\n",
      "     |      astropy.io.fits.hdu.table.BinTableHDU\n",
      "     |      astropy.io.fits.hdu.table._TableBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      astropy.io.fits.hdu.table._TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, compression_type='RICE_1', tile_size=None, hcomp_scale=0, hcomp_smooth=0, quantize_level=16.0, quantize_method=-1, dither_seed=0, do_not_scale_image_data=False, uint=False, scale_back=False, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array, optional\n",
      "     |          Uncompressed image data\n",
      "     |      \n",
      "     |      header : `~astropy.io.fits.Header`, optional\n",
      "     |          Header to be associated with the image; when reading the HDU from a\n",
      "     |          file (data=DELAYED), the header read from the file\n",
      "     |      \n",
      "     |      name : str, optional\n",
      "     |          The ``EXTNAME`` value; if this value is `None`, then the name from\n",
      "     |          the input image header will be used; if there is no name in the\n",
      "     |          input image header then the default name ``COMPRESSED_IMAGE`` is\n",
      "     |          used.\n",
      "     |      \n",
      "     |      compression_type : str, optional\n",
      "     |          Compression algorithm: one of\n",
      "     |          ``'RICE_1'``, ``'RICE_ONE'``, ``'PLIO_1'``, ``'GZIP_1'``,\n",
      "     |          ``'GZIP_2'``, ``'HCOMPRESS_1'``\n",
      "     |      \n",
      "     |      tile_size : int, optional\n",
      "     |          Compression tile sizes.  Default treats each row of image as a\n",
      "     |          tile.\n",
      "     |      \n",
      "     |      hcomp_scale : float, optional\n",
      "     |          HCOMPRESS scale parameter\n",
      "     |      \n",
      "     |      hcomp_smooth : float, optional\n",
      "     |          HCOMPRESS smooth parameter\n",
      "     |      \n",
      "     |      quantize_level : float, optional\n",
      "     |          Floating point quantization level; see note below\n",
      "     |      \n",
      "     |      quantize_method : int, optional\n",
      "     |          Floating point quantization dithering method; can be either\n",
      "     |          ``NO_DITHER`` (-1; default), ``SUBTRACTIVE_DITHER_1`` (1), or\n",
      "     |          ``SUBTRACTIVE_DITHER_2`` (2); see note below\n",
      "     |      \n",
      "     |      dither_seed : int, optional\n",
      "     |          Random seed to use for dithering; can be either an integer in the\n",
      "     |          range 1 to 1000 (inclusive), ``DITHER_SEED_CLOCK`` (0; default), or\n",
      "     |          ``DITHER_SEED_CHECKSUM`` (-1); see note below\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The astropy.io.fits package supports 2 methods of image compression:\n",
      "     |      \n",
      "     |          1) The entire FITS file may be externally compressed with the gzip\n",
      "     |             or pkzip utility programs, producing a ``*.gz`` or ``*.zip``\n",
      "     |             file, respectively.  When reading compressed files of this type,\n",
      "     |             Astropy first uncompresses the entire file into a temporary file\n",
      "     |             before performing the requested read operations.  The\n",
      "     |             astropy.io.fits package does not support writing to these types\n",
      "     |             of compressed files.  This type of compression is supported in\n",
      "     |             the ``_File`` class, not in the `CompImageHDU` class.  The file\n",
      "     |             compression type is recognized by the ``.gz`` or ``.zip`` file\n",
      "     |             name extension.\n",
      "     |      \n",
      "     |          2) The `CompImageHDU` class supports the FITS tiled image\n",
      "     |             compression convention in which the image is subdivided into a\n",
      "     |             grid of rectangular tiles, and each tile of pixels is\n",
      "     |             individually compressed.  The details of this FITS compression\n",
      "     |             convention are described at the `FITS Support Office web site\n",
      "     |             <https://fits.gsfc.nasa.gov/registry/tilecompression.html>`_.\n",
      "     |             Basically, the compressed image tiles are stored in rows of a\n",
      "     |             variable length array column in a FITS binary table.  The\n",
      "     |             astropy.io.fits recognizes that this binary table extension\n",
      "     |             contains an image and treats it as if it were an image\n",
      "     |             extension.  Under this tile-compression format, FITS header\n",
      "     |             keywords remain uncompressed.  At this time, Astropy does not\n",
      "     |             support the ability to extract and uncompress sections of the\n",
      "     |             image without having to uncompress the entire image.\n",
      "     |      \n",
      "     |      The astropy.io.fits package supports 3 general-purpose compression\n",
      "     |      algorithms plus one other special-purpose compression technique that is\n",
      "     |      designed for data masks with positive integer pixel values.  The 3\n",
      "     |      general purpose algorithms are GZIP, Rice, and HCOMPRESS, and the\n",
      "     |      special-purpose technique is the IRAF pixel list compression technique\n",
      "     |      (PLIO).  The ``compression_type`` parameter defines the compression\n",
      "     |      algorithm to be used.\n",
      "     |      \n",
      "     |      The FITS image can be subdivided into any desired rectangular grid of\n",
      "     |      compression tiles.  With the GZIP, Rice, and PLIO algorithms, the\n",
      "     |      default is to take each row of the image as a tile.  The HCOMPRESS\n",
      "     |      algorithm is inherently 2-dimensional in nature, so the default in this\n",
      "     |      case is to take 16 rows of the image per tile.  In most cases, it makes\n",
      "     |      little difference what tiling pattern is used, so the default tiles are\n",
      "     |      usually adequate.  In the case of very small images, it could be more\n",
      "     |      efficient to compress the whole image as a single tile.  Note that the\n",
      "     |      image dimensions are not required to be an integer multiple of the tile\n",
      "     |      dimensions; if not, then the tiles at the edges of the image will be\n",
      "     |      smaller than the other tiles.  The ``tile_size`` parameter may be\n",
      "     |      provided as a list of tile sizes, one for each dimension in the image.\n",
      "     |      For example a ``tile_size`` value of ``[100,100]`` would divide a 300 X\n",
      "     |      300 image into 9 100 X 100 tiles.\n",
      "     |      \n",
      "     |      The 4 supported image compression algorithms are all 'lossless' when\n",
      "     |      applied to integer FITS images; the pixel values are preserved exactly\n",
      "     |      with no loss of information during the compression and uncompression\n",
      "     |      process.  In addition, the HCOMPRESS algorithm supports a 'lossy'\n",
      "     |      compression mode that will produce larger amount of image compression.\n",
      "     |      This is achieved by specifying a non-zero value for the ``hcomp_scale``\n",
      "     |      parameter.  Since the amount of compression that is achieved depends\n",
      "     |      directly on the RMS noise in the image, it is usually more convenient\n",
      "     |      to specify the ``hcomp_scale`` factor relative to the RMS noise.\n",
      "     |      Setting ``hcomp_scale = 2.5`` means use a scale factor that is 2.5\n",
      "     |      times the calculated RMS noise in the image tile.  In some cases it may\n",
      "     |      be desirable to specify the exact scaling to be used, instead of\n",
      "     |      specifying it relative to the calculated noise value.  This may be done\n",
      "     |      by specifying the negative of the desired scale value (typically in the\n",
      "     |      range -2 to -100).\n",
      "     |      \n",
      "     |      Very high compression factors (of 100 or more) can be achieved by using\n",
      "     |      large ``hcomp_scale`` values, however, this can produce undesirable\n",
      "     |      'blocky' artifacts in the compressed image.  A variation of the\n",
      "     |      HCOMPRESS algorithm (called HSCOMPRESS) can be used in this case to\n",
      "     |      apply a small amount of smoothing of the image when it is uncompressed\n",
      "     |      to help cover up these artifacts.  This smoothing is purely cosmetic\n",
      "     |      and does not cause any significant change to the image pixel values.\n",
      "     |      Setting the ``hcomp_smooth`` parameter to 1 will engage the smoothing\n",
      "     |      algorithm.\n",
      "     |      \n",
      "     |      Floating point FITS images (which have ``BITPIX`` = -32 or -64) usually\n",
      "     |      contain too much 'noise' in the least significant bits of the mantissa\n",
      "     |      of the pixel values to be effectively compressed with any lossless\n",
      "     |      algorithm.  Consequently, floating point images are first quantized\n",
      "     |      into scaled integer pixel values (and thus throwing away much of the\n",
      "     |      noise) before being compressed with the specified algorithm (either\n",
      "     |      GZIP, RICE, or HCOMPRESS).  This technique produces much higher\n",
      "     |      compression factors than simply using the GZIP utility to externally\n",
      "     |      compress the whole FITS file, but it also means that the original\n",
      "     |      floating point value pixel values are not exactly preserved.  When done\n",
      "     |      properly, this integer scaling technique will only discard the\n",
      "     |      insignificant noise while still preserving all the real information in\n",
      "     |      the image.  The amount of precision that is retained in the pixel\n",
      "     |      values is controlled by the ``quantize_level`` parameter.  Larger\n",
      "     |      values will result in compressed images whose pixels more closely match\n",
      "     |      the floating point pixel values, but at the same time the amount of\n",
      "     |      compression that is achieved will be reduced.  Users should experiment\n",
      "     |      with different values for this parameter to determine the optimal value\n",
      "     |      that preserves all the useful information in the image, without\n",
      "     |      needlessly preserving all the 'noise' which will hurt the compression\n",
      "     |      efficiency.\n",
      "     |      \n",
      "     |      The default value for the ``quantize_level`` scale factor is 16, which\n",
      "     |      means that scaled integer pixel values will be quantized such that the\n",
      "     |      difference between adjacent integer values will be 1/16th of the noise\n",
      "     |      level in the image background.  An optimized algorithm is used to\n",
      "     |      accurately estimate the noise in the image.  As an example, if the RMS\n",
      "     |      noise in the background pixels of an image = 32.0, then the spacing\n",
      "     |      between adjacent scaled integer pixel values will equal 2.0 by default.\n",
      "     |      Note that the RMS noise is independently calculated for each tile of\n",
      "     |      the image, so the resulting integer scaling factor may fluctuate\n",
      "     |      slightly for each tile.  In some cases, it may be desirable to specify\n",
      "     |      the exact quantization level to be used, instead of specifying it\n",
      "     |      relative to the calculated noise value.  This may be done by specifying\n",
      "     |      the negative of desired quantization level for the value of\n",
      "     |      ``quantize_level``.  In the previous example, one could specify\n",
      "     |      ``quantize_level = -2.0`` so that the quantized integer levels differ\n",
      "     |      by 2.0.  Larger negative values for ``quantize_level`` means that the\n",
      "     |      levels are more coarsely-spaced, and will produce higher compression\n",
      "     |      factors.\n",
      "     |      \n",
      "     |      The quantization algorithm can also apply one of two random dithering\n",
      "     |      methods in order to reduce bias in the measured intensity of background\n",
      "     |      regions.  The default method, specified with the constant\n",
      "     |      ``SUBTRACTIVE_DITHER_1`` adds dithering to the zero-point of the\n",
      "     |      quantization array itself rather than adding noise to the actual image.\n",
      "     |      The random noise is added on a pixel-by-pixel basis, so in order\n",
      "     |      restore each pixel from its integer value to its floating point value\n",
      "     |      it is necessary to replay the same sequence of random numbers for each\n",
      "     |      pixel (see below).  The other method, ``SUBTRACTIVE_DITHER_2``, is\n",
      "     |      exactly like the first except that before dithering any pixel with a\n",
      "     |      floating point value of ``0.0`` is replaced with the special integer\n",
      "     |      value ``-2147483647``.  When the image is uncompressed, pixels with\n",
      "     |      this value are restored back to ``0.0`` exactly.  Finally, a value of\n",
      "     |      ``NO_DITHER`` disables dithering entirely.\n",
      "     |      \n",
      "     |      As mentioned above, when using the subtractive dithering algorithm it\n",
      "     |      is necessary to be able to generate a (pseudo-)random sequence of noise\n",
      "     |      for each pixel, and replay that same sequence upon decompressing.  To\n",
      "     |      facilitate this, a random seed between 1 and 10000 (inclusive) is used\n",
      "     |      to seed a random number generator, and that seed is stored in the\n",
      "     |      ``ZDITHER0`` keyword in the header of the compressed HDU.  In order to\n",
      "     |      use that seed to generate the same sequence of random numbers the same\n",
      "     |      random number generator must be used at compression and decompression\n",
      "     |      time; for that reason the tiled image convention provides an\n",
      "     |      implementation of a very simple pseudo-random number generator.  The\n",
      "     |      seed itself can be provided in one of three ways, controllable by the\n",
      "     |      ``dither_seed`` argument:  It may be specified manually, or it may be\n",
      "     |      generated arbitrarily based on the system's clock\n",
      "     |      (``DITHER_SEED_CLOCK``) or based on a checksum of the pixels in the\n",
      "     |      image's first tile (``DITHER_SEED_CHECKSUM``).  The clock-based method\n",
      "     |      is the default, and is sufficient to ensure that the value is\n",
      "     |      reasonably \"arbitrary\" and that the same seed is unlikely to be\n",
      "     |      generated sequentially.  The checksum method, on the other hand,\n",
      "     |      ensures that the same seed is used every time for a specific image.\n",
      "     |      This is particularly useful for software testing as it ensures that the\n",
      "     |      same image will always use the same seed.\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=1, bzero=0)\n",
      "     |      Scale image data by using ``BSCALE`` and ``BZERO``.\n",
      "     |      \n",
      "     |      Calling this method will scale ``self.data`` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in ``self._header`` and ``self._image_header``.\n",
      "     |      This method should only be used right before writing to the output\n",
      "     |      file, as the data will be scaled and is therefore not very usable after\n",
      "     |      the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy dtype\n",
      "     |          name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'`` etc.).  If is\n",
      "     |          `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          how to scale the data: if ``\"old\"``, use the original ``BSCALE``\n",
      "     |          and ``BZERO`` values when the data was read/created. If\n",
      "     |          ``\"minmax\"``, use the minimum and maximum of the data to scale.\n",
      "     |          The option will be overwritten by any user-specified bscale/bzero\n",
      "     |          values.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          user specified ``BSCALE`` and ``BZERO`` values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      This is an abstract type that implements the shared functionality of\n",
      "     |      the ASCII and Binary Table HDU types, which should be used instead of\n",
      "     |      this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  compressed_data\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.table.BinTableHDU:\n",
      "     |  \n",
      "     |  dump(self, datafile=None, cdfile=None, hfile=None, overwrite=False)\n",
      "     |      Dump the table HDU to a file in ASCII format.  The table may be dumped\n",
      "     |      in three separate files, one containing column definitions, one\n",
      "     |      containing header parameters, and one for table data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : path-like or file-like, optional\n",
      "     |          Output data file.  The default is the root name of the\n",
      "     |          fits file associated with this HDU appended with the\n",
      "     |          extension ``.txt``.\n",
      "     |      \n",
      "     |      cdfile : path-like or file-like, optional\n",
      "     |          Output column definitions file.  The default is `None`, no\n",
      "     |          column definitions output is produced.\n",
      "     |      \n",
      "     |      hfile : path-like or file-like, optional\n",
      "     |          Output header parameters file.  The default is `None`,\n",
      "     |          no header parameters output is produced.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` if ``False`` and the output file exists. Default is\n",
      "     |          ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `dump` method is to allow viewing and editing\n",
      "     |      the table data and parameters in a standard text editor.\n",
      "     |      The `load` method can be used to create a new table from the three\n",
      "     |      plain text (ASCII) files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.table.BinTableHDU:\n",
      "     |  \n",
      "     |  load(datafile, cdfile=None, hfile=None, replace=False, header=None) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Create a table from the input ASCII files.  The input is from up to\n",
      "     |      three separate files, one containing column definitions, one containing\n",
      "     |      header parameters, and one containing column data.\n",
      "     |      \n",
      "     |      The column definition and header parameters files are not required.\n",
      "     |      When absent the column definitions and/or header parameters are taken\n",
      "     |      from the header object given in the header argument; otherwise sensible\n",
      "     |      defaults are inferred (though this mode is not recommended).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : path-like or file-like\n",
      "     |          Input data file containing the table data in ASCII format.\n",
      "     |      \n",
      "     |      cdfile : path-like or file-like, optional\n",
      "     |          Input column definition file containing the names,\n",
      "     |          formats, display formats, physical units, multidimensional\n",
      "     |          array dimensions, undefined values, scale factors, and\n",
      "     |          offsets associated with the columns in the table.  If\n",
      "     |          `None`, the column definitions are taken from the current\n",
      "     |          values in this object.\n",
      "     |      \n",
      "     |      hfile : path-like or file-like, optional\n",
      "     |          Input parameter definition file containing the header\n",
      "     |          parameter definitions to be associated with the table.  If\n",
      "     |          `None`, the header parameter definitions are taken from\n",
      "     |          the current values in this objects header.\n",
      "     |      \n",
      "     |      replace : bool, optional\n",
      "     |          When `True`, indicates that the entire header should be\n",
      "     |          replaced with the contents of the ASCII file instead of\n",
      "     |          just updating the current header.\n",
      "     |      \n",
      "     |      header : `~astropy.io.fits.Header`, optional\n",
      "     |          When the cdfile and hfile are missing, use this Header object in\n",
      "     |          the creation of the new table and HDU.  Otherwise this Header\n",
      "     |          supersedes the keywords from hfile, which is only used to update\n",
      "     |          values not present in this Header, unless ``replace=True`` in which\n",
      "     |          this Header's values are completely replaced with the values from\n",
      "     |          hfile.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `load` method is to allow the input of ASCII\n",
      "     |      data that was edited in a standard text editor of the table data and\n",
      "     |      parameters.  The `dump` method can be used to create the initial ASCII\n",
      "     |      files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.table._TableBaseHDU:\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the table HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  update(self)\n",
      "     |      Update header keywords to reflect recent changes of columns.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.table._TableBaseHDU:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.table._TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, character_as_bytes=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs` -like\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      character_as_bytes : bool\n",
      "     |          Whether to return bytes for string columns when accessed from the\n",
      "     |          HDU. By default this is `False` and (unicode) strings are returned,\n",
      "     |          but for large tables this may use up a lot of memory.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self)\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self)\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file-like\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Conf(astropy.config.configuration.ConfigNamespace)\n",
      "     |  Configuration parameters for `astropy.io.fits`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Conf\n",
      "     |      astropy.config.configuration.ConfigNamespace\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  enable_record_valued_keyword_cards\n",
      "     |      If True, enable support for record-valued keywords as described by FITS WCS distortion paper. Otherwise they are treated as normal keywords.\n",
      "     |  \n",
      "     |  enable_uint\n",
      "     |      If True, default to recognizing the convention for representing unsigned integers in FITS--if an array has BITPIX > 0, BSCALE = 1, and BZERO = 2**BITPIX, represent the data as unsigned integers per this convention.\n",
      "     |  \n",
      "     |  extension_name_case_sensitive\n",
      "     |      If True, extension names (i.e. the ``EXTNAME`` keyword) should be treated as case-sensitive.\n",
      "     |  \n",
      "     |  lazy_load_hdus\n",
      "     |      If True, use lazy loading of HDUs when opening FITS files by default; that is fits.open() will only seek for and read HDUs on demand rather than reading all HDUs at once.  See the documentation for fits.open() for more datails.\n",
      "     |  \n",
      "     |  strip_header_whitespace\n",
      "     |      If True, automatically remove trailing whitespace for string values in headers. Otherwise the values are returned verbatim, with all whitespace intact.\n",
      "     |  \n",
      "     |  use_memmap\n",
      "     |      If True, use memory-mapped file access to read/write the data in FITS files. This generally provides better performance, especially for large files, but may affect performance in I/O-heavy applications.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.config.configuration.ConfigNamespace:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      Iterate over configuration item ``(name, value)`` pairs.\n",
      "     |  \n",
      "     |  keys = __iter__(self)\n",
      "     |  \n",
      "     |  reload(self, attr=None)\n",
      "     |      Reload a configuration item from the configuration file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attr : str, optional\n",
      "     |          The name of the configuration parameter to reload.  If not\n",
      "     |          provided, reload all configuration parameters.\n",
      "     |  \n",
      "     |  reset(self, attr=None)\n",
      "     |      Reset a configuration item to its default.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attr : str, optional\n",
      "     |          The name of the configuration parameter to reload.  If not\n",
      "     |          provided, reset all configuration parameters.\n",
      "     |  \n",
      "     |  set_temp(self, attr, value)\n",
      "     |      Temporarily set a configuration value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attr : str\n",
      "     |          Configuration item name\n",
      "     |      \n",
      "     |      value : object\n",
      "     |          The value to set temporarily.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import astropy\n",
      "     |      >>> with astropy.conf.set_temp('use_color', False):\n",
      "     |      ...     pass\n",
      "     |      ...     # console output will not contain color\n",
      "     |      >>> # console output contains color again...\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      Iterate over configuration item values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.config.configuration.ConfigNamespace:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Delayed(builtins.object)\n",
      "     |  Delayed(hdu=None, field=None)\n",
      "     |  \n",
      "     |  Delayed file-reading data.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, hdu=None, field=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class FITS_rec(numpy.recarray)\n",
      "     |  FITS_rec(input)\n",
      "     |  \n",
      "     |  FITS record array class.\n",
      "     |  \n",
      "     |  `FITS_rec` is the data part of a table HDU's data part.  This is a layer\n",
      "     |  over the `~numpy.recarray`, so we can deal with scaled columns.\n",
      "     |  \n",
      "     |  It inherits all of the standard methods from `numpy.ndarray`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FITS_rec\n",
      "     |      numpy.recarray\n",
      "     |      numpy.ndarray\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __array_finalize__(self, obj)\n",
      "     |      None.\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __getattribute__(self, attr)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Return a 3-tuple for pickling a FITS_rec. Use the super-class\n",
      "     |      functionality but then add in a tuple of FITS_rec-specific\n",
      "     |      values that get used in __setstate__.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      a.__setstate__(state, /)\n",
      "     |      \n",
      "     |      For unpickling.\n",
      "     |      \n",
      "     |      The `state` argument must be a sequence that contains the following\n",
      "     |      elements:\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      version : int\n",
      "     |          optional pickle version. If omitted defaults to 0.\n",
      "     |      shape : tuple\n",
      "     |      dtype : data-type\n",
      "     |      isFortran : bool\n",
      "     |      rawdata : string or list\n",
      "     |          a binary string with the data (or a list if 'a' is an object array)\n",
      "     |  \n",
      "     |  copy(self, order='C')\n",
      "     |      The Numpy documentation lies; `numpy.ndarray.copy` is not equivalent to\n",
      "     |      `numpy.copy`.  Differences include that it re-views the copied array as\n",
      "     |      self's ndarray subclass, as though it were taking a slice; this means\n",
      "     |      ``__array_finalize__`` is called and the copy shares all the array\n",
      "     |      attributes (including ``._converted``!).  So we need to make a deep\n",
      "     |      copy of all those attributes so that the two arrays truly do not share\n",
      "     |      any data.\n",
      "     |  \n",
      "     |  field(self, key)\n",
      "     |      A view of a `Column`'s data as an array.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_columns(columns, nrows=0, fill=False, character_as_bytes=False) from builtins.type\n",
      "     |      Given a `ColDefs` object of unknown origin, initialize a new `FITS_rec`\n",
      "     |      object.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This was originally part of the ``new_table`` function in the table\n",
      "     |          module but was moved into a class method since most of its\n",
      "     |          functionality always had more to do with initializing a `FITS_rec`\n",
      "     |          object than anything else, and much of it also overlapped with\n",
      "     |          ``FITS_rec._scale_back``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column` or a `ColDefs`\n",
      "     |          The columns from which to create the table data.  If these\n",
      "     |          columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns\n",
      "     |          will be used as a template for a new table with the requested\n",
      "     |          number of rows.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If\n",
      "     |          `False`, copy the data from input, undefined cells will still\n",
      "     |          be filled with zeros/blanks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(subtype, input)\n",
      "     |      Construct a FITS record array from a recarray.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      A user-visible accessor for the coldefs.\n",
      "     |  \n",
      "     |  formats\n",
      "     |      List of column FITS formats.\n",
      "     |  \n",
      "     |  names\n",
      "     |      List of column names.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __abs__(self, /)\n",
      "     |      abs(self)\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __and__(self, value, /)\n",
      "     |      Return self&value.\n",
      "     |  \n",
      "     |  __array__(...)\n",
      "     |      a.__array__([dtype], /) -> reference if type unchanged, copy otherwise.\n",
      "     |      \n",
      "     |      Returns either a new reference to self if dtype is not given or a new array\n",
      "     |      of provided data type if dtype is different from the current dtype of the\n",
      "     |      array.\n",
      "     |  \n",
      "     |  __array_function__(...)\n",
      "     |  \n",
      "     |  __array_prepare__(...)\n",
      "     |      a.__array_prepare__(obj) -> Object of same type as ndarray object obj.\n",
      "     |  \n",
      "     |  __array_ufunc__(...)\n",
      "     |  \n",
      "     |  __array_wrap__(...)\n",
      "     |      a.__array_wrap__(obj) -> Object of same type as ndarray object a.\n",
      "     |  \n",
      "     |  __bool__(self, /)\n",
      "     |      self != 0\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      a.__copy__()\n",
      "     |      \n",
      "     |      Used if :func:`copy.copy` is called on an array. Returns a copy of the array.\n",
      "     |      \n",
      "     |      Equivalent to ``a.copy(order='K')``.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      a.__deepcopy__(memo, /) -> Deep copy of array.\n",
      "     |      \n",
      "     |      Used if :func:`copy.deepcopy` is called on an array.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __divmod__(self, value, /)\n",
      "     |      Return divmod(self, value).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(self, /)\n",
      "     |      float(self)\n",
      "     |  \n",
      "     |  __floordiv__(self, value, /)\n",
      "     |      Return self//value.\n",
      "     |  \n",
      "     |  __format__(...)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iadd__(self, value, /)\n",
      "     |      Return self+=value.\n",
      "     |  \n",
      "     |  __iand__(self, value, /)\n",
      "     |      Return self&=value.\n",
      "     |  \n",
      "     |  __ifloordiv__(self, value, /)\n",
      "     |      Return self//=value.\n",
      "     |  \n",
      "     |  __ilshift__(self, value, /)\n",
      "     |      Return self<<=value.\n",
      "     |  \n",
      "     |  __imatmul__(self, value, /)\n",
      "     |      Return self@=value.\n",
      "     |  \n",
      "     |  __imod__(self, value, /)\n",
      "     |      Return self%=value.\n",
      "     |  \n",
      "     |  __imul__(self, value, /)\n",
      "     |      Return self*=value.\n",
      "     |  \n",
      "     |  __index__(self, /)\n",
      "     |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      "     |  \n",
      "     |  __int__(self, /)\n",
      "     |      int(self)\n",
      "     |  \n",
      "     |  __invert__(self, /)\n",
      "     |      ~self\n",
      "     |  \n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |  \n",
      "     |  __ipow__(self, value, /)\n",
      "     |      Return self**=value.\n",
      "     |  \n",
      "     |  __irshift__(self, value, /)\n",
      "     |      Return self>>=value.\n",
      "     |  \n",
      "     |  __isub__(self, value, /)\n",
      "     |      Return self-=value.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __itruediv__(self, value, /)\n",
      "     |      Return self/=value.\n",
      "     |  \n",
      "     |  __ixor__(self, value, /)\n",
      "     |      Return self^=value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lshift__(self, value, /)\n",
      "     |      Return self<<value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(self, value, /)\n",
      "     |      Return self@value.\n",
      "     |  \n",
      "     |  __mod__(self, value, /)\n",
      "     |      Return self%value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__(self, /)\n",
      "     |      -self\n",
      "     |  \n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |  \n",
      "     |  __pos__(self, /)\n",
      "     |      +self\n",
      "     |  \n",
      "     |  __pow__(self, value, mod=None, /)\n",
      "     |      Return pow(self, value, mod).\n",
      "     |  \n",
      "     |  __radd__(self, value, /)\n",
      "     |      Return value+self.\n",
      "     |  \n",
      "     |  __rand__(self, value, /)\n",
      "     |      Return value&self.\n",
      "     |  \n",
      "     |  __rdivmod__(self, value, /)\n",
      "     |      Return divmod(value, self).\n",
      "     |  \n",
      "     |  __reduce_ex__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, value, /)\n",
      "     |      Return value//self.\n",
      "     |  \n",
      "     |  __rlshift__(self, value, /)\n",
      "     |      Return value<<self.\n",
      "     |  \n",
      "     |  __rmatmul__(self, value, /)\n",
      "     |      Return value@self.\n",
      "     |  \n",
      "     |  __rmod__(self, value, /)\n",
      "     |      Return value%self.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |  \n",
      "     |  __rpow__(self, value, mod=None, /)\n",
      "     |      Return pow(value, self, mod).\n",
      "     |  \n",
      "     |  __rrshift__(self, value, /)\n",
      "     |      Return value>>self.\n",
      "     |  \n",
      "     |  __rshift__(self, value, /)\n",
      "     |      Return self>>value.\n",
      "     |  \n",
      "     |  __rsub__(self, value, /)\n",
      "     |      Return value-self.\n",
      "     |  \n",
      "     |  __rtruediv__(self, value, /)\n",
      "     |      Return value/self.\n",
      "     |  \n",
      "     |  __rxor__(self, value, /)\n",
      "     |      Return value^self.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__(self, value, /)\n",
      "     |      Return self-value.\n",
      "     |  \n",
      "     |  __truediv__(self, value, /)\n",
      "     |      Return self/value.\n",
      "     |  \n",
      "     |  __xor__(self, value, /)\n",
      "     |      Return self^value.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      a.all(axis=None, out=None, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns True if all elements evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.all` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.all : equivalent function\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      a.any(axis=None, out=None, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns True if any of the elements of `a` evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.any` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.any : equivalent function\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      a.argmax(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the maximum values along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmax : equivalent function\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      a.argmin(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the minimum values along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmin` for detailed documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmin : equivalent function\n",
      "     |  \n",
      "     |  argpartition(...)\n",
      "     |      a.argpartition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would partition this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argpartition` for full documentation.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argpartition : equivalent function\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      a.argsort(axis=-1, kind=None, order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would sort this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argsort` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argsort : equivalent function\n",
      "     |  \n",
      "     |  astype(...)\n",
      "     |      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n",
      "     |      \n",
      "     |      Copy of the array, cast to a specified type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          Typecode or data-type to which the array is cast.\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          Controls the memory layout order of the result.\n",
      "     |          'C' means C order, 'F' means Fortran order, 'A'\n",
      "     |          means 'F' order if all the arrays are Fortran contiguous,\n",
      "     |          'C' order otherwise, and 'K' means as close to the\n",
      "     |          order the array elements appear in memory as possible.\n",
      "     |          Default is 'K'.\n",
      "     |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "     |          Controls what kind of data casting may occur. Defaults to 'unsafe'\n",
      "     |          for backwards compatibility.\n",
      "     |      \n",
      "     |            * 'no' means the data types should not be cast at all.\n",
      "     |            * 'equiv' means only byte-order changes are allowed.\n",
      "     |            * 'safe' means only casts which can preserve values are allowed.\n",
      "     |            * 'same_kind' means only safe casts or casts within a kind,\n",
      "     |              like float64 to float32, are allowed.\n",
      "     |            * 'unsafe' means any data conversions may be done.\n",
      "     |      subok : bool, optional\n",
      "     |          If True, then sub-classes will be passed-through (default), otherwise\n",
      "     |          the returned array will be forced to be a base-class array.\n",
      "     |      copy : bool, optional\n",
      "     |          By default, astype always returns a newly allocated array. If this\n",
      "     |          is set to false, and the `dtype`, `order`, and `subok`\n",
      "     |          requirements are satisfied, the input array is returned instead\n",
      "     |          of a copy.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      arr_t : ndarray\n",
      "     |          Unless `copy` is False and the other conditions for returning the input\n",
      "     |          array are satisfied (see description for `copy` input parameter), `arr_t`\n",
      "     |          is a new array of the same shape as the input array, with dtype, order\n",
      "     |          given by `dtype`, `order`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. versionchanged:: 1.17.0\n",
      "     |         Casting between a simple data type and a structured one is possible only\n",
      "     |         for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n",
      "     |         casting from multiple fields is not.\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.9.0\n",
      "     |         Casting from numeric to string types in 'safe' casting mode requires\n",
      "     |         that the string dtype length is long enough to store the max\n",
      "     |         integer/float value converted.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ComplexWarning\n",
      "     |          When casting from complex to float or int. To avoid this,\n",
      "     |          one should use ``a.real.astype(t)``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 2.5])\n",
      "     |      >>> x\n",
      "     |      array([1. ,  2. ,  2.5])\n",
      "     |      \n",
      "     |      >>> x.astype(int)\n",
      "     |      array([1, 2, 2])\n",
      "     |  \n",
      "     |  byteswap(...)\n",
      "     |      a.byteswap(inplace=False)\n",
      "     |      \n",
      "     |      Swap the bytes of the array elements\n",
      "     |      \n",
      "     |      Toggle between low-endian and big-endian data representation by\n",
      "     |      returning a byteswapped array, optionally swapped in-place.\n",
      "     |      Arrays of byte-strings are not swapped. The real and imaginary\n",
      "     |      parts of a complex number are swapped individually.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : bool, optional\n",
      "     |          If ``True``, swap bytes in-place, default is ``False``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The byteswapped array. If `inplace` is ``True``, this is\n",
      "     |          a view to self.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> A = np.array([1, 256, 8755], dtype=np.int16)\n",
      "     |      >>> list(map(hex, A))\n",
      "     |      ['0x1', '0x100', '0x2233']\n",
      "     |      >>> A.byteswap(inplace=True)\n",
      "     |      array([  256,     1, 13090], dtype=int16)\n",
      "     |      >>> list(map(hex, A))\n",
      "     |      ['0x100', '0x1', '0x3322']\n",
      "     |      \n",
      "     |      Arrays of byte-strings are not swapped\n",
      "     |      \n",
      "     |      >>> A = np.array([b'ceg', b'fac'])\n",
      "     |      >>> A.byteswap()\n",
      "     |      array([b'ceg', b'fac'], dtype='|S3')\n",
      "     |      \n",
      "     |      ``A.newbyteorder().byteswap()`` produces an array with the same values\n",
      "     |        but different representation in memory\n",
      "     |      \n",
      "     |      >>> A = np.array([1, 2, 3])\n",
      "     |      >>> A.view(np.uint8)\n",
      "     |      array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "     |             0, 0], dtype=uint8)\n",
      "     |      >>> A.newbyteorder().byteswap(inplace=True)\n",
      "     |      array([1, 2, 3])\n",
      "     |      >>> A.view(np.uint8)\n",
      "     |      array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
      "     |             0, 3], dtype=uint8)\n",
      "     |  \n",
      "     |  choose(...)\n",
      "     |      a.choose(choices, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Use an index array to construct a new array from a set of choices.\n",
      "     |      \n",
      "     |      Refer to `numpy.choose` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.choose : equivalent function\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      a.clip(min=None, max=None, out=None, **kwargs)\n",
      "     |      \n",
      "     |      Return an array whose values are limited to ``[min, max]``.\n",
      "     |      One of max or min must be given.\n",
      "     |      \n",
      "     |      Refer to `numpy.clip` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.clip : equivalent function\n",
      "     |  \n",
      "     |  compress(...)\n",
      "     |      a.compress(condition, axis=None, out=None)\n",
      "     |      \n",
      "     |      Return selected slices of this array along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.compress` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.compress : equivalent function\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      a.conj()\n",
      "     |      \n",
      "     |      Complex-conjugate all elements.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  conjugate(...)\n",
      "     |      a.conjugate()\n",
      "     |      \n",
      "     |      Return the complex conjugate, element-wise.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      a.cumprod(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative product of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumprod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumprod : equivalent function\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      a.cumsum(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative sum of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumsum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumsum : equivalent function\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      a.diagonal(offset=0, axis1=0, axis2=1)\n",
      "     |      \n",
      "     |      Return specified diagonals. In NumPy 1.9 the returned array is a\n",
      "     |      read-only view instead of a copy as in previous NumPy versions.  In\n",
      "     |      a future version the read-only restriction will be removed.\n",
      "     |      \n",
      "     |      Refer to :func:`numpy.diagonal` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.diagonal : equivalent function\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      a.dot(b, out=None)\n",
      "     |      \n",
      "     |      Dot product of two arrays.\n",
      "     |      \n",
      "     |      Refer to `numpy.dot` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dot : equivalent function\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.eye(2)\n",
      "     |      >>> b = np.ones((2, 2)) * 2\n",
      "     |      >>> a.dot(b)\n",
      "     |      array([[2.,  2.],\n",
      "     |             [2.,  2.]])\n",
      "     |      \n",
      "     |      This array method can be conveniently chained:\n",
      "     |      \n",
      "     |      >>> a.dot(b).dot(b)\n",
      "     |      array([[8.,  8.],\n",
      "     |             [8.,  8.]])\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      a.dump(file)\n",
      "     |      \n",
      "     |      Dump a pickle of the array to the specified file.\n",
      "     |      The array can be read back with pickle.load or numpy.load.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      file : str or Path\n",
      "     |          A string naming the dump file.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.17.0\n",
      "     |              `pathlib.Path` objects are now accepted.\n",
      "     |  \n",
      "     |  dumps(...)\n",
      "     |      a.dumps()\n",
      "     |      \n",
      "     |      Returns the pickle of the array as a string.\n",
      "     |      pickle.loads or numpy.loads will convert the string back to an array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |  \n",
      "     |  fill(...)\n",
      "     |      a.fill(value)\n",
      "     |      \n",
      "     |      Fill the array with a scalar value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar\n",
      "     |          All elements of `a` will be assigned this value.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([1, 2])\n",
      "     |      >>> a.fill(0)\n",
      "     |      >>> a\n",
      "     |      array([0, 0])\n",
      "     |      >>> a = np.empty(2)\n",
      "     |      >>> a.fill(1)\n",
      "     |      >>> a\n",
      "     |      array([1.,  1.])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      a.flatten(order='C')\n",
      "     |      \n",
      "     |      Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          'C' means to flatten in row-major (C-style) order.\n",
      "     |          'F' means to flatten in column-major (Fortran-\n",
      "     |          style) order. 'A' means to flatten in column-major\n",
      "     |          order if `a` is Fortran *contiguous* in memory,\n",
      "     |          row-major order otherwise. 'K' means to flatten\n",
      "     |          `a` in the order the elements occur in memory.\n",
      "     |          The default is 'C'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : ndarray\n",
      "     |          A copy of the input array, flattened to one dimension.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ravel : Return a flattened array.\n",
      "     |      flat : A 1-D flat iterator over the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,2], [3,4]])\n",
      "     |      >>> a.flatten()\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |      >>> a.flatten('F')\n",
      "     |      array([1, 3, 2, 4])\n",
      "     |  \n",
      "     |  getfield(...)\n",
      "     |      a.getfield(dtype, offset=0)\n",
      "     |      \n",
      "     |      Returns a field of the given array as a certain type.\n",
      "     |      \n",
      "     |      A field is a view of the array data with a given data-type. The values in\n",
      "     |      the view are determined by the given type and the offset into the current\n",
      "     |      array in bytes. The offset needs to be such that the view dtype fits in the\n",
      "     |      array dtype; for example an array of dtype complex128 has 16-byte elements.\n",
      "     |      If taking a view with a 32-bit integer (4 bytes), the offset needs to be\n",
      "     |      between 0 and 12 bytes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          The data type of the view. The dtype size of the view can not be larger\n",
      "     |          than that of the array itself.\n",
      "     |      offset : int\n",
      "     |          Number of bytes to skip before beginning the element view.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.diag([1.+1.j]*2)\n",
      "     |      >>> x[1, 1] = 2 + 4.j\n",
      "     |      >>> x\n",
      "     |      array([[1.+1.j,  0.+0.j],\n",
      "     |             [0.+0.j,  2.+4.j]])\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[1.,  0.],\n",
      "     |             [0.,  2.]])\n",
      "     |      \n",
      "     |      By choosing an offset of 8 bytes we can select the complex part of the\n",
      "     |      array for our view:\n",
      "     |      \n",
      "     |      >>> x.getfield(np.float64, offset=8)\n",
      "     |      array([[1.,  0.],\n",
      "     |             [0.,  4.]])\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      a.item(*args)\n",
      "     |      \n",
      "     |      Copy an element of an array to a standard Python scalar and return it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments (variable number and type)\n",
      "     |      \n",
      "     |          * none: in this case, the method only works for arrays\n",
      "     |            with one element (`a.size == 1`), which element is\n",
      "     |            copied into a standard Python scalar object and returned.\n",
      "     |      \n",
      "     |          * int_type: this argument is interpreted as a flat index into\n",
      "     |            the array, specifying which element to copy and return.\n",
      "     |      \n",
      "     |          * tuple of int_types: functions as does a single int_type argument,\n",
      "     |            except that the argument is interpreted as an nd-index into the\n",
      "     |            array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      z : Standard Python scalar object\n",
      "     |          A copy of the specified element of the array as a suitable\n",
      "     |          Python scalar\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When the data type of `a` is longdouble or clongdouble, item() returns\n",
      "     |      a scalar array object because there is no available Python scalar that\n",
      "     |      would not lose information. Void arrays return a buffer object for item(),\n",
      "     |      unless fields are defined, in which case a tuple is returned.\n",
      "     |      \n",
      "     |      `item` is very similar to a[args], except, instead of an array scalar,\n",
      "     |      a standard Python scalar is returned. This can be useful for speeding up\n",
      "     |      access to elements of the array and doing arithmetic on elements of the\n",
      "     |      array using Python's optimized math.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.seed(123)\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[2, 2, 6],\n",
      "     |             [1, 3, 6],\n",
      "     |             [1, 0, 1]])\n",
      "     |      >>> x.item(3)\n",
      "     |      1\n",
      "     |      >>> x.item(7)\n",
      "     |      0\n",
      "     |      >>> x.item((0, 1))\n",
      "     |      2\n",
      "     |      >>> x.item((2, 2))\n",
      "     |      1\n",
      "     |  \n",
      "     |  itemset(...)\n",
      "     |      a.itemset(*args)\n",
      "     |      \n",
      "     |      Insert scalar into an array (scalar is cast to array's dtype, if possible)\n",
      "     |      \n",
      "     |      There must be at least 1 argument, and define the last argument\n",
      "     |      as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster\n",
      "     |      than ``a[args] = item``.  The item should be a scalar value and `args`\n",
      "     |      must select a single item in the array `a`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments\n",
      "     |          If one argument: a scalar, only used in case `a` is of size 1.\n",
      "     |          If two arguments: the last argument is the value to be set\n",
      "     |          and must be a scalar, the first argument specifies a single array\n",
      "     |          element location. It is either an int or a tuple.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Compared to indexing syntax, `itemset` provides some speed increase\n",
      "     |      for placing a scalar into a particular location in an `ndarray`,\n",
      "     |      if you must do this.  However, generally this is discouraged:\n",
      "     |      among other problems, it complicates the appearance of the code.\n",
      "     |      Also, when using `itemset` (and `item`) inside a loop, be sure\n",
      "     |      to assign the methods to a local variable to avoid the attribute\n",
      "     |      look-up at each loop iteration.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.seed(123)\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[2, 2, 6],\n",
      "     |             [1, 3, 6],\n",
      "     |             [1, 0, 1]])\n",
      "     |      >>> x.itemset(4, 0)\n",
      "     |      >>> x.itemset((2, 2), 9)\n",
      "     |      >>> x\n",
      "     |      array([[2, 2, 6],\n",
      "     |             [1, 0, 6],\n",
      "     |             [1, 0, 9]])\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      a.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n",
      "     |      \n",
      "     |      Return the maximum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amax : equivalent function\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      a.mean(axis=None, dtype=None, out=None, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns the average of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.mean` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.mean : equivalent function\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      a.min(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n",
      "     |      \n",
      "     |      Return the minimum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amin` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amin : equivalent function\n",
      "     |  \n",
      "     |  newbyteorder(...)\n",
      "     |      arr.newbyteorder(new_order='S', /)\n",
      "     |      \n",
      "     |      Return the array with the same data viewed with a different byte order.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          arr.view(arr.dtype.newbytorder(new_order))\n",
      "     |      \n",
      "     |      Changes are also made in all fields and sub-arrays of the array data\n",
      "     |      type.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_order : string, optional\n",
      "     |          Byte order to force; a value from the byte order specifications\n",
      "     |          below. `new_order` codes can be any of:\n",
      "     |      \n",
      "     |          * 'S' - swap dtype from current to opposite endian\n",
      "     |          * {'<', 'little'} - little endian\n",
      "     |          * {'>', 'big'} - big endian\n",
      "     |          * '=' - native order, equivalent to `sys.byteorder`\n",
      "     |          * {'|', 'I'} - ignore (no change to byte order)\n",
      "     |      \n",
      "     |          The default value ('S') results in swapping the current\n",
      "     |          byte order.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      new_arr : array\n",
      "     |          New array object with the dtype reflecting given change to the\n",
      "     |          byte order.\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      a.nonzero()\n",
      "     |      \n",
      "     |      Return the indices of the elements that are non-zero.\n",
      "     |      \n",
      "     |      Refer to `numpy.nonzero` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.nonzero : equivalent function\n",
      "     |  \n",
      "     |  partition(...)\n",
      "     |      a.partition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Rearranges the elements in the array in such a way that the value of the\n",
      "     |      element in kth position is in the position it would be in a sorted array.\n",
      "     |      All elements smaller than the kth element are moved before this element and\n",
      "     |      all equal or greater are moved behind it. The ordering of the elements in\n",
      "     |      the two partitions is undefined.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kth : int or sequence of ints\n",
      "     |          Element index to partition by. The kth element value will be in its\n",
      "     |          final sorted position and all smaller elements will be moved before it\n",
      "     |          and all equal or greater elements behind it.\n",
      "     |          The order of all elements in the partitions is undefined.\n",
      "     |          If provided with a sequence of kth it will partition all elements\n",
      "     |          indexed by kth of them into their sorted position at once.\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'introselect'}, optional\n",
      "     |          Selection algorithm. Default is 'introselect'.\n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc. A single field can\n",
      "     |          be specified as a string, and not all fields need to be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.partition : Return a parititioned copy of an array.\n",
      "     |      argpartition : Indirect partition.\n",
      "     |      sort : Full sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See ``np.partition`` for notes on the different algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([3, 4, 2, 1])\n",
      "     |      >>> a.partition(3)\n",
      "     |      >>> a\n",
      "     |      array([2, 1, 3, 4])\n",
      "     |      \n",
      "     |      >>> a.partition((1, 3))\n",
      "     |      >>> a\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      a.prod(axis=None, dtype=None, out=None, keepdims=False, initial=1, where=True)\n",
      "     |      \n",
      "     |      Return the product of the array elements over the given axis\n",
      "     |      \n",
      "     |      Refer to `numpy.prod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.prod : equivalent function\n",
      "     |  \n",
      "     |  ptp(...)\n",
      "     |      a.ptp(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Peak to peak (maximum - minimum) value along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.ptp` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ptp : equivalent function\n",
      "     |  \n",
      "     |  put(...)\n",
      "     |      a.put(indices, values, mode='raise')\n",
      "     |      \n",
      "     |      Set ``a.flat[n] = values[n]`` for all `n` in indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.put` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.put : equivalent function\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      a.ravel([order])\n",
      "     |      \n",
      "     |      Return a flattened array.\n",
      "     |      \n",
      "     |      Refer to `numpy.ravel` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ravel : equivalent function\n",
      "     |      \n",
      "     |      ndarray.flat : a flat iterator on the array.\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      a.repeat(repeats, axis=None)\n",
      "     |      \n",
      "     |      Repeat elements of an array.\n",
      "     |      \n",
      "     |      Refer to `numpy.repeat` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.repeat : equivalent function\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      a.reshape(shape, order='C')\n",
      "     |      \n",
      "     |      Returns an array containing the same data with a new shape.\n",
      "     |      \n",
      "     |      Refer to `numpy.reshape` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.reshape : equivalent function\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n",
      "     |      the elements of the shape parameter to be passed in as separate arguments.\n",
      "     |      For example, ``a.reshape(10, 11)`` is equivalent to\n",
      "     |      ``a.reshape((10, 11))``.\n",
      "     |  \n",
      "     |  resize(...)\n",
      "     |      a.resize(new_shape, refcheck=True)\n",
      "     |      \n",
      "     |      Change shape and size of array in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_shape : tuple of ints, or `n` ints\n",
      "     |          Shape of resized array.\n",
      "     |      refcheck : bool, optional\n",
      "     |          If False, reference count will not be checked. Default is True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If `a` does not own its own data or references or views to it exist,\n",
      "     |          and the data memory must be changed.\n",
      "     |          PyPy only: will always raise if the data memory must be changed, since\n",
      "     |          there is no reliable way to determine if references or views to it\n",
      "     |          exist.\n",
      "     |      \n",
      "     |      SystemError\n",
      "     |          If the `order` keyword argument is specified. This behaviour is a\n",
      "     |          bug in NumPy.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      resize : Return a new array with the specified shape.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This reallocates space for the data area if necessary.\n",
      "     |      \n",
      "     |      Only contiguous arrays (data elements consecutive in memory) can be\n",
      "     |      resized.\n",
      "     |      \n",
      "     |      The purpose of the reference count check is to make sure you\n",
      "     |      do not use this array as a buffer for another Python object and then\n",
      "     |      reallocate the memory. However, reference counts can increase in\n",
      "     |      other ways so if you are sure that you have not shared the memory\n",
      "     |      for this array with another Python object, then you may safely set\n",
      "     |      `refcheck` to False.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Shrinking an array: array is flattened (in the order that the data are\n",
      "     |      stored in memory), resized, and reshaped:\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='C')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [1]])\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='F')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [2]])\n",
      "     |      \n",
      "     |      Enlarging an array: as above, but missing entries are filled with zeros:\n",
      "     |      \n",
      "     |      >>> b = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple\n",
      "     |      >>> b\n",
      "     |      array([[0, 1, 2],\n",
      "     |             [3, 0, 0]])\n",
      "     |      \n",
      "     |      Referencing an array prevents resizing...\n",
      "     |      \n",
      "     |      >>> c = a\n",
      "     |      >>> a.resize((1, 1))\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: cannot resize an array that references or is referenced ...\n",
      "     |      \n",
      "     |      Unless `refcheck` is False:\n",
      "     |      \n",
      "     |      >>> a.resize((1, 1), refcheck=False)\n",
      "     |      >>> a\n",
      "     |      array([[0]])\n",
      "     |      >>> c\n",
      "     |      array([[0]])\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      a.round(decimals=0, out=None)\n",
      "     |      \n",
      "     |      Return `a` with each element rounded to the given number of decimals.\n",
      "     |      \n",
      "     |      Refer to `numpy.around` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around : equivalent function\n",
      "     |  \n",
      "     |  searchsorted(...)\n",
      "     |      a.searchsorted(v, side='left', sorter=None)\n",
      "     |      \n",
      "     |      Find indices where elements of v should be inserted in a to maintain order.\n",
      "     |      \n",
      "     |      For full documentation, see `numpy.searchsorted`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.searchsorted : equivalent function\n",
      "     |  \n",
      "     |  setfield(...)\n",
      "     |      a.setfield(val, dtype, offset=0)\n",
      "     |      \n",
      "     |      Put a value into a specified place in a field defined by a data-type.\n",
      "     |      \n",
      "     |      Place `val` into `a`'s field defined by `dtype` and beginning `offset`\n",
      "     |      bytes into the field.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      val : object\n",
      "     |          Value to be placed in field.\n",
      "     |      dtype : dtype object\n",
      "     |          Data-type of the field in which to place `val`.\n",
      "     |      offset : int, optional\n",
      "     |          The number of bytes into the field at which to place `val`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      getfield\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.eye(3)\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[1.,  0.,  0.],\n",
      "     |             [0.,  1.,  0.],\n",
      "     |             [0.,  0.,  1.]])\n",
      "     |      >>> x.setfield(3, np.int32)\n",
      "     |      >>> x.getfield(np.int32)\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3],\n",
      "     |             [3, 3, 3]], dtype=int32)\n",
      "     |      >>> x\n",
      "     |      array([[1.0e+000, 1.5e-323, 1.5e-323],\n",
      "     |             [1.5e-323, 1.0e+000, 1.5e-323],\n",
      "     |             [1.5e-323, 1.5e-323, 1.0e+000]])\n",
      "     |      >>> x.setfield(np.eye(3), np.int32)\n",
      "     |      >>> x\n",
      "     |      array([[1.,  0.,  0.],\n",
      "     |             [0.,  1.,  0.],\n",
      "     |             [0.,  0.,  1.]])\n",
      "     |  \n",
      "     |  setflags(...)\n",
      "     |      a.setflags(write=None, align=None, uic=None)\n",
      "     |      \n",
      "     |      Set array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\n",
      "     |      respectively.\n",
      "     |      \n",
      "     |      These Boolean-valued flags affect how numpy interprets the memory\n",
      "     |      area used by `a` (see Notes below). The ALIGNED flag can only\n",
      "     |      be set to True if the data is actually aligned according to the type.\n",
      "     |      The WRITEBACKIFCOPY and (deprecated) UPDATEIFCOPY flags can never be set\n",
      "     |      to True. The flag WRITEABLE can only be set to True if the array owns its\n",
      "     |      own memory, or the ultimate owner of the memory exposes a writeable buffer\n",
      "     |      interface, or is a string. (The exception for string is made so that\n",
      "     |      unpickling can be done without copying memory.)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      write : bool, optional\n",
      "     |          Describes whether or not `a` can be written to.\n",
      "     |      align : bool, optional\n",
      "     |          Describes whether or not `a` is aligned properly for its type.\n",
      "     |      uic : bool, optional\n",
      "     |          Describes whether or not `a` is a copy of another \"base\" array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Array flags provide information about how the memory area used\n",
      "     |      for the array is to be interpreted. There are 7 Boolean flags\n",
      "     |      in use, only four of which can be changed by the user:\n",
      "     |      WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n",
      "     |      \n",
      "     |      WRITEABLE (W) the data area can be written to;\n",
      "     |      \n",
      "     |      ALIGNED (A) the data and strides are aligned appropriately for the hardware\n",
      "     |      (as determined by the compiler);\n",
      "     |      \n",
      "     |      UPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n",
      "     |      \n",
      "     |      WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced\n",
      "     |      by .base). When the C-API function PyArray_ResolveWritebackIfCopy is\n",
      "     |      called, the base array will be updated with the contents of this array.\n",
      "     |      \n",
      "     |      All flags can be accessed using the single (upper case) letter as well\n",
      "     |      as the full name.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y = np.array([[3, 1, 7],\n",
      "     |      ...               [2, 0, 0],\n",
      "     |      ...               [8, 5, 9]])\n",
      "     |      >>> y\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 0, 0],\n",
      "     |             [8, 5, 9]])\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : True\n",
      "     |        ALIGNED : True\n",
      "     |        WRITEBACKIFCOPY : False\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(write=0, align=0)\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : False\n",
      "     |        ALIGNED : False\n",
      "     |        WRITEBACKIFCOPY : False\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(uic=1)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: cannot set WRITEBACKIFCOPY flag to True\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      a.sort(axis=-1, kind=None, order=None)\n",
      "     |      \n",
      "     |      Sort an array in-place. Refer to `numpy.sort` for full documentation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n",
      "     |          Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n",
      "     |          and 'mergesort' use timsort under the covers and, in general, the\n",
      "     |          actual implementation will vary with datatype. The 'mergesort' option\n",
      "     |          is retained for backwards compatibility.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.15.0\n",
      "     |             The 'stable' option was added.\n",
      "     |      \n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc.  A single field can\n",
      "     |          be specified as a string, and not all fields need be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sort : Return a sorted copy of an array.\n",
      "     |      numpy.argsort : Indirect sort.\n",
      "     |      numpy.lexsort : Indirect stable sort on multiple keys.\n",
      "     |      numpy.searchsorted : Find elements in sorted array.\n",
      "     |      numpy.partition: Partial sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See `numpy.sort` for notes on the different sorting algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,4], [3,1]])\n",
      "     |      >>> a.sort(axis=1)\n",
      "     |      >>> a\n",
      "     |      array([[1, 4],\n",
      "     |             [1, 3]])\n",
      "     |      >>> a.sort(axis=0)\n",
      "     |      >>> a\n",
      "     |      array([[1, 3],\n",
      "     |             [1, 4]])\n",
      "     |      \n",
      "     |      Use the `order` keyword to specify a field to use when sorting a\n",
      "     |      structured array:\n",
      "     |      \n",
      "     |      >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\n",
      "     |      >>> a.sort(order='y')\n",
      "     |      >>> a\n",
      "     |      array([(b'c', 1), (b'a', 2)],\n",
      "     |            dtype=[('x', 'S1'), ('y', '<i8')])\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      a.squeeze(axis=None)\n",
      "     |      \n",
      "     |      Remove axes of length one from `a`.\n",
      "     |      \n",
      "     |      Refer to `numpy.squeeze` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.squeeze : equivalent function\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      a.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns the standard deviation of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.std` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.std : equivalent function\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      a.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)\n",
      "     |      \n",
      "     |      Return the sum of the array elements over the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.sum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sum : equivalent function\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      a.swapaxes(axis1, axis2)\n",
      "     |      \n",
      "     |      Return a view of the array with `axis1` and `axis2` interchanged.\n",
      "     |      \n",
      "     |      Refer to `numpy.swapaxes` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.swapaxes : equivalent function\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      a.take(indices, axis=None, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Return an array formed from the elements of `a` at the given indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.take` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.take : equivalent function\n",
      "     |  \n",
      "     |  tobytes(...)\n",
      "     |      a.tobytes(order='C')\n",
      "     |      \n",
      "     |      Construct Python bytes containing the raw data bytes in the array.\n",
      "     |      \n",
      "     |      Constructs Python bytes showing a copy of the raw contents of\n",
      "     |      data memory. The bytes object is produced in C-order by default.\n",
      "     |      This behavior is controlled by the ``order`` parameter.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.9.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A'}, optional\n",
      "     |          Controls the memory layout of the bytes object. 'C' means C-order,\n",
      "     |          'F' means F-order, 'A' (short for *Any*) means 'F' if `a` is\n",
      "     |          Fortran contiguous, 'C' otherwise. Default is 'C'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : bytes\n",
      "     |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]], dtype='<u2')\n",
      "     |      >>> x.tobytes()\n",
      "     |      b'\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00'\n",
      "     |      >>> x.tobytes('C') == x.tobytes()\n",
      "     |      True\n",
      "     |      >>> x.tobytes('F')\n",
      "     |      b'\\x00\\x00\\x02\\x00\\x01\\x00\\x03\\x00'\n",
      "     |  \n",
      "     |  tofile(...)\n",
      "     |      a.tofile(fid, sep=\"\", format=\"%s\")\n",
      "     |      \n",
      "     |      Write array to a file as text or binary (default).\n",
      "     |      \n",
      "     |      Data is always written in 'C' order, independent of the order of `a`.\n",
      "     |      The data produced by this method can be recovered using the function\n",
      "     |      fromfile().\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fid : file or str or Path\n",
      "     |          An open file object, or a string containing a filename.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.17.0\n",
      "     |              `pathlib.Path` objects are now accepted.\n",
      "     |      \n",
      "     |      sep : str\n",
      "     |          Separator between array items for text output.\n",
      "     |          If \"\" (empty), a binary file is written, equivalent to\n",
      "     |          ``file.write(a.tobytes())``.\n",
      "     |      format : str\n",
      "     |          Format string for text file output.\n",
      "     |          Each entry in the array is formatted to text by first converting\n",
      "     |          it to the closest Python type, and then using \"format\" % item.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a convenience function for quick storage of array data.\n",
      "     |      Information on endianness and precision is lost, so this method is not a\n",
      "     |      good choice for files intended to archive data or transport data between\n",
      "     |      machines with different endianness. Some of these problems can be overcome\n",
      "     |      by outputting the data as text files, at the expense of speed and file\n",
      "     |      size.\n",
      "     |      \n",
      "     |      When fid is a file object, array contents are directly written to the\n",
      "     |      file, bypassing the file object's ``write`` method. As a result, tofile\n",
      "     |      cannot be used with files objects supporting compression (e.g., GzipFile)\n",
      "     |      or file-like objects that do not support ``fileno()`` (e.g., BytesIO).\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      a.tolist()\n",
      "     |      \n",
      "     |      Return the array as an ``a.ndim``-levels deep nested list of Python scalars.\n",
      "     |      \n",
      "     |      Return a copy of the array data as a (nested) Python list.\n",
      "     |      Data items are converted to the nearest compatible builtin Python type, via\n",
      "     |      the `~numpy.ndarray.item` function.\n",
      "     |      \n",
      "     |      If ``a.ndim`` is 0, then since the depth of the nested list is 0, it will\n",
      "     |      not be a list at all, but a simple Python scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      none\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : object, or list of object, or list of list of object, or ...\n",
      "     |          The possibly nested list of array elements.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The array may be recreated via ``a = np.array(a.tolist())``, although this\n",
      "     |      may sometimes lose precision.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      For a 1D array, ``a.tolist()`` is almost the same as ``list(a)``,\n",
      "     |      except that ``tolist`` changes numpy scalars to Python scalars:\n",
      "     |      \n",
      "     |      >>> a = np.uint32([1, 2])\n",
      "     |      >>> a_list = list(a)\n",
      "     |      >>> a_list\n",
      "     |      [1, 2]\n",
      "     |      >>> type(a_list[0])\n",
      "     |      <class 'numpy.uint32'>\n",
      "     |      >>> a_tolist = a.tolist()\n",
      "     |      >>> a_tolist\n",
      "     |      [1, 2]\n",
      "     |      >>> type(a_tolist[0])\n",
      "     |      <class 'int'>\n",
      "     |      \n",
      "     |      Additionally, for a 2D array, ``tolist`` applies recursively:\n",
      "     |      \n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> list(a)\n",
      "     |      [array([1, 2]), array([3, 4])]\n",
      "     |      >>> a.tolist()\n",
      "     |      [[1, 2], [3, 4]]\n",
      "     |      \n",
      "     |      The base case for this recursion is a 0D array:\n",
      "     |      \n",
      "     |      >>> a = np.array(1)\n",
      "     |      >>> list(a)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: iteration over a 0-d array\n",
      "     |      >>> a.tolist()\n",
      "     |      1\n",
      "     |  \n",
      "     |  tostring(...)\n",
      "     |      a.tostring(order='C')\n",
      "     |      \n",
      "     |      A compatibility alias for `tobytes`, with exactly the same behavior.\n",
      "     |      \n",
      "     |      Despite its name, it returns `bytes` not `str`\\ s.\n",
      "     |      \n",
      "     |      .. deprecated:: 1.19.0\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the sum along diagonals of the array.\n",
      "     |      \n",
      "     |      Refer to `numpy.trace` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.trace : equivalent function\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      a.transpose(*axes)\n",
      "     |      \n",
      "     |      Returns a view of the array with axes transposed.\n",
      "     |      \n",
      "     |      For a 1-D array this has no effect, as a transposed vector is simply the\n",
      "     |      same vector. To convert a 1-D array into a 2D column vector, an additional\n",
      "     |      dimension must be added. `np.atleast2d(a).T` achieves this, as does\n",
      "     |      `a[:, np.newaxis]`.\n",
      "     |      For a 2-D array, this is a standard matrix transpose.\n",
      "     |      For an n-D array, if axes are given, their order indicates how the\n",
      "     |      axes are permuted (see Examples). If axes are not provided and\n",
      "     |      ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then\n",
      "     |      ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axes : None, tuple of ints, or `n` ints\n",
      "     |      \n",
      "     |       * None or no argument: reverses the order of the axes.\n",
      "     |      \n",
      "     |       * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s\n",
      "     |         `i`-th axis becomes `a.transpose()`'s `j`-th axis.\n",
      "     |      \n",
      "     |       * `n` ints: same as an n-tuple of the same ints (this form is\n",
      "     |         intended simply as a \"convenience\" alternative to the tuple form)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          View of `a`, with axes suitably permuted.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transpose : Equivalent function\n",
      "     |      ndarray.T : Array property returning the array transposed.\n",
      "     |      ndarray.reshape : Give a new shape to an array without changing its data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> a\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]])\n",
      "     |      >>> a.transpose()\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose((1, 0))\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose(1, 0)\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      a.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns the variance of the array elements, along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.var` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.var : equivalent function\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      a.view([dtype][, type])\n",
      "     |      \n",
      "     |      New view of array with the same data.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          Passing None for ``dtype`` is different from omitting the parameter,\n",
      "     |          since the former invokes ``dtype(None)`` which is an alias for\n",
      "     |          ``dtype('float_')``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data-type or ndarray sub-class, optional\n",
      "     |          Data-type descriptor of the returned view, e.g., float32 or int16.\n",
      "     |          Omitting it results in the view having the same data-type as `a`.\n",
      "     |          This argument can also be specified as an ndarray sub-class, which\n",
      "     |          then specifies the type of the returned object (this is equivalent to\n",
      "     |          setting the ``type`` parameter).\n",
      "     |      type : Python type, optional\n",
      "     |          Type of the returned view, e.g., ndarray or matrix.  Again, omission\n",
      "     |          of the parameter results in type preservation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      ``a.view()`` is used two different ways:\n",
      "     |      \n",
      "     |      ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view\n",
      "     |      of the array's memory with a different data-type.  This can cause a\n",
      "     |      reinterpretation of the bytes of memory.\n",
      "     |      \n",
      "     |      ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just\n",
      "     |      returns an instance of `ndarray_subclass` that looks at the same array\n",
      "     |      (same shape, dtype, etc.)  This does not cause a reinterpretation of the\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of\n",
      "     |      bytes per entry than the previous dtype (for example, converting a\n",
      "     |      regular array to a structured array), then the behavior of the view\n",
      "     |      cannot be predicted just from the superficial appearance of ``a`` (shown\n",
      "     |      by ``print(a)``). It also depends on exactly how ``a`` is stored in\n",
      "     |      memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus\n",
      "     |      defined as a slice or transpose, etc., the view may give different\n",
      "     |      results.\n",
      "     |      \n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      \n",
      "     |      Viewing array data using a different type and dtype:\n",
      "     |      \n",
      "     |      >>> y = x.view(dtype=np.int16, type=np.matrix)\n",
      "     |      >>> y\n",
      "     |      matrix([[513]], dtype=int16)\n",
      "     |      >>> print(type(y))\n",
      "     |      <class 'numpy.matrix'>\n",
      "     |      \n",
      "     |      Creating a view on a structured array so it can be used in calculations\n",
      "     |      \n",
      "     |      >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      >>> xv = x.view(dtype=np.int8).reshape(-1,2)\n",
      "     |      >>> xv\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]], dtype=int8)\n",
      "     |      >>> xv.mean(0)\n",
      "     |      array([2.,  3.])\n",
      "     |      \n",
      "     |      Making changes to the view changes the underlying array\n",
      "     |      \n",
      "     |      >>> xv[0,1] = 20\n",
      "     |      >>> x\n",
      "     |      array([(1, 20), (3,  4)], dtype=[('a', 'i1'), ('b', 'i1')])\n",
      "     |      \n",
      "     |      Using a view to convert an array to a recarray:\n",
      "     |      \n",
      "     |      >>> z = x.view(np.recarray)\n",
      "     |      >>> z.a\n",
      "     |      array([1, 3], dtype=int8)\n",
      "     |      \n",
      "     |      Views share data:\n",
      "     |      \n",
      "     |      >>> x[0] = (9, 10)\n",
      "     |      >>> z[0]\n",
      "     |      (9, 10)\n",
      "     |      \n",
      "     |      Views that change the dtype size (bytes per entry) should normally be\n",
      "     |      avoided on arrays defined by slices, transposes, fortran-ordering, etc.:\n",
      "     |      \n",
      "     |      >>> x = np.array([[1,2,3],[4,5,6]], dtype=np.int16)\n",
      "     |      >>> y = x[:, 0:2]\n",
      "     |      >>> y\n",
      "     |      array([[1, 2],\n",
      "     |             [4, 5]], dtype=int16)\n",
      "     |      >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      ValueError: To change to a dtype of a different size, the array must be C-contiguous\n",
      "     |      >>> z = y.copy()\n",
      "     |      >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      array([[(1, 2)],\n",
      "     |             [(4, 5)]], dtype=[('width', '<i2'), ('length', '<i2')])\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  T\n",
      "     |      The transposed array.\n",
      "     |      \n",
      "     |      Same as ``self.transpose()``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[1.,2.],[3.,4.]])\n",
      "     |      >>> x\n",
      "     |      array([[ 1.,  2.],\n",
      "     |             [ 3.,  4.]])\n",
      "     |      >>> x.T\n",
      "     |      array([[ 1.,  3.],\n",
      "     |             [ 2.,  4.]])\n",
      "     |      >>> x = np.array([1.,2.,3.,4.])\n",
      "     |      >>> x\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |      >>> x.T\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transpose\n",
      "     |  \n",
      "     |  __array_interface__\n",
      "     |      Array protocol: Python side.\n",
      "     |  \n",
      "     |  __array_priority__\n",
      "     |      Array priority.\n",
      "     |  \n",
      "     |  __array_struct__\n",
      "     |      Array protocol: C-struct side.\n",
      "     |  \n",
      "     |  base\n",
      "     |      Base object if memory is from some other object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      The base of an array that owns its memory is None:\n",
      "     |      \n",
      "     |      >>> x = np.array([1,2,3,4])\n",
      "     |      >>> x.base is None\n",
      "     |      True\n",
      "     |      \n",
      "     |      Slicing creates a view, whose memory is shared with x:\n",
      "     |      \n",
      "     |      >>> y = x[2:]\n",
      "     |      >>> y.base is x\n",
      "     |      True\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      An object to simplify the interaction of the array with the ctypes\n",
      "     |      module.\n",
      "     |      \n",
      "     |      This attribute creates an object that makes it easier to use arrays\n",
      "     |      when calling shared libraries with the ctypes module. The returned\n",
      "     |      object has, among others, data, shape, and strides attributes (see\n",
      "     |      Notes below) which themselves return ctypes objects that can be used\n",
      "     |      as arguments to a shared library.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      c : Python object\n",
      "     |          Possessing attributes data, shape, strides, etc.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ctypeslib\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Below are the public attributes of this object which were documented\n",
      "     |      in \"Guide to NumPy\" (we have omitted undocumented public attributes,\n",
      "     |      as well as documented private attributes):\n",
      "     |      \n",
      "     |      .. autoattribute:: numpy.core._internal._ctypes.data\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. autoattribute:: numpy.core._internal._ctypes.shape\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. autoattribute:: numpy.core._internal._ctypes.strides\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. automethod:: numpy.core._internal._ctypes.data_as\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. automethod:: numpy.core._internal._ctypes.shape_as\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. automethod:: numpy.core._internal._ctypes.strides_as\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      If the ctypes module is not available, then the ctypes attribute\n",
      "     |      of array objects still returns something useful, but ctypes objects\n",
      "     |      are not returned and errors may be raised instead. In particular,\n",
      "     |      the object will still have the ``as_parameter`` attribute which will\n",
      "     |      return an integer equal to the data attribute.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import ctypes\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32)\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]], dtype=int32)\n",
      "     |      >>> x.ctypes.data\n",
      "     |      31962608 # may vary\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32))\n",
      "     |      <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents\n",
      "     |      c_uint(0)\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents\n",
      "     |      c_ulong(4294967296)\n",
      "     |      >>> x.ctypes.shape\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary\n",
      "     |      >>> x.ctypes.strides\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary\n",
      "     |  \n",
      "     |  data\n",
      "     |      Python buffer object pointing to the start of the array's data.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Data-type of the array's elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      d : numpy dtype object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dtype\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]])\n",
      "     |      >>> x.dtype\n",
      "     |      dtype('int32')\n",
      "     |      >>> type(x.dtype)\n",
      "     |      <type 'numpy.dtype'>\n",
      "     |  \n",
      "     |  flags\n",
      "     |      Information about the memory layout of the array.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      C_CONTIGUOUS (C)\n",
      "     |          The data is in a single, C-style contiguous segment.\n",
      "     |      F_CONTIGUOUS (F)\n",
      "     |          The data is in a single, Fortran-style contiguous segment.\n",
      "     |      OWNDATA (O)\n",
      "     |          The array owns the memory it uses or borrows it from another object.\n",
      "     |      WRITEABLE (W)\n",
      "     |          The data area can be written to.  Setting this to False locks\n",
      "     |          the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE\n",
      "     |          from its base array at creation time, but a view of a writeable\n",
      "     |          array may be subsequently locked while the base array remains writeable.\n",
      "     |          (The opposite is not true, in that a view of a locked array may not\n",
      "     |          be made writeable.  However, currently, locking a base object does not\n",
      "     |          lock any views that already reference it, so under that circumstance it\n",
      "     |          is possible to alter the contents of a locked array via a previously\n",
      "     |          created writeable view onto it.)  Attempting to change a non-writeable\n",
      "     |          array raises a RuntimeError exception.\n",
      "     |      ALIGNED (A)\n",
      "     |          The data and all elements are aligned appropriately for the hardware.\n",
      "     |      WRITEBACKIFCOPY (X)\n",
      "     |          This array is a copy of some other array. The C-API function\n",
      "     |          PyArray_ResolveWritebackIfCopy must be called before deallocating\n",
      "     |          to the base array will be updated with the contents of this array.\n",
      "     |      UPDATEIFCOPY (U)\n",
      "     |          (Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\n",
      "     |          When this array is\n",
      "     |          deallocated, the base array will be updated with the contents of\n",
      "     |          this array.\n",
      "     |      FNC\n",
      "     |          F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      FORC\n",
      "     |          F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n",
      "     |      BEHAVED (B)\n",
      "     |          ALIGNED and WRITEABLE.\n",
      "     |      CARRAY (CA)\n",
      "     |          BEHAVED and C_CONTIGUOUS.\n",
      "     |      FARRAY (FA)\n",
      "     |          BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),\n",
      "     |      or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag\n",
      "     |      names are only supported in dictionary access.\n",
      "     |      \n",
      "     |      Only the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\n",
      "     |      changed by the user, via direct assignment to the attribute or dictionary\n",
      "     |      entry, or by calling `ndarray.setflags`.\n",
      "     |      \n",
      "     |      The array flags cannot be set arbitrarily:\n",
      "     |      \n",
      "     |      - UPDATEIFCOPY can only be set ``False``.\n",
      "     |      - WRITEBACKIFCOPY can only be set ``False``.\n",
      "     |      - ALIGNED can only be set ``True`` if the data is truly aligned.\n",
      "     |      - WRITEABLE can only be set ``True`` if the array owns its own memory\n",
      "     |        or the ultimate owner of the memory exposes a writeable buffer\n",
      "     |        interface or is a string.\n",
      "     |      \n",
      "     |      Arrays can be both C-style and Fortran-style contiguous simultaneously.\n",
      "     |      This is clear for 1-dimensional arrays, but can also be true for higher\n",
      "     |      dimensional arrays.\n",
      "     |      \n",
      "     |      Even for contiguous arrays a stride for a given dimension\n",
      "     |      ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``\n",
      "     |      or the array has no elements.\n",
      "     |      It does *not* generally hold that ``self.strides[-1] == self.itemsize``\n",
      "     |      for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for\n",
      "     |      Fortran-style contiguous arrays is true.\n",
      "     |  \n",
      "     |  flat\n",
      "     |      A 1-D iterator over the array.\n",
      "     |      \n",
      "     |      This is a `numpy.flatiter` instance, which acts similarly to, but is not\n",
      "     |      a subclass of, Python's built-in iterator object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      flatten : Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      flatiter\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.arange(1, 7).reshape(2, 3)\n",
      "     |      >>> x\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]])\n",
      "     |      >>> x.flat[3]\n",
      "     |      4\n",
      "     |      >>> x.T\n",
      "     |      array([[1, 4],\n",
      "     |             [2, 5],\n",
      "     |             [3, 6]])\n",
      "     |      >>> x.T.flat[3]\n",
      "     |      5\n",
      "     |      >>> type(x.flat)\n",
      "     |      <class 'numpy.flatiter'>\n",
      "     |      \n",
      "     |      An assignment example:\n",
      "     |      \n",
      "     |      >>> x.flat = 3; x\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3]])\n",
      "     |      >>> x.flat[[1,4]] = 1; x\n",
      "     |      array([[3, 1, 3],\n",
      "     |             [3, 1, 3]])\n",
      "     |  \n",
      "     |  imag\n",
      "     |      The imaginary part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.imag\n",
      "     |      array([ 0.        ,  0.70710678])\n",
      "     |      >>> x.imag.dtype\n",
      "     |      dtype('float64')\n",
      "     |  \n",
      "     |  itemsize\n",
      "     |      Length of one array element in bytes.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.float64)\n",
      "     |      >>> x.itemsize\n",
      "     |      8\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.complex128)\n",
      "     |      >>> x.itemsize\n",
      "     |      16\n",
      "     |  \n",
      "     |  nbytes\n",
      "     |      Total bytes consumed by the elements of the array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Does not include memory consumed by non-element attributes of the\n",
      "     |      array object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3,5,2), dtype=np.complex128)\n",
      "     |      >>> x.nbytes\n",
      "     |      480\n",
      "     |      >>> np.prod(x.shape) * x.itemsize\n",
      "     |      480\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Number of array dimensions.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3])\n",
      "     |      >>> x.ndim\n",
      "     |      1\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.ndim\n",
      "     |      3\n",
      "     |  \n",
      "     |  real\n",
      "     |      The real part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.real\n",
      "     |      array([ 1.        ,  0.70710678])\n",
      "     |      >>> x.real.dtype\n",
      "     |      dtype('float64')\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.real : equivalent function\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Tuple of array dimensions.\n",
      "     |      \n",
      "     |      The shape property is usually used to get the current shape of an array,\n",
      "     |      but may also be used to reshape the array in-place by assigning a tuple of\n",
      "     |      array dimensions to it.  As with `numpy.reshape`, one of the new shape\n",
      "     |      dimensions can be -1, in which case its value is inferred from the size of\n",
      "     |      the array and the remaining dimensions. Reshaping an array in-place will\n",
      "     |      fail if a copy is required.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3, 4])\n",
      "     |      >>> x.shape\n",
      "     |      (4,)\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.shape\n",
      "     |      (2, 3, 4)\n",
      "     |      >>> y.shape = (3, 8)\n",
      "     |      >>> y\n",
      "     |      array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "     |      >>> y.shape = (3, 6)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: total size of new array must be unchanged\n",
      "     |      >>> np.zeros((4,2))[::2].shape = (-1,)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      AttributeError: Incompatible shape for in-place modification. Use\n",
      "     |      `.reshape()` to make a copy with the desired shape.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.reshape : similar function\n",
      "     |      ndarray.reshape : similar method\n",
      "     |  \n",
      "     |  size\n",
      "     |      Number of elements in the array.\n",
      "     |      \n",
      "     |      Equal to ``np.prod(a.shape)``, i.e., the product of the array's\n",
      "     |      dimensions.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `a.size` returns a standard arbitrary precision Python integer. This\n",
      "     |      may not be the case with other methods of obtaining the same value\n",
      "     |      (like the suggested ``np.prod(a.shape)``, which returns an instance\n",
      "     |      of ``np.int_``), and may be relevant if the value is used further in\n",
      "     |      calculations that may overflow a fixed size integer type.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3, 5, 2), dtype=np.complex128)\n",
      "     |      >>> x.size\n",
      "     |      30\n",
      "     |      >>> np.prod(x.shape)\n",
      "     |      30\n",
      "     |  \n",
      "     |  strides\n",
      "     |      Tuple of bytes to step in each dimension when traversing an array.\n",
      "     |      \n",
      "     |      The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`\n",
      "     |      is::\n",
      "     |      \n",
      "     |          offset = sum(np.array(i) * a.strides)\n",
      "     |      \n",
      "     |      A more detailed explanation of strides can be found in the\n",
      "     |      \"ndarray.rst\" file in the NumPy reference guide.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Imagine an array of 32-bit integers (each 4 bytes)::\n",
      "     |      \n",
      "     |        x = np.array([[0, 1, 2, 3, 4],\n",
      "     |                      [5, 6, 7, 8, 9]], dtype=np.int32)\n",
      "     |      \n",
      "     |      This array is stored in memory as 40 bytes, one after the other\n",
      "     |      (known as a contiguous block of memory).  The strides of an array tell\n",
      "     |      us how many bytes we have to skip in memory to move to the next position\n",
      "     |      along a certain axis.  For example, we have to skip 4 bytes (1 value) to\n",
      "     |      move to the next column, but 20 bytes (5 values) to get to the same\n",
      "     |      position in the next row.  As such, the strides for the array `x` will be\n",
      "     |      ``(20, 4)``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.lib.stride_tricks.as_strided\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y = np.reshape(np.arange(2*3*4), (2,3,4))\n",
      "     |      >>> y\n",
      "     |      array([[[ 0,  1,  2,  3],\n",
      "     |              [ 4,  5,  6,  7],\n",
      "     |              [ 8,  9, 10, 11]],\n",
      "     |             [[12, 13, 14, 15],\n",
      "     |              [16, 17, 18, 19],\n",
      "     |              [20, 21, 22, 23]]])\n",
      "     |      >>> y.strides\n",
      "     |      (48, 16, 4)\n",
      "     |      >>> y[1,1,1]\n",
      "     |      17\n",
      "     |      >>> offset=sum(y.strides * np.array((1,1,1)))\n",
      "     |      >>> offset/y.itemsize\n",
      "     |      17\n",
      "     |      \n",
      "     |      >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)\n",
      "     |      >>> x.strides\n",
      "     |      (32, 4, 224, 1344)\n",
      "     |      >>> i = np.array([3,5,2,2])\n",
      "     |      >>> offset = sum(i * x.strides)\n",
      "     |      >>> x[3,5,2,2]\n",
      "     |      813\n",
      "     |      >>> offset / x.itemsize\n",
      "     |      813\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class FITS_record(builtins.object)\n",
      "     |  FITS_record(input, row=0, start=None, end=None, step=None, base=None, **kwargs)\n",
      "     |  \n",
      "     |  FITS record class.\n",
      "     |  \n",
      "     |  `FITS_record` is used to access records of the `FITS_rec` object.\n",
      "     |  This will allow us to deal with scaled columns.  It also handles\n",
      "     |  conversion/scaling of columns in ASCII tables.  The `FITS_record`\n",
      "     |  class expects a `FITS_rec` object as input.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, input, row=0, start=None, end=None, step=None, base=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input : array\n",
      "     |         The array to wrap.\n",
      "     |      \n",
      "     |      row : int, optional\n",
      "     |         The starting logical row of the array.\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |         The starting column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |      \n",
      "     |      end : int, optional\n",
      "     |         The ending column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Display a single row.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  field(self, field)\n",
      "     |      Get the field data of the record.\n",
      "     |  \n",
      "     |  setfield(self, field, value)\n",
      "     |      Set the field data of the record.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class FitsHDU(astropy.io.fits.hdu.base.NonstandardExtHDU)\n",
      "     |  FitsHDU(data=None, header=None, name=None, ver=None, **kwargs)\n",
      "     |  \n",
      "     |  A non-standard extension HDU for encapsulating entire FITS files within a\n",
      "     |  single HDU of a container FITS file.  These HDUs have an extension (that is\n",
      "     |  an XTENSION keyword) of FITS.\n",
      "     |  \n",
      "     |  The FITS file contained in the HDU's data can be accessed by the `hdulist`\n",
      "     |  attribute which returns the contained FITS file as an `HDUList` object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FitsHDU\n",
      "     |      astropy.io.fits.hdu.base.NonstandardExtHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromfile(filename, compress=False) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Like `FitsHDU.fromhdulist()`, but creates a FitsHDU from a file on\n",
      "     |      disk.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          The path to the file to read into a FitsHDU\n",
      "     |      compress : bool, optional\n",
      "     |          Gzip compress the FITS file\n",
      "     |  \n",
      "     |  fromhdulist(hdulist, compress=False) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new FitsHDU from a given HDUList object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hdulist : HDUList\n",
      "     |          A valid Headerlet object.\n",
      "     |      compress : bool, optional\n",
      "     |          Gzip compress the FITS file\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Matches any extension HDU that is not one of the standard extension HDU\n",
      "     |      types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  hdulist\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base.NonstandardExtHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |      Return the file data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, ver=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self)\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self)\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file-like\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Group(astropy.io.fits.fitsrec.FITS_record)\n",
      "     |  Group(input, row=0, start=None, end=None, step=None, base=None)\n",
      "     |  \n",
      "     |  One group of the random group data.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Group\n",
      "     |      astropy.io.fits.fitsrec.FITS_record\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, input, row=0, start=None, end=None, step=None, base=None)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input : array\n",
      "     |         The array to wrap.\n",
      "     |      \n",
      "     |      row : int, optional\n",
      "     |         The starting logical row of the array.\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |         The starting column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |      \n",
      "     |      end : int, optional\n",
      "     |         The ending column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |  \n",
      "     |  par(self, parname)\n",
      "     |      Get the group parameter value.\n",
      "     |  \n",
      "     |  setpar(self, parname, value)\n",
      "     |      Set the group parameter value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  parnames\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.fitsrec.FITS_record:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Display a single row.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  field(self, field)\n",
      "     |      Get the field data of the record.\n",
      "     |  \n",
      "     |  setfield(self, field, value)\n",
      "     |      Set the field data of the record.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.fitsrec.FITS_record:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GroupData(astropy.io.fits.fitsrec.FITS_rec)\n",
      "     |  GroupData(input=None, bitpix=None, pardata=None, parnames=[], bscale=None, bzero=None, parbscales=None, parbzeros=None)\n",
      "     |  \n",
      "     |  Random groups data object.\n",
      "     |  \n",
      "     |  Allows structured access to FITS Group data in a manner analogous\n",
      "     |  to tables.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupData\n",
      "     |      astropy.io.fits.fitsrec.FITS_rec\n",
      "     |      numpy.recarray\n",
      "     |      numpy.ndarray\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __array_finalize__(self, obj)\n",
      "     |      None.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  par(self, parname)\n",
      "     |      Get the group parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, input=None, bitpix=None, pardata=None, parnames=[], bscale=None, bzero=None, parbscales=None, parbzeros=None)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input : array or FITS_rec instance\n",
      "     |          input data, either the group data itself (a\n",
      "     |          `numpy.ndarray`) or a record array (`FITS_rec`) which will\n",
      "     |          contain both group parameter info and the data.  The rest\n",
      "     |          of the arguments are used only for the first case.\n",
      "     |      \n",
      "     |      bitpix : int\n",
      "     |          data type as expressed in FITS ``BITPIX`` value (8, 16, 32,\n",
      "     |          64, -32, or -64)\n",
      "     |      \n",
      "     |      pardata : sequence of array\n",
      "     |          parameter data, as a list of (numeric) arrays.\n",
      "     |      \n",
      "     |      parnames : sequence of str\n",
      "     |          list of parameter names.\n",
      "     |      \n",
      "     |      bscale : int\n",
      "     |          ``BSCALE`` of the data\n",
      "     |      \n",
      "     |      bzero : int\n",
      "     |          ``BZERO`` of the data\n",
      "     |      \n",
      "     |      parbscales : sequence of int\n",
      "     |          list of bscales for the parameters\n",
      "     |      \n",
      "     |      parbzeros : sequence of int\n",
      "     |          list of bzeros for the parameters\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  data\n",
      "     |      The raw group data represented as a multi-dimensional `numpy.ndarray`\n",
      "     |      array.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.fitsrec.FITS_rec:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __getattribute__(self, attr)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Return a 3-tuple for pickling a FITS_rec. Use the super-class\n",
      "     |      functionality but then add in a tuple of FITS_rec-specific\n",
      "     |      values that get used in __setstate__.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      a.__setstate__(state, /)\n",
      "     |      \n",
      "     |      For unpickling.\n",
      "     |      \n",
      "     |      The `state` argument must be a sequence that contains the following\n",
      "     |      elements:\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      version : int\n",
      "     |          optional pickle version. If omitted defaults to 0.\n",
      "     |      shape : tuple\n",
      "     |      dtype : data-type\n",
      "     |      isFortran : bool\n",
      "     |      rawdata : string or list\n",
      "     |          a binary string with the data (or a list if 'a' is an object array)\n",
      "     |  \n",
      "     |  copy(self, order='C')\n",
      "     |      The Numpy documentation lies; `numpy.ndarray.copy` is not equivalent to\n",
      "     |      `numpy.copy`.  Differences include that it re-views the copied array as\n",
      "     |      self's ndarray subclass, as though it were taking a slice; this means\n",
      "     |      ``__array_finalize__`` is called and the copy shares all the array\n",
      "     |      attributes (including ``._converted``!).  So we need to make a deep\n",
      "     |      copy of all those attributes so that the two arrays truly do not share\n",
      "     |      any data.\n",
      "     |  \n",
      "     |  field(self, key)\n",
      "     |      A view of a `Column`'s data as an array.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.fitsrec.FITS_rec:\n",
      "     |  \n",
      "     |  from_columns(columns, nrows=0, fill=False, character_as_bytes=False) from builtins.type\n",
      "     |      Given a `ColDefs` object of unknown origin, initialize a new `FITS_rec`\n",
      "     |      object.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This was originally part of the ``new_table`` function in the table\n",
      "     |          module but was moved into a class method since most of its\n",
      "     |          functionality always had more to do with initializing a `FITS_rec`\n",
      "     |          object than anything else, and much of it also overlapped with\n",
      "     |          ``FITS_rec._scale_back``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column` or a `ColDefs`\n",
      "     |          The columns from which to create the table data.  If these\n",
      "     |          columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns\n",
      "     |          will be used as a template for a new table with the requested\n",
      "     |          number of rows.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If\n",
      "     |          `False`, copy the data from input, undefined cells will still\n",
      "     |          be filled with zeros/blanks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.fitsrec.FITS_rec:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      A user-visible accessor for the coldefs.\n",
      "     |  \n",
      "     |  formats\n",
      "     |      List of column FITS formats.\n",
      "     |  \n",
      "     |  names\n",
      "     |      List of column names.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __abs__(self, /)\n",
      "     |      abs(self)\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __and__(self, value, /)\n",
      "     |      Return self&value.\n",
      "     |  \n",
      "     |  __array__(...)\n",
      "     |      a.__array__([dtype], /) -> reference if type unchanged, copy otherwise.\n",
      "     |      \n",
      "     |      Returns either a new reference to self if dtype is not given or a new array\n",
      "     |      of provided data type if dtype is different from the current dtype of the\n",
      "     |      array.\n",
      "     |  \n",
      "     |  __array_function__(...)\n",
      "     |  \n",
      "     |  __array_prepare__(...)\n",
      "     |      a.__array_prepare__(obj) -> Object of same type as ndarray object obj.\n",
      "     |  \n",
      "     |  __array_ufunc__(...)\n",
      "     |  \n",
      "     |  __array_wrap__(...)\n",
      "     |      a.__array_wrap__(obj) -> Object of same type as ndarray object a.\n",
      "     |  \n",
      "     |  __bool__(self, /)\n",
      "     |      self != 0\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      a.__copy__()\n",
      "     |      \n",
      "     |      Used if :func:`copy.copy` is called on an array. Returns a copy of the array.\n",
      "     |      \n",
      "     |      Equivalent to ``a.copy(order='K')``.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      a.__deepcopy__(memo, /) -> Deep copy of array.\n",
      "     |      \n",
      "     |      Used if :func:`copy.deepcopy` is called on an array.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __divmod__(self, value, /)\n",
      "     |      Return divmod(self, value).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(self, /)\n",
      "     |      float(self)\n",
      "     |  \n",
      "     |  __floordiv__(self, value, /)\n",
      "     |      Return self//value.\n",
      "     |  \n",
      "     |  __format__(...)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iadd__(self, value, /)\n",
      "     |      Return self+=value.\n",
      "     |  \n",
      "     |  __iand__(self, value, /)\n",
      "     |      Return self&=value.\n",
      "     |  \n",
      "     |  __ifloordiv__(self, value, /)\n",
      "     |      Return self//=value.\n",
      "     |  \n",
      "     |  __ilshift__(self, value, /)\n",
      "     |      Return self<<=value.\n",
      "     |  \n",
      "     |  __imatmul__(self, value, /)\n",
      "     |      Return self@=value.\n",
      "     |  \n",
      "     |  __imod__(self, value, /)\n",
      "     |      Return self%=value.\n",
      "     |  \n",
      "     |  __imul__(self, value, /)\n",
      "     |      Return self*=value.\n",
      "     |  \n",
      "     |  __index__(self, /)\n",
      "     |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      "     |  \n",
      "     |  __int__(self, /)\n",
      "     |      int(self)\n",
      "     |  \n",
      "     |  __invert__(self, /)\n",
      "     |      ~self\n",
      "     |  \n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |  \n",
      "     |  __ipow__(self, value, /)\n",
      "     |      Return self**=value.\n",
      "     |  \n",
      "     |  __irshift__(self, value, /)\n",
      "     |      Return self>>=value.\n",
      "     |  \n",
      "     |  __isub__(self, value, /)\n",
      "     |      Return self-=value.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __itruediv__(self, value, /)\n",
      "     |      Return self/=value.\n",
      "     |  \n",
      "     |  __ixor__(self, value, /)\n",
      "     |      Return self^=value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lshift__(self, value, /)\n",
      "     |      Return self<<value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(self, value, /)\n",
      "     |      Return self@value.\n",
      "     |  \n",
      "     |  __mod__(self, value, /)\n",
      "     |      Return self%value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__(self, /)\n",
      "     |      -self\n",
      "     |  \n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |  \n",
      "     |  __pos__(self, /)\n",
      "     |      +self\n",
      "     |  \n",
      "     |  __pow__(self, value, mod=None, /)\n",
      "     |      Return pow(self, value, mod).\n",
      "     |  \n",
      "     |  __radd__(self, value, /)\n",
      "     |      Return value+self.\n",
      "     |  \n",
      "     |  __rand__(self, value, /)\n",
      "     |      Return value&self.\n",
      "     |  \n",
      "     |  __rdivmod__(self, value, /)\n",
      "     |      Return divmod(value, self).\n",
      "     |  \n",
      "     |  __reduce_ex__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, value, /)\n",
      "     |      Return value//self.\n",
      "     |  \n",
      "     |  __rlshift__(self, value, /)\n",
      "     |      Return value<<self.\n",
      "     |  \n",
      "     |  __rmatmul__(self, value, /)\n",
      "     |      Return value@self.\n",
      "     |  \n",
      "     |  __rmod__(self, value, /)\n",
      "     |      Return value%self.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |  \n",
      "     |  __rpow__(self, value, mod=None, /)\n",
      "     |      Return pow(value, self, mod).\n",
      "     |  \n",
      "     |  __rrshift__(self, value, /)\n",
      "     |      Return value>>self.\n",
      "     |  \n",
      "     |  __rshift__(self, value, /)\n",
      "     |      Return self>>value.\n",
      "     |  \n",
      "     |  __rsub__(self, value, /)\n",
      "     |      Return value-self.\n",
      "     |  \n",
      "     |  __rtruediv__(self, value, /)\n",
      "     |      Return value/self.\n",
      "     |  \n",
      "     |  __rxor__(self, value, /)\n",
      "     |      Return value^self.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__(self, value, /)\n",
      "     |      Return self-value.\n",
      "     |  \n",
      "     |  __truediv__(self, value, /)\n",
      "     |      Return self/value.\n",
      "     |  \n",
      "     |  __xor__(self, value, /)\n",
      "     |      Return self^value.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      a.all(axis=None, out=None, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns True if all elements evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.all` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.all : equivalent function\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      a.any(axis=None, out=None, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns True if any of the elements of `a` evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.any` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.any : equivalent function\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      a.argmax(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the maximum values along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmax : equivalent function\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      a.argmin(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the minimum values along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmin` for detailed documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmin : equivalent function\n",
      "     |  \n",
      "     |  argpartition(...)\n",
      "     |      a.argpartition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would partition this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argpartition` for full documentation.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argpartition : equivalent function\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      a.argsort(axis=-1, kind=None, order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would sort this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argsort` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argsort : equivalent function\n",
      "     |  \n",
      "     |  astype(...)\n",
      "     |      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n",
      "     |      \n",
      "     |      Copy of the array, cast to a specified type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          Typecode or data-type to which the array is cast.\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          Controls the memory layout order of the result.\n",
      "     |          'C' means C order, 'F' means Fortran order, 'A'\n",
      "     |          means 'F' order if all the arrays are Fortran contiguous,\n",
      "     |          'C' order otherwise, and 'K' means as close to the\n",
      "     |          order the array elements appear in memory as possible.\n",
      "     |          Default is 'K'.\n",
      "     |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "     |          Controls what kind of data casting may occur. Defaults to 'unsafe'\n",
      "     |          for backwards compatibility.\n",
      "     |      \n",
      "     |            * 'no' means the data types should not be cast at all.\n",
      "     |            * 'equiv' means only byte-order changes are allowed.\n",
      "     |            * 'safe' means only casts which can preserve values are allowed.\n",
      "     |            * 'same_kind' means only safe casts or casts within a kind,\n",
      "     |              like float64 to float32, are allowed.\n",
      "     |            * 'unsafe' means any data conversions may be done.\n",
      "     |      subok : bool, optional\n",
      "     |          If True, then sub-classes will be passed-through (default), otherwise\n",
      "     |          the returned array will be forced to be a base-class array.\n",
      "     |      copy : bool, optional\n",
      "     |          By default, astype always returns a newly allocated array. If this\n",
      "     |          is set to false, and the `dtype`, `order`, and `subok`\n",
      "     |          requirements are satisfied, the input array is returned instead\n",
      "     |          of a copy.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      arr_t : ndarray\n",
      "     |          Unless `copy` is False and the other conditions for returning the input\n",
      "     |          array are satisfied (see description for `copy` input parameter), `arr_t`\n",
      "     |          is a new array of the same shape as the input array, with dtype, order\n",
      "     |          given by `dtype`, `order`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. versionchanged:: 1.17.0\n",
      "     |         Casting between a simple data type and a structured one is possible only\n",
      "     |         for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n",
      "     |         casting from multiple fields is not.\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.9.0\n",
      "     |         Casting from numeric to string types in 'safe' casting mode requires\n",
      "     |         that the string dtype length is long enough to store the max\n",
      "     |         integer/float value converted.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ComplexWarning\n",
      "     |          When casting from complex to float or int. To avoid this,\n",
      "     |          one should use ``a.real.astype(t)``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 2.5])\n",
      "     |      >>> x\n",
      "     |      array([1. ,  2. ,  2.5])\n",
      "     |      \n",
      "     |      >>> x.astype(int)\n",
      "     |      array([1, 2, 2])\n",
      "     |  \n",
      "     |  byteswap(...)\n",
      "     |      a.byteswap(inplace=False)\n",
      "     |      \n",
      "     |      Swap the bytes of the array elements\n",
      "     |      \n",
      "     |      Toggle between low-endian and big-endian data representation by\n",
      "     |      returning a byteswapped array, optionally swapped in-place.\n",
      "     |      Arrays of byte-strings are not swapped. The real and imaginary\n",
      "     |      parts of a complex number are swapped individually.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : bool, optional\n",
      "     |          If ``True``, swap bytes in-place, default is ``False``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The byteswapped array. If `inplace` is ``True``, this is\n",
      "     |          a view to self.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> A = np.array([1, 256, 8755], dtype=np.int16)\n",
      "     |      >>> list(map(hex, A))\n",
      "     |      ['0x1', '0x100', '0x2233']\n",
      "     |      >>> A.byteswap(inplace=True)\n",
      "     |      array([  256,     1, 13090], dtype=int16)\n",
      "     |      >>> list(map(hex, A))\n",
      "     |      ['0x100', '0x1', '0x3322']\n",
      "     |      \n",
      "     |      Arrays of byte-strings are not swapped\n",
      "     |      \n",
      "     |      >>> A = np.array([b'ceg', b'fac'])\n",
      "     |      >>> A.byteswap()\n",
      "     |      array([b'ceg', b'fac'], dtype='|S3')\n",
      "     |      \n",
      "     |      ``A.newbyteorder().byteswap()`` produces an array with the same values\n",
      "     |        but different representation in memory\n",
      "     |      \n",
      "     |      >>> A = np.array([1, 2, 3])\n",
      "     |      >>> A.view(np.uint8)\n",
      "     |      array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "     |             0, 0], dtype=uint8)\n",
      "     |      >>> A.newbyteorder().byteswap(inplace=True)\n",
      "     |      array([1, 2, 3])\n",
      "     |      >>> A.view(np.uint8)\n",
      "     |      array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
      "     |             0, 3], dtype=uint8)\n",
      "     |  \n",
      "     |  choose(...)\n",
      "     |      a.choose(choices, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Use an index array to construct a new array from a set of choices.\n",
      "     |      \n",
      "     |      Refer to `numpy.choose` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.choose : equivalent function\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      a.clip(min=None, max=None, out=None, **kwargs)\n",
      "     |      \n",
      "     |      Return an array whose values are limited to ``[min, max]``.\n",
      "     |      One of max or min must be given.\n",
      "     |      \n",
      "     |      Refer to `numpy.clip` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.clip : equivalent function\n",
      "     |  \n",
      "     |  compress(...)\n",
      "     |      a.compress(condition, axis=None, out=None)\n",
      "     |      \n",
      "     |      Return selected slices of this array along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.compress` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.compress : equivalent function\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      a.conj()\n",
      "     |      \n",
      "     |      Complex-conjugate all elements.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  conjugate(...)\n",
      "     |      a.conjugate()\n",
      "     |      \n",
      "     |      Return the complex conjugate, element-wise.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      a.cumprod(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative product of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumprod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumprod : equivalent function\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      a.cumsum(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative sum of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumsum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumsum : equivalent function\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      a.diagonal(offset=0, axis1=0, axis2=1)\n",
      "     |      \n",
      "     |      Return specified diagonals. In NumPy 1.9 the returned array is a\n",
      "     |      read-only view instead of a copy as in previous NumPy versions.  In\n",
      "     |      a future version the read-only restriction will be removed.\n",
      "     |      \n",
      "     |      Refer to :func:`numpy.diagonal` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.diagonal : equivalent function\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      a.dot(b, out=None)\n",
      "     |      \n",
      "     |      Dot product of two arrays.\n",
      "     |      \n",
      "     |      Refer to `numpy.dot` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dot : equivalent function\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.eye(2)\n",
      "     |      >>> b = np.ones((2, 2)) * 2\n",
      "     |      >>> a.dot(b)\n",
      "     |      array([[2.,  2.],\n",
      "     |             [2.,  2.]])\n",
      "     |      \n",
      "     |      This array method can be conveniently chained:\n",
      "     |      \n",
      "     |      >>> a.dot(b).dot(b)\n",
      "     |      array([[8.,  8.],\n",
      "     |             [8.,  8.]])\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      a.dump(file)\n",
      "     |      \n",
      "     |      Dump a pickle of the array to the specified file.\n",
      "     |      The array can be read back with pickle.load or numpy.load.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      file : str or Path\n",
      "     |          A string naming the dump file.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.17.0\n",
      "     |              `pathlib.Path` objects are now accepted.\n",
      "     |  \n",
      "     |  dumps(...)\n",
      "     |      a.dumps()\n",
      "     |      \n",
      "     |      Returns the pickle of the array as a string.\n",
      "     |      pickle.loads or numpy.loads will convert the string back to an array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |  \n",
      "     |  fill(...)\n",
      "     |      a.fill(value)\n",
      "     |      \n",
      "     |      Fill the array with a scalar value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar\n",
      "     |          All elements of `a` will be assigned this value.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([1, 2])\n",
      "     |      >>> a.fill(0)\n",
      "     |      >>> a\n",
      "     |      array([0, 0])\n",
      "     |      >>> a = np.empty(2)\n",
      "     |      >>> a.fill(1)\n",
      "     |      >>> a\n",
      "     |      array([1.,  1.])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      a.flatten(order='C')\n",
      "     |      \n",
      "     |      Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          'C' means to flatten in row-major (C-style) order.\n",
      "     |          'F' means to flatten in column-major (Fortran-\n",
      "     |          style) order. 'A' means to flatten in column-major\n",
      "     |          order if `a` is Fortran *contiguous* in memory,\n",
      "     |          row-major order otherwise. 'K' means to flatten\n",
      "     |          `a` in the order the elements occur in memory.\n",
      "     |          The default is 'C'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : ndarray\n",
      "     |          A copy of the input array, flattened to one dimension.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ravel : Return a flattened array.\n",
      "     |      flat : A 1-D flat iterator over the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,2], [3,4]])\n",
      "     |      >>> a.flatten()\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |      >>> a.flatten('F')\n",
      "     |      array([1, 3, 2, 4])\n",
      "     |  \n",
      "     |  getfield(...)\n",
      "     |      a.getfield(dtype, offset=0)\n",
      "     |      \n",
      "     |      Returns a field of the given array as a certain type.\n",
      "     |      \n",
      "     |      A field is a view of the array data with a given data-type. The values in\n",
      "     |      the view are determined by the given type and the offset into the current\n",
      "     |      array in bytes. The offset needs to be such that the view dtype fits in the\n",
      "     |      array dtype; for example an array of dtype complex128 has 16-byte elements.\n",
      "     |      If taking a view with a 32-bit integer (4 bytes), the offset needs to be\n",
      "     |      between 0 and 12 bytes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          The data type of the view. The dtype size of the view can not be larger\n",
      "     |          than that of the array itself.\n",
      "     |      offset : int\n",
      "     |          Number of bytes to skip before beginning the element view.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.diag([1.+1.j]*2)\n",
      "     |      >>> x[1, 1] = 2 + 4.j\n",
      "     |      >>> x\n",
      "     |      array([[1.+1.j,  0.+0.j],\n",
      "     |             [0.+0.j,  2.+4.j]])\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[1.,  0.],\n",
      "     |             [0.,  2.]])\n",
      "     |      \n",
      "     |      By choosing an offset of 8 bytes we can select the complex part of the\n",
      "     |      array for our view:\n",
      "     |      \n",
      "     |      >>> x.getfield(np.float64, offset=8)\n",
      "     |      array([[1.,  0.],\n",
      "     |             [0.,  4.]])\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      a.item(*args)\n",
      "     |      \n",
      "     |      Copy an element of an array to a standard Python scalar and return it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments (variable number and type)\n",
      "     |      \n",
      "     |          * none: in this case, the method only works for arrays\n",
      "     |            with one element (`a.size == 1`), which element is\n",
      "     |            copied into a standard Python scalar object and returned.\n",
      "     |      \n",
      "     |          * int_type: this argument is interpreted as a flat index into\n",
      "     |            the array, specifying which element to copy and return.\n",
      "     |      \n",
      "     |          * tuple of int_types: functions as does a single int_type argument,\n",
      "     |            except that the argument is interpreted as an nd-index into the\n",
      "     |            array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      z : Standard Python scalar object\n",
      "     |          A copy of the specified element of the array as a suitable\n",
      "     |          Python scalar\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When the data type of `a` is longdouble or clongdouble, item() returns\n",
      "     |      a scalar array object because there is no available Python scalar that\n",
      "     |      would not lose information. Void arrays return a buffer object for item(),\n",
      "     |      unless fields are defined, in which case a tuple is returned.\n",
      "     |      \n",
      "     |      `item` is very similar to a[args], except, instead of an array scalar,\n",
      "     |      a standard Python scalar is returned. This can be useful for speeding up\n",
      "     |      access to elements of the array and doing arithmetic on elements of the\n",
      "     |      array using Python's optimized math.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.seed(123)\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[2, 2, 6],\n",
      "     |             [1, 3, 6],\n",
      "     |             [1, 0, 1]])\n",
      "     |      >>> x.item(3)\n",
      "     |      1\n",
      "     |      >>> x.item(7)\n",
      "     |      0\n",
      "     |      >>> x.item((0, 1))\n",
      "     |      2\n",
      "     |      >>> x.item((2, 2))\n",
      "     |      1\n",
      "     |  \n",
      "     |  itemset(...)\n",
      "     |      a.itemset(*args)\n",
      "     |      \n",
      "     |      Insert scalar into an array (scalar is cast to array's dtype, if possible)\n",
      "     |      \n",
      "     |      There must be at least 1 argument, and define the last argument\n",
      "     |      as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster\n",
      "     |      than ``a[args] = item``.  The item should be a scalar value and `args`\n",
      "     |      must select a single item in the array `a`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments\n",
      "     |          If one argument: a scalar, only used in case `a` is of size 1.\n",
      "     |          If two arguments: the last argument is the value to be set\n",
      "     |          and must be a scalar, the first argument specifies a single array\n",
      "     |          element location. It is either an int or a tuple.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Compared to indexing syntax, `itemset` provides some speed increase\n",
      "     |      for placing a scalar into a particular location in an `ndarray`,\n",
      "     |      if you must do this.  However, generally this is discouraged:\n",
      "     |      among other problems, it complicates the appearance of the code.\n",
      "     |      Also, when using `itemset` (and `item`) inside a loop, be sure\n",
      "     |      to assign the methods to a local variable to avoid the attribute\n",
      "     |      look-up at each loop iteration.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.seed(123)\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[2, 2, 6],\n",
      "     |             [1, 3, 6],\n",
      "     |             [1, 0, 1]])\n",
      "     |      >>> x.itemset(4, 0)\n",
      "     |      >>> x.itemset((2, 2), 9)\n",
      "     |      >>> x\n",
      "     |      array([[2, 2, 6],\n",
      "     |             [1, 0, 6],\n",
      "     |             [1, 0, 9]])\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      a.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n",
      "     |      \n",
      "     |      Return the maximum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amax : equivalent function\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      a.mean(axis=None, dtype=None, out=None, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns the average of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.mean` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.mean : equivalent function\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      a.min(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n",
      "     |      \n",
      "     |      Return the minimum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amin` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amin : equivalent function\n",
      "     |  \n",
      "     |  newbyteorder(...)\n",
      "     |      arr.newbyteorder(new_order='S', /)\n",
      "     |      \n",
      "     |      Return the array with the same data viewed with a different byte order.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          arr.view(arr.dtype.newbytorder(new_order))\n",
      "     |      \n",
      "     |      Changes are also made in all fields and sub-arrays of the array data\n",
      "     |      type.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_order : string, optional\n",
      "     |          Byte order to force; a value from the byte order specifications\n",
      "     |          below. `new_order` codes can be any of:\n",
      "     |      \n",
      "     |          * 'S' - swap dtype from current to opposite endian\n",
      "     |          * {'<', 'little'} - little endian\n",
      "     |          * {'>', 'big'} - big endian\n",
      "     |          * '=' - native order, equivalent to `sys.byteorder`\n",
      "     |          * {'|', 'I'} - ignore (no change to byte order)\n",
      "     |      \n",
      "     |          The default value ('S') results in swapping the current\n",
      "     |          byte order.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      new_arr : array\n",
      "     |          New array object with the dtype reflecting given change to the\n",
      "     |          byte order.\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      a.nonzero()\n",
      "     |      \n",
      "     |      Return the indices of the elements that are non-zero.\n",
      "     |      \n",
      "     |      Refer to `numpy.nonzero` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.nonzero : equivalent function\n",
      "     |  \n",
      "     |  partition(...)\n",
      "     |      a.partition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Rearranges the elements in the array in such a way that the value of the\n",
      "     |      element in kth position is in the position it would be in a sorted array.\n",
      "     |      All elements smaller than the kth element are moved before this element and\n",
      "     |      all equal or greater are moved behind it. The ordering of the elements in\n",
      "     |      the two partitions is undefined.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kth : int or sequence of ints\n",
      "     |          Element index to partition by. The kth element value will be in its\n",
      "     |          final sorted position and all smaller elements will be moved before it\n",
      "     |          and all equal or greater elements behind it.\n",
      "     |          The order of all elements in the partitions is undefined.\n",
      "     |          If provided with a sequence of kth it will partition all elements\n",
      "     |          indexed by kth of them into their sorted position at once.\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'introselect'}, optional\n",
      "     |          Selection algorithm. Default is 'introselect'.\n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc. A single field can\n",
      "     |          be specified as a string, and not all fields need to be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.partition : Return a parititioned copy of an array.\n",
      "     |      argpartition : Indirect partition.\n",
      "     |      sort : Full sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See ``np.partition`` for notes on the different algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([3, 4, 2, 1])\n",
      "     |      >>> a.partition(3)\n",
      "     |      >>> a\n",
      "     |      array([2, 1, 3, 4])\n",
      "     |      \n",
      "     |      >>> a.partition((1, 3))\n",
      "     |      >>> a\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      a.prod(axis=None, dtype=None, out=None, keepdims=False, initial=1, where=True)\n",
      "     |      \n",
      "     |      Return the product of the array elements over the given axis\n",
      "     |      \n",
      "     |      Refer to `numpy.prod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.prod : equivalent function\n",
      "     |  \n",
      "     |  ptp(...)\n",
      "     |      a.ptp(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Peak to peak (maximum - minimum) value along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.ptp` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ptp : equivalent function\n",
      "     |  \n",
      "     |  put(...)\n",
      "     |      a.put(indices, values, mode='raise')\n",
      "     |      \n",
      "     |      Set ``a.flat[n] = values[n]`` for all `n` in indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.put` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.put : equivalent function\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      a.ravel([order])\n",
      "     |      \n",
      "     |      Return a flattened array.\n",
      "     |      \n",
      "     |      Refer to `numpy.ravel` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ravel : equivalent function\n",
      "     |      \n",
      "     |      ndarray.flat : a flat iterator on the array.\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      a.repeat(repeats, axis=None)\n",
      "     |      \n",
      "     |      Repeat elements of an array.\n",
      "     |      \n",
      "     |      Refer to `numpy.repeat` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.repeat : equivalent function\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      a.reshape(shape, order='C')\n",
      "     |      \n",
      "     |      Returns an array containing the same data with a new shape.\n",
      "     |      \n",
      "     |      Refer to `numpy.reshape` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.reshape : equivalent function\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n",
      "     |      the elements of the shape parameter to be passed in as separate arguments.\n",
      "     |      For example, ``a.reshape(10, 11)`` is equivalent to\n",
      "     |      ``a.reshape((10, 11))``.\n",
      "     |  \n",
      "     |  resize(...)\n",
      "     |      a.resize(new_shape, refcheck=True)\n",
      "     |      \n",
      "     |      Change shape and size of array in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_shape : tuple of ints, or `n` ints\n",
      "     |          Shape of resized array.\n",
      "     |      refcheck : bool, optional\n",
      "     |          If False, reference count will not be checked. Default is True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If `a` does not own its own data or references or views to it exist,\n",
      "     |          and the data memory must be changed.\n",
      "     |          PyPy only: will always raise if the data memory must be changed, since\n",
      "     |          there is no reliable way to determine if references or views to it\n",
      "     |          exist.\n",
      "     |      \n",
      "     |      SystemError\n",
      "     |          If the `order` keyword argument is specified. This behaviour is a\n",
      "     |          bug in NumPy.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      resize : Return a new array with the specified shape.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This reallocates space for the data area if necessary.\n",
      "     |      \n",
      "     |      Only contiguous arrays (data elements consecutive in memory) can be\n",
      "     |      resized.\n",
      "     |      \n",
      "     |      The purpose of the reference count check is to make sure you\n",
      "     |      do not use this array as a buffer for another Python object and then\n",
      "     |      reallocate the memory. However, reference counts can increase in\n",
      "     |      other ways so if you are sure that you have not shared the memory\n",
      "     |      for this array with another Python object, then you may safely set\n",
      "     |      `refcheck` to False.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Shrinking an array: array is flattened (in the order that the data are\n",
      "     |      stored in memory), resized, and reshaped:\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='C')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [1]])\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='F')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [2]])\n",
      "     |      \n",
      "     |      Enlarging an array: as above, but missing entries are filled with zeros:\n",
      "     |      \n",
      "     |      >>> b = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple\n",
      "     |      >>> b\n",
      "     |      array([[0, 1, 2],\n",
      "     |             [3, 0, 0]])\n",
      "     |      \n",
      "     |      Referencing an array prevents resizing...\n",
      "     |      \n",
      "     |      >>> c = a\n",
      "     |      >>> a.resize((1, 1))\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: cannot resize an array that references or is referenced ...\n",
      "     |      \n",
      "     |      Unless `refcheck` is False:\n",
      "     |      \n",
      "     |      >>> a.resize((1, 1), refcheck=False)\n",
      "     |      >>> a\n",
      "     |      array([[0]])\n",
      "     |      >>> c\n",
      "     |      array([[0]])\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      a.round(decimals=0, out=None)\n",
      "     |      \n",
      "     |      Return `a` with each element rounded to the given number of decimals.\n",
      "     |      \n",
      "     |      Refer to `numpy.around` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around : equivalent function\n",
      "     |  \n",
      "     |  searchsorted(...)\n",
      "     |      a.searchsorted(v, side='left', sorter=None)\n",
      "     |      \n",
      "     |      Find indices where elements of v should be inserted in a to maintain order.\n",
      "     |      \n",
      "     |      For full documentation, see `numpy.searchsorted`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.searchsorted : equivalent function\n",
      "     |  \n",
      "     |  setfield(...)\n",
      "     |      a.setfield(val, dtype, offset=0)\n",
      "     |      \n",
      "     |      Put a value into a specified place in a field defined by a data-type.\n",
      "     |      \n",
      "     |      Place `val` into `a`'s field defined by `dtype` and beginning `offset`\n",
      "     |      bytes into the field.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      val : object\n",
      "     |          Value to be placed in field.\n",
      "     |      dtype : dtype object\n",
      "     |          Data-type of the field in which to place `val`.\n",
      "     |      offset : int, optional\n",
      "     |          The number of bytes into the field at which to place `val`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      getfield\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.eye(3)\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[1.,  0.,  0.],\n",
      "     |             [0.,  1.,  0.],\n",
      "     |             [0.,  0.,  1.]])\n",
      "     |      >>> x.setfield(3, np.int32)\n",
      "     |      >>> x.getfield(np.int32)\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3],\n",
      "     |             [3, 3, 3]], dtype=int32)\n",
      "     |      >>> x\n",
      "     |      array([[1.0e+000, 1.5e-323, 1.5e-323],\n",
      "     |             [1.5e-323, 1.0e+000, 1.5e-323],\n",
      "     |             [1.5e-323, 1.5e-323, 1.0e+000]])\n",
      "     |      >>> x.setfield(np.eye(3), np.int32)\n",
      "     |      >>> x\n",
      "     |      array([[1.,  0.,  0.],\n",
      "     |             [0.,  1.,  0.],\n",
      "     |             [0.,  0.,  1.]])\n",
      "     |  \n",
      "     |  setflags(...)\n",
      "     |      a.setflags(write=None, align=None, uic=None)\n",
      "     |      \n",
      "     |      Set array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\n",
      "     |      respectively.\n",
      "     |      \n",
      "     |      These Boolean-valued flags affect how numpy interprets the memory\n",
      "     |      area used by `a` (see Notes below). The ALIGNED flag can only\n",
      "     |      be set to True if the data is actually aligned according to the type.\n",
      "     |      The WRITEBACKIFCOPY and (deprecated) UPDATEIFCOPY flags can never be set\n",
      "     |      to True. The flag WRITEABLE can only be set to True if the array owns its\n",
      "     |      own memory, or the ultimate owner of the memory exposes a writeable buffer\n",
      "     |      interface, or is a string. (The exception for string is made so that\n",
      "     |      unpickling can be done without copying memory.)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      write : bool, optional\n",
      "     |          Describes whether or not `a` can be written to.\n",
      "     |      align : bool, optional\n",
      "     |          Describes whether or not `a` is aligned properly for its type.\n",
      "     |      uic : bool, optional\n",
      "     |          Describes whether or not `a` is a copy of another \"base\" array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Array flags provide information about how the memory area used\n",
      "     |      for the array is to be interpreted. There are 7 Boolean flags\n",
      "     |      in use, only four of which can be changed by the user:\n",
      "     |      WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n",
      "     |      \n",
      "     |      WRITEABLE (W) the data area can be written to;\n",
      "     |      \n",
      "     |      ALIGNED (A) the data and strides are aligned appropriately for the hardware\n",
      "     |      (as determined by the compiler);\n",
      "     |      \n",
      "     |      UPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n",
      "     |      \n",
      "     |      WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced\n",
      "     |      by .base). When the C-API function PyArray_ResolveWritebackIfCopy is\n",
      "     |      called, the base array will be updated with the contents of this array.\n",
      "     |      \n",
      "     |      All flags can be accessed using the single (upper case) letter as well\n",
      "     |      as the full name.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y = np.array([[3, 1, 7],\n",
      "     |      ...               [2, 0, 0],\n",
      "     |      ...               [8, 5, 9]])\n",
      "     |      >>> y\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 0, 0],\n",
      "     |             [8, 5, 9]])\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : True\n",
      "     |        ALIGNED : True\n",
      "     |        WRITEBACKIFCOPY : False\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(write=0, align=0)\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : False\n",
      "     |        ALIGNED : False\n",
      "     |        WRITEBACKIFCOPY : False\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(uic=1)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: cannot set WRITEBACKIFCOPY flag to True\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      a.sort(axis=-1, kind=None, order=None)\n",
      "     |      \n",
      "     |      Sort an array in-place. Refer to `numpy.sort` for full documentation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n",
      "     |          Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n",
      "     |          and 'mergesort' use timsort under the covers and, in general, the\n",
      "     |          actual implementation will vary with datatype. The 'mergesort' option\n",
      "     |          is retained for backwards compatibility.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.15.0\n",
      "     |             The 'stable' option was added.\n",
      "     |      \n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc.  A single field can\n",
      "     |          be specified as a string, and not all fields need be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sort : Return a sorted copy of an array.\n",
      "     |      numpy.argsort : Indirect sort.\n",
      "     |      numpy.lexsort : Indirect stable sort on multiple keys.\n",
      "     |      numpy.searchsorted : Find elements in sorted array.\n",
      "     |      numpy.partition: Partial sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See `numpy.sort` for notes on the different sorting algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,4], [3,1]])\n",
      "     |      >>> a.sort(axis=1)\n",
      "     |      >>> a\n",
      "     |      array([[1, 4],\n",
      "     |             [1, 3]])\n",
      "     |      >>> a.sort(axis=0)\n",
      "     |      >>> a\n",
      "     |      array([[1, 3],\n",
      "     |             [1, 4]])\n",
      "     |      \n",
      "     |      Use the `order` keyword to specify a field to use when sorting a\n",
      "     |      structured array:\n",
      "     |      \n",
      "     |      >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\n",
      "     |      >>> a.sort(order='y')\n",
      "     |      >>> a\n",
      "     |      array([(b'c', 1), (b'a', 2)],\n",
      "     |            dtype=[('x', 'S1'), ('y', '<i8')])\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      a.squeeze(axis=None)\n",
      "     |      \n",
      "     |      Remove axes of length one from `a`.\n",
      "     |      \n",
      "     |      Refer to `numpy.squeeze` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.squeeze : equivalent function\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      a.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns the standard deviation of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.std` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.std : equivalent function\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      a.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)\n",
      "     |      \n",
      "     |      Return the sum of the array elements over the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.sum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sum : equivalent function\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      a.swapaxes(axis1, axis2)\n",
      "     |      \n",
      "     |      Return a view of the array with `axis1` and `axis2` interchanged.\n",
      "     |      \n",
      "     |      Refer to `numpy.swapaxes` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.swapaxes : equivalent function\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      a.take(indices, axis=None, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Return an array formed from the elements of `a` at the given indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.take` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.take : equivalent function\n",
      "     |  \n",
      "     |  tobytes(...)\n",
      "     |      a.tobytes(order='C')\n",
      "     |      \n",
      "     |      Construct Python bytes containing the raw data bytes in the array.\n",
      "     |      \n",
      "     |      Constructs Python bytes showing a copy of the raw contents of\n",
      "     |      data memory. The bytes object is produced in C-order by default.\n",
      "     |      This behavior is controlled by the ``order`` parameter.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.9.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A'}, optional\n",
      "     |          Controls the memory layout of the bytes object. 'C' means C-order,\n",
      "     |          'F' means F-order, 'A' (short for *Any*) means 'F' if `a` is\n",
      "     |          Fortran contiguous, 'C' otherwise. Default is 'C'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : bytes\n",
      "     |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]], dtype='<u2')\n",
      "     |      >>> x.tobytes()\n",
      "     |      b'\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00'\n",
      "     |      >>> x.tobytes('C') == x.tobytes()\n",
      "     |      True\n",
      "     |      >>> x.tobytes('F')\n",
      "     |      b'\\x00\\x00\\x02\\x00\\x01\\x00\\x03\\x00'\n",
      "     |  \n",
      "     |  tofile(...)\n",
      "     |      a.tofile(fid, sep=\"\", format=\"%s\")\n",
      "     |      \n",
      "     |      Write array to a file as text or binary (default).\n",
      "     |      \n",
      "     |      Data is always written in 'C' order, independent of the order of `a`.\n",
      "     |      The data produced by this method can be recovered using the function\n",
      "     |      fromfile().\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fid : file or str or Path\n",
      "     |          An open file object, or a string containing a filename.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.17.0\n",
      "     |              `pathlib.Path` objects are now accepted.\n",
      "     |      \n",
      "     |      sep : str\n",
      "     |          Separator between array items for text output.\n",
      "     |          If \"\" (empty), a binary file is written, equivalent to\n",
      "     |          ``file.write(a.tobytes())``.\n",
      "     |      format : str\n",
      "     |          Format string for text file output.\n",
      "     |          Each entry in the array is formatted to text by first converting\n",
      "     |          it to the closest Python type, and then using \"format\" % item.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a convenience function for quick storage of array data.\n",
      "     |      Information on endianness and precision is lost, so this method is not a\n",
      "     |      good choice for files intended to archive data or transport data between\n",
      "     |      machines with different endianness. Some of these problems can be overcome\n",
      "     |      by outputting the data as text files, at the expense of speed and file\n",
      "     |      size.\n",
      "     |      \n",
      "     |      When fid is a file object, array contents are directly written to the\n",
      "     |      file, bypassing the file object's ``write`` method. As a result, tofile\n",
      "     |      cannot be used with files objects supporting compression (e.g., GzipFile)\n",
      "     |      or file-like objects that do not support ``fileno()`` (e.g., BytesIO).\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      a.tolist()\n",
      "     |      \n",
      "     |      Return the array as an ``a.ndim``-levels deep nested list of Python scalars.\n",
      "     |      \n",
      "     |      Return a copy of the array data as a (nested) Python list.\n",
      "     |      Data items are converted to the nearest compatible builtin Python type, via\n",
      "     |      the `~numpy.ndarray.item` function.\n",
      "     |      \n",
      "     |      If ``a.ndim`` is 0, then since the depth of the nested list is 0, it will\n",
      "     |      not be a list at all, but a simple Python scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      none\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : object, or list of object, or list of list of object, or ...\n",
      "     |          The possibly nested list of array elements.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The array may be recreated via ``a = np.array(a.tolist())``, although this\n",
      "     |      may sometimes lose precision.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      For a 1D array, ``a.tolist()`` is almost the same as ``list(a)``,\n",
      "     |      except that ``tolist`` changes numpy scalars to Python scalars:\n",
      "     |      \n",
      "     |      >>> a = np.uint32([1, 2])\n",
      "     |      >>> a_list = list(a)\n",
      "     |      >>> a_list\n",
      "     |      [1, 2]\n",
      "     |      >>> type(a_list[0])\n",
      "     |      <class 'numpy.uint32'>\n",
      "     |      >>> a_tolist = a.tolist()\n",
      "     |      >>> a_tolist\n",
      "     |      [1, 2]\n",
      "     |      >>> type(a_tolist[0])\n",
      "     |      <class 'int'>\n",
      "     |      \n",
      "     |      Additionally, for a 2D array, ``tolist`` applies recursively:\n",
      "     |      \n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> list(a)\n",
      "     |      [array([1, 2]), array([3, 4])]\n",
      "     |      >>> a.tolist()\n",
      "     |      [[1, 2], [3, 4]]\n",
      "     |      \n",
      "     |      The base case for this recursion is a 0D array:\n",
      "     |      \n",
      "     |      >>> a = np.array(1)\n",
      "     |      >>> list(a)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: iteration over a 0-d array\n",
      "     |      >>> a.tolist()\n",
      "     |      1\n",
      "     |  \n",
      "     |  tostring(...)\n",
      "     |      a.tostring(order='C')\n",
      "     |      \n",
      "     |      A compatibility alias for `tobytes`, with exactly the same behavior.\n",
      "     |      \n",
      "     |      Despite its name, it returns `bytes` not `str`\\ s.\n",
      "     |      \n",
      "     |      .. deprecated:: 1.19.0\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the sum along diagonals of the array.\n",
      "     |      \n",
      "     |      Refer to `numpy.trace` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.trace : equivalent function\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      a.transpose(*axes)\n",
      "     |      \n",
      "     |      Returns a view of the array with axes transposed.\n",
      "     |      \n",
      "     |      For a 1-D array this has no effect, as a transposed vector is simply the\n",
      "     |      same vector. To convert a 1-D array into a 2D column vector, an additional\n",
      "     |      dimension must be added. `np.atleast2d(a).T` achieves this, as does\n",
      "     |      `a[:, np.newaxis]`.\n",
      "     |      For a 2-D array, this is a standard matrix transpose.\n",
      "     |      For an n-D array, if axes are given, their order indicates how the\n",
      "     |      axes are permuted (see Examples). If axes are not provided and\n",
      "     |      ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then\n",
      "     |      ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axes : None, tuple of ints, or `n` ints\n",
      "     |      \n",
      "     |       * None or no argument: reverses the order of the axes.\n",
      "     |      \n",
      "     |       * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s\n",
      "     |         `i`-th axis becomes `a.transpose()`'s `j`-th axis.\n",
      "     |      \n",
      "     |       * `n` ints: same as an n-tuple of the same ints (this form is\n",
      "     |         intended simply as a \"convenience\" alternative to the tuple form)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          View of `a`, with axes suitably permuted.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transpose : Equivalent function\n",
      "     |      ndarray.T : Array property returning the array transposed.\n",
      "     |      ndarray.reshape : Give a new shape to an array without changing its data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> a\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]])\n",
      "     |      >>> a.transpose()\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose((1, 0))\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose(1, 0)\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      a.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n",
      "     |      \n",
      "     |      Returns the variance of the array elements, along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.var` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.var : equivalent function\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      a.view([dtype][, type])\n",
      "     |      \n",
      "     |      New view of array with the same data.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          Passing None for ``dtype`` is different from omitting the parameter,\n",
      "     |          since the former invokes ``dtype(None)`` which is an alias for\n",
      "     |          ``dtype('float_')``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data-type or ndarray sub-class, optional\n",
      "     |          Data-type descriptor of the returned view, e.g., float32 or int16.\n",
      "     |          Omitting it results in the view having the same data-type as `a`.\n",
      "     |          This argument can also be specified as an ndarray sub-class, which\n",
      "     |          then specifies the type of the returned object (this is equivalent to\n",
      "     |          setting the ``type`` parameter).\n",
      "     |      type : Python type, optional\n",
      "     |          Type of the returned view, e.g., ndarray or matrix.  Again, omission\n",
      "     |          of the parameter results in type preservation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      ``a.view()`` is used two different ways:\n",
      "     |      \n",
      "     |      ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view\n",
      "     |      of the array's memory with a different data-type.  This can cause a\n",
      "     |      reinterpretation of the bytes of memory.\n",
      "     |      \n",
      "     |      ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just\n",
      "     |      returns an instance of `ndarray_subclass` that looks at the same array\n",
      "     |      (same shape, dtype, etc.)  This does not cause a reinterpretation of the\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of\n",
      "     |      bytes per entry than the previous dtype (for example, converting a\n",
      "     |      regular array to a structured array), then the behavior of the view\n",
      "     |      cannot be predicted just from the superficial appearance of ``a`` (shown\n",
      "     |      by ``print(a)``). It also depends on exactly how ``a`` is stored in\n",
      "     |      memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus\n",
      "     |      defined as a slice or transpose, etc., the view may give different\n",
      "     |      results.\n",
      "     |      \n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      \n",
      "     |      Viewing array data using a different type and dtype:\n",
      "     |      \n",
      "     |      >>> y = x.view(dtype=np.int16, type=np.matrix)\n",
      "     |      >>> y\n",
      "     |      matrix([[513]], dtype=int16)\n",
      "     |      >>> print(type(y))\n",
      "     |      <class 'numpy.matrix'>\n",
      "     |      \n",
      "     |      Creating a view on a structured array so it can be used in calculations\n",
      "     |      \n",
      "     |      >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      >>> xv = x.view(dtype=np.int8).reshape(-1,2)\n",
      "     |      >>> xv\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]], dtype=int8)\n",
      "     |      >>> xv.mean(0)\n",
      "     |      array([2.,  3.])\n",
      "     |      \n",
      "     |      Making changes to the view changes the underlying array\n",
      "     |      \n",
      "     |      >>> xv[0,1] = 20\n",
      "     |      >>> x\n",
      "     |      array([(1, 20), (3,  4)], dtype=[('a', 'i1'), ('b', 'i1')])\n",
      "     |      \n",
      "     |      Using a view to convert an array to a recarray:\n",
      "     |      \n",
      "     |      >>> z = x.view(np.recarray)\n",
      "     |      >>> z.a\n",
      "     |      array([1, 3], dtype=int8)\n",
      "     |      \n",
      "     |      Views share data:\n",
      "     |      \n",
      "     |      >>> x[0] = (9, 10)\n",
      "     |      >>> z[0]\n",
      "     |      (9, 10)\n",
      "     |      \n",
      "     |      Views that change the dtype size (bytes per entry) should normally be\n",
      "     |      avoided on arrays defined by slices, transposes, fortran-ordering, etc.:\n",
      "     |      \n",
      "     |      >>> x = np.array([[1,2,3],[4,5,6]], dtype=np.int16)\n",
      "     |      >>> y = x[:, 0:2]\n",
      "     |      >>> y\n",
      "     |      array([[1, 2],\n",
      "     |             [4, 5]], dtype=int16)\n",
      "     |      >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      ValueError: To change to a dtype of a different size, the array must be C-contiguous\n",
      "     |      >>> z = y.copy()\n",
      "     |      >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      array([[(1, 2)],\n",
      "     |             [(4, 5)]], dtype=[('width', '<i2'), ('length', '<i2')])\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  T\n",
      "     |      The transposed array.\n",
      "     |      \n",
      "     |      Same as ``self.transpose()``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[1.,2.],[3.,4.]])\n",
      "     |      >>> x\n",
      "     |      array([[ 1.,  2.],\n",
      "     |             [ 3.,  4.]])\n",
      "     |      >>> x.T\n",
      "     |      array([[ 1.,  3.],\n",
      "     |             [ 2.,  4.]])\n",
      "     |      >>> x = np.array([1.,2.,3.,4.])\n",
      "     |      >>> x\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |      >>> x.T\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transpose\n",
      "     |  \n",
      "     |  __array_interface__\n",
      "     |      Array protocol: Python side.\n",
      "     |  \n",
      "     |  __array_priority__\n",
      "     |      Array priority.\n",
      "     |  \n",
      "     |  __array_struct__\n",
      "     |      Array protocol: C-struct side.\n",
      "     |  \n",
      "     |  base\n",
      "     |      Base object if memory is from some other object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      The base of an array that owns its memory is None:\n",
      "     |      \n",
      "     |      >>> x = np.array([1,2,3,4])\n",
      "     |      >>> x.base is None\n",
      "     |      True\n",
      "     |      \n",
      "     |      Slicing creates a view, whose memory is shared with x:\n",
      "     |      \n",
      "     |      >>> y = x[2:]\n",
      "     |      >>> y.base is x\n",
      "     |      True\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      An object to simplify the interaction of the array with the ctypes\n",
      "     |      module.\n",
      "     |      \n",
      "     |      This attribute creates an object that makes it easier to use arrays\n",
      "     |      when calling shared libraries with the ctypes module. The returned\n",
      "     |      object has, among others, data, shape, and strides attributes (see\n",
      "     |      Notes below) which themselves return ctypes objects that can be used\n",
      "     |      as arguments to a shared library.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      c : Python object\n",
      "     |          Possessing attributes data, shape, strides, etc.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ctypeslib\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Below are the public attributes of this object which were documented\n",
      "     |      in \"Guide to NumPy\" (we have omitted undocumented public attributes,\n",
      "     |      as well as documented private attributes):\n",
      "     |      \n",
      "     |      .. autoattribute:: numpy.core._internal._ctypes.data\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. autoattribute:: numpy.core._internal._ctypes.shape\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. autoattribute:: numpy.core._internal._ctypes.strides\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. automethod:: numpy.core._internal._ctypes.data_as\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. automethod:: numpy.core._internal._ctypes.shape_as\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      .. automethod:: numpy.core._internal._ctypes.strides_as\n",
      "     |          :noindex:\n",
      "     |      \n",
      "     |      If the ctypes module is not available, then the ctypes attribute\n",
      "     |      of array objects still returns something useful, but ctypes objects\n",
      "     |      are not returned and errors may be raised instead. In particular,\n",
      "     |      the object will still have the ``as_parameter`` attribute which will\n",
      "     |      return an integer equal to the data attribute.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import ctypes\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32)\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]], dtype=int32)\n",
      "     |      >>> x.ctypes.data\n",
      "     |      31962608 # may vary\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32))\n",
      "     |      <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents\n",
      "     |      c_uint(0)\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents\n",
      "     |      c_ulong(4294967296)\n",
      "     |      >>> x.ctypes.shape\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary\n",
      "     |      >>> x.ctypes.strides\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Data-type of the array's elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      d : numpy dtype object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dtype\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]])\n",
      "     |      >>> x.dtype\n",
      "     |      dtype('int32')\n",
      "     |      >>> type(x.dtype)\n",
      "     |      <type 'numpy.dtype'>\n",
      "     |  \n",
      "     |  flags\n",
      "     |      Information about the memory layout of the array.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      C_CONTIGUOUS (C)\n",
      "     |          The data is in a single, C-style contiguous segment.\n",
      "     |      F_CONTIGUOUS (F)\n",
      "     |          The data is in a single, Fortran-style contiguous segment.\n",
      "     |      OWNDATA (O)\n",
      "     |          The array owns the memory it uses or borrows it from another object.\n",
      "     |      WRITEABLE (W)\n",
      "     |          The data area can be written to.  Setting this to False locks\n",
      "     |          the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE\n",
      "     |          from its base array at creation time, but a view of a writeable\n",
      "     |          array may be subsequently locked while the base array remains writeable.\n",
      "     |          (The opposite is not true, in that a view of a locked array may not\n",
      "     |          be made writeable.  However, currently, locking a base object does not\n",
      "     |          lock any views that already reference it, so under that circumstance it\n",
      "     |          is possible to alter the contents of a locked array via a previously\n",
      "     |          created writeable view onto it.)  Attempting to change a non-writeable\n",
      "     |          array raises a RuntimeError exception.\n",
      "     |      ALIGNED (A)\n",
      "     |          The data and all elements are aligned appropriately for the hardware.\n",
      "     |      WRITEBACKIFCOPY (X)\n",
      "     |          This array is a copy of some other array. The C-API function\n",
      "     |          PyArray_ResolveWritebackIfCopy must be called before deallocating\n",
      "     |          to the base array will be updated with the contents of this array.\n",
      "     |      UPDATEIFCOPY (U)\n",
      "     |          (Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\n",
      "     |          When this array is\n",
      "     |          deallocated, the base array will be updated with the contents of\n",
      "     |          this array.\n",
      "     |      FNC\n",
      "     |          F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      FORC\n",
      "     |          F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n",
      "     |      BEHAVED (B)\n",
      "     |          ALIGNED and WRITEABLE.\n",
      "     |      CARRAY (CA)\n",
      "     |          BEHAVED and C_CONTIGUOUS.\n",
      "     |      FARRAY (FA)\n",
      "     |          BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),\n",
      "     |      or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag\n",
      "     |      names are only supported in dictionary access.\n",
      "     |      \n",
      "     |      Only the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\n",
      "     |      changed by the user, via direct assignment to the attribute or dictionary\n",
      "     |      entry, or by calling `ndarray.setflags`.\n",
      "     |      \n",
      "     |      The array flags cannot be set arbitrarily:\n",
      "     |      \n",
      "     |      - UPDATEIFCOPY can only be set ``False``.\n",
      "     |      - WRITEBACKIFCOPY can only be set ``False``.\n",
      "     |      - ALIGNED can only be set ``True`` if the data is truly aligned.\n",
      "     |      - WRITEABLE can only be set ``True`` if the array owns its own memory\n",
      "     |        or the ultimate owner of the memory exposes a writeable buffer\n",
      "     |        interface or is a string.\n",
      "     |      \n",
      "     |      Arrays can be both C-style and Fortran-style contiguous simultaneously.\n",
      "     |      This is clear for 1-dimensional arrays, but can also be true for higher\n",
      "     |      dimensional arrays.\n",
      "     |      \n",
      "     |      Even for contiguous arrays a stride for a given dimension\n",
      "     |      ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``\n",
      "     |      or the array has no elements.\n",
      "     |      It does *not* generally hold that ``self.strides[-1] == self.itemsize``\n",
      "     |      for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for\n",
      "     |      Fortran-style contiguous arrays is true.\n",
      "     |  \n",
      "     |  flat\n",
      "     |      A 1-D iterator over the array.\n",
      "     |      \n",
      "     |      This is a `numpy.flatiter` instance, which acts similarly to, but is not\n",
      "     |      a subclass of, Python's built-in iterator object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      flatten : Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      flatiter\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.arange(1, 7).reshape(2, 3)\n",
      "     |      >>> x\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]])\n",
      "     |      >>> x.flat[3]\n",
      "     |      4\n",
      "     |      >>> x.T\n",
      "     |      array([[1, 4],\n",
      "     |             [2, 5],\n",
      "     |             [3, 6]])\n",
      "     |      >>> x.T.flat[3]\n",
      "     |      5\n",
      "     |      >>> type(x.flat)\n",
      "     |      <class 'numpy.flatiter'>\n",
      "     |      \n",
      "     |      An assignment example:\n",
      "     |      \n",
      "     |      >>> x.flat = 3; x\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3]])\n",
      "     |      >>> x.flat[[1,4]] = 1; x\n",
      "     |      array([[3, 1, 3],\n",
      "     |             [3, 1, 3]])\n",
      "     |  \n",
      "     |  imag\n",
      "     |      The imaginary part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.imag\n",
      "     |      array([ 0.        ,  0.70710678])\n",
      "     |      >>> x.imag.dtype\n",
      "     |      dtype('float64')\n",
      "     |  \n",
      "     |  itemsize\n",
      "     |      Length of one array element in bytes.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.float64)\n",
      "     |      >>> x.itemsize\n",
      "     |      8\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.complex128)\n",
      "     |      >>> x.itemsize\n",
      "     |      16\n",
      "     |  \n",
      "     |  nbytes\n",
      "     |      Total bytes consumed by the elements of the array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Does not include memory consumed by non-element attributes of the\n",
      "     |      array object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3,5,2), dtype=np.complex128)\n",
      "     |      >>> x.nbytes\n",
      "     |      480\n",
      "     |      >>> np.prod(x.shape) * x.itemsize\n",
      "     |      480\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Number of array dimensions.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3])\n",
      "     |      >>> x.ndim\n",
      "     |      1\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.ndim\n",
      "     |      3\n",
      "     |  \n",
      "     |  real\n",
      "     |      The real part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.real\n",
      "     |      array([ 1.        ,  0.70710678])\n",
      "     |      >>> x.real.dtype\n",
      "     |      dtype('float64')\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.real : equivalent function\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Tuple of array dimensions.\n",
      "     |      \n",
      "     |      The shape property is usually used to get the current shape of an array,\n",
      "     |      but may also be used to reshape the array in-place by assigning a tuple of\n",
      "     |      array dimensions to it.  As with `numpy.reshape`, one of the new shape\n",
      "     |      dimensions can be -1, in which case its value is inferred from the size of\n",
      "     |      the array and the remaining dimensions. Reshaping an array in-place will\n",
      "     |      fail if a copy is required.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3, 4])\n",
      "     |      >>> x.shape\n",
      "     |      (4,)\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.shape\n",
      "     |      (2, 3, 4)\n",
      "     |      >>> y.shape = (3, 8)\n",
      "     |      >>> y\n",
      "     |      array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "     |      >>> y.shape = (3, 6)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: total size of new array must be unchanged\n",
      "     |      >>> np.zeros((4,2))[::2].shape = (-1,)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      AttributeError: Incompatible shape for in-place modification. Use\n",
      "     |      `.reshape()` to make a copy with the desired shape.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.reshape : similar function\n",
      "     |      ndarray.reshape : similar method\n",
      "     |  \n",
      "     |  size\n",
      "     |      Number of elements in the array.\n",
      "     |      \n",
      "     |      Equal to ``np.prod(a.shape)``, i.e., the product of the array's\n",
      "     |      dimensions.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `a.size` returns a standard arbitrary precision Python integer. This\n",
      "     |      may not be the case with other methods of obtaining the same value\n",
      "     |      (like the suggested ``np.prod(a.shape)``, which returns an instance\n",
      "     |      of ``np.int_``), and may be relevant if the value is used further in\n",
      "     |      calculations that may overflow a fixed size integer type.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3, 5, 2), dtype=np.complex128)\n",
      "     |      >>> x.size\n",
      "     |      30\n",
      "     |      >>> np.prod(x.shape)\n",
      "     |      30\n",
      "     |  \n",
      "     |  strides\n",
      "     |      Tuple of bytes to step in each dimension when traversing an array.\n",
      "     |      \n",
      "     |      The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`\n",
      "     |      is::\n",
      "     |      \n",
      "     |          offset = sum(np.array(i) * a.strides)\n",
      "     |      \n",
      "     |      A more detailed explanation of strides can be found in the\n",
      "     |      \"ndarray.rst\" file in the NumPy reference guide.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Imagine an array of 32-bit integers (each 4 bytes)::\n",
      "     |      \n",
      "     |        x = np.array([[0, 1, 2, 3, 4],\n",
      "     |                      [5, 6, 7, 8, 9]], dtype=np.int32)\n",
      "     |      \n",
      "     |      This array is stored in memory as 40 bytes, one after the other\n",
      "     |      (known as a contiguous block of memory).  The strides of an array tell\n",
      "     |      us how many bytes we have to skip in memory to move to the next position\n",
      "     |      along a certain axis.  For example, we have to skip 4 bytes (1 value) to\n",
      "     |      move to the next column, but 20 bytes (5 values) to get to the same\n",
      "     |      position in the next row.  As such, the strides for the array `x` will be\n",
      "     |      ``(20, 4)``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.lib.stride_tricks.as_strided\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y = np.reshape(np.arange(2*3*4), (2,3,4))\n",
      "     |      >>> y\n",
      "     |      array([[[ 0,  1,  2,  3],\n",
      "     |              [ 4,  5,  6,  7],\n",
      "     |              [ 8,  9, 10, 11]],\n",
      "     |             [[12, 13, 14, 15],\n",
      "     |              [16, 17, 18, 19],\n",
      "     |              [20, 21, 22, 23]]])\n",
      "     |      >>> y.strides\n",
      "     |      (48, 16, 4)\n",
      "     |      >>> y[1,1,1]\n",
      "     |      17\n",
      "     |      >>> offset=sum(y.strides * np.array((1,1,1)))\n",
      "     |      >>> offset/y.itemsize\n",
      "     |      17\n",
      "     |      \n",
      "     |      >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)\n",
      "     |      >>> x.strides\n",
      "     |      (32, 4, 224, 1344)\n",
      "     |      >>> i = np.array([3,5,2,2])\n",
      "     |      >>> offset = sum(i * x.strides)\n",
      "     |      >>> x[3,5,2,2]\n",
      "     |      813\n",
      "     |      >>> offset / x.itemsize\n",
      "     |      813\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class GroupsHDU(astropy.io.fits.hdu.image.PrimaryHDU, astropy.io.fits.hdu.table._TableLikeHDU)\n",
      "     |  GroupsHDU(data=None, header=None)\n",
      "     |  \n",
      "     |  FITS Random Groups HDU class.\n",
      "     |  \n",
      "     |  See the :ref:`random-groups` section in the Astropy documentation for more\n",
      "     |  details on working with this type of HDU.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupsHDU\n",
      "     |      astropy.io.fits.hdu.image.PrimaryHDU\n",
      "     |      astropy.io.fits.hdu.image._ImageBaseHDU\n",
      "     |      astropy.io.fits.hdu.table._TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None)\n",
      "     |      Construct a primary HDU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array or ``astropy.io.fits.hdu.base.DELAYED``, optional\n",
      "     |          The data in the HDU.\n",
      "     |      \n",
      "     |      header : `~astropy.io.fits.Header`, optional\n",
      "     |          The header to be used (as a template).  If ``header`` is `None`, a\n",
      "     |          minimal header will be provided.\n",
      "     |      \n",
      "     |      do_not_scale_image_data : bool, optional\n",
      "     |          If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "     |          when read. (default: False)\n",
      "     |      \n",
      "     |      ignore_blank : bool, optional\n",
      "     |          If `True`, the BLANK header keyword will be ignored if present.\n",
      "     |          Otherwise, pixels equal to this value will be replaced with\n",
      "     |          NaNs. (default: False)\n",
      "     |      \n",
      "     |      uint : bool, optional\n",
      "     |          Interpret signed integer data where ``BZERO`` is the\n",
      "     |          central value and ``BSCALE == 1`` as unsigned integer\n",
      "     |          data.  For example, ``int16`` data with ``BZERO = 32768``\n",
      "     |          and ``BSCALE = 1`` would be treated as ``uint16`` data.\n",
      "     |          (default: True)\n",
      "     |      \n",
      "     |      scale_back : bool, optional\n",
      "     |          If `True`, when saving changes to a file that contained scaled\n",
      "     |          image data, restore the data to the original type and reapply the\n",
      "     |          original BSCALE/BZERO values.  This could lead to loss of accuracy\n",
      "     |          if scaling back to integer values after performing floating point\n",
      "     |          operations on the data.  Pseudo-unsigned integers are automatically\n",
      "     |          rescaled unless scale_back is explicitly set to `False`.\n",
      "     |          (default: None)\n",
      "     |  \n",
      "     |  update_header(self)\n",
      "     |      Update the header keywords to agree with the data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      _ImageBaseHDU is sort of an abstract class for HDUs containing image\n",
      "     |      data (as opposed to table data) and should never be used directly.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  data\n",
      "     |      The data of a random group FITS file will be like a binary table's\n",
      "     |      data.\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  parnames\n",
      "     |      The names of the group parameters as described by the header.\n",
      "     |  \n",
      "     |  size\n",
      "     |      Returns the size (in bytes) of the HDU's data part.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.image._ImageBaseHDU:\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=None, bzero=None)\n",
      "     |      Scale image data by using ``BSCALE``/``BZERO``.\n",
      "     |      \n",
      "     |      Call to this method will scale `data` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in the HDU's header.  This method should only\n",
      "     |      be used right before writing to the output file, as the data will be\n",
      "     |      scaled and is therefore not very usable after the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy\n",
      "     |          dtype name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'``\n",
      "     |          etc.).  If is `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          How to scale the data: ``\"old\"`` uses the original ``BSCALE`` and\n",
      "     |          ``BZERO`` values from when the data was read/created (defaulting to\n",
      "     |          1 and 0 if they don't exist). For integer data only, ``\"minmax\"``\n",
      "     |          uses the minimum and maximum of the data to scale. User-specified\n",
      "     |          ``bscale``/``bzero`` values always take precedence.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          User-specified ``BSCALE`` and ``BZERO`` values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.image._ImageBaseHDU:\n",
      "     |  \n",
      "     |  section\n",
      "     |      Access a section of the image array without loading the entire array\n",
      "     |      into memory.  The :class:`Section` object returned by this attribute is\n",
      "     |      not meant to be used directly by itself.  Rather, slices of the section\n",
      "     |      return the appropriate slice of the data, and loads *only* that section\n",
      "     |      into memory.\n",
      "     |      \n",
      "     |      Sections are mostly obsoleted by memmap support, but should still be\n",
      "     |      used to deal with very large scaled images.  See the\n",
      "     |      :ref:`data-sections` section of the Astropy documentation for more\n",
      "     |      details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.image._ImageBaseHDU:\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from astropy.io.fits.hdu.image._ImageBaseHDU:\n",
      "     |  \n",
      "     |  standard_keyword_comments = {'BITPIX': 'array data type', 'GCOUNT': 'n...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.table._TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, character_as_bytes=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs` -like\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      character_as_bytes : bool\n",
      "     |          Whether to return bytes for string columns when accessed from the\n",
      "     |          HDU. By default this is `False` and (unicode) strings are returned,\n",
      "     |          but for large tables this may use up a lot of memory.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self)\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self)\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Write the HDU to a new file. This is a convenience method to\n",
      "     |      provide a user easier output interface if only one HDU needs\n",
      "     |      to be written to a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : path-like or file-like\n",
      "     |          Output FITS file.  If the file object is already opened, it must\n",
      "     |          be opened in a writeable mode.\n",
      "     |      \n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` if ``False`` and the output file exists. Default is\n",
      "     |          ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards\n",
      "     |          to the header of the HDU when written to the file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file-like\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class HDUList(builtins.list, astropy.io.fits.verify._Verify)\n",
      "     |  HDUList(hdus=[], file=None)\n",
      "     |  \n",
      "     |  HDU list class.  This is the top-level FITS object.  When a FITS\n",
      "     |  file is opened, a `HDUList` object is returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HDUList\n",
      "     |      builtins.list\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, item)\n",
      "     |      Returns `True` if ``item`` is an ``HDU`` _in_ ``self`` or a valid\n",
      "     |      extension specification (e.g., integer extension number, extension\n",
      "     |      name, or a tuple of extension name and an extension version)\n",
      "     |      of a ``HDU`` in ``self``.\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |      Return a shallow copy of an HDUList.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      copy : `HDUList`\n",
      "     |          A shallow copy of this `HDUList` object.\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Delete an HDU from the `HDUList`, indexed by number or name.\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      # Support the 'with' statement\n",
      "     |  \n",
      "     |  __exit__(self, type, value, traceback)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Get an HDU from the `HDUList`, indexed by number or name.\n",
      "     |  \n",
      "     |  __init__(self, hdus=[], file=None)\n",
      "     |      Construct a `HDUList` object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hdus : BaseHDU or sequence thereof, optional\n",
      "     |          The HDU object(s) to comprise the `HDUList`.  Should be\n",
      "     |          instances of HDU classes like `ImageHDU` or `BinTableHDU`.\n",
      "     |      \n",
      "     |      file : file-like, bytes, optional\n",
      "     |          The opened physical file associated with the `HDUList`\n",
      "     |          or a bytes object containing the contents of the FITS\n",
      "     |          file.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, hdu)\n",
      "     |      Set an HDU to the `HDUList`, indexed by number or name.\n",
      "     |  \n",
      "     |  append(self, hdu)\n",
      "     |      Append a new HDU to the `HDUList`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hdu : BaseHDU\n",
      "     |          HDU to add to the `HDUList`.\n",
      "     |  \n",
      "     |  close(self, output_verify='exception', verbose=False, closed=True)\n",
      "     |      Close the associated FITS file and memmap object, if any.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          When `True`, print out verbose messages.\n",
      "     |      \n",
      "     |      closed : bool\n",
      "     |          When `True`, close the underlying file object.\n",
      "     |  \n",
      "     |  copy = __copy__(self)\n",
      "     |  \n",
      "     |  fileinfo(self, index)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of the indexed HDU within any associated file.  The values are\n",
      "     |      only valid after a read or write of the associated file with\n",
      "     |      no intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : int\n",
      "     |          Index of HDU for which info is to be returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      fileinfo : dict or None\n",
      "     |      \n",
      "     |          The dictionary details information about the locations of\n",
      "     |          the indexed HDU within an associated file.  Returns `None`\n",
      "     |          when the HDU is not associated with a file.\n",
      "     |      \n",
      "     |          Dictionary contents:\n",
      "     |      \n",
      "     |          ========== ========================================================\n",
      "     |          Key        Value\n",
      "     |          ========== ========================================================\n",
      "     |          file       File object associated with the HDU\n",
      "     |          filename   Name of associated file object\n",
      "     |          filemode   Mode in which the file was opened (readonly,\n",
      "     |                     update, append, denywrite, ostream)\n",
      "     |          resized    Flag that when `True` indicates that the data has been\n",
      "     |                     resized since the last read/write so the returned values\n",
      "     |                     may not be valid.\n",
      "     |          hdrLoc     Starting byte location of header in file\n",
      "     |          datLoc     Starting byte location of data block in file\n",
      "     |          datSpan    Data size including padding\n",
      "     |          ========== ========================================================\n",
      "     |  \n",
      "     |  filename(self)\n",
      "     |      Return the file name associated with the HDUList object if one exists.\n",
      "     |      Otherwise returns None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filename : str\n",
      "     |          A string containing the file name associated with the HDUList\n",
      "     |          object if an association exists.  Otherwise returns None.\n",
      "     |  \n",
      "     |  flush(self, output_verify='fix', verbose=False)\n",
      "     |      Force a write of the `HDUList` back to the file (for append and\n",
      "     |      update modes only).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          When `True`, print verbose messages\n",
      "     |  \n",
      "     |  index_of(self, key)\n",
      "     |      Get the index of an HDU from the `HDUList`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : int, str, tuple of (string, int) or BaseHDU\n",
      "     |         The key identifying the HDU.  If ``key`` is a tuple, it is of the\n",
      "     |         form ``(name, ver)`` where ``ver`` is an ``EXTVER`` value that must\n",
      "     |         match the HDU being searched for.\n",
      "     |      \n",
      "     |         If the key is ambiguous (e.g. there are multiple 'SCI' extensions)\n",
      "     |         the first match is returned.  For a more precise match use the\n",
      "     |         ``(name, ver)`` pair.\n",
      "     |      \n",
      "     |         If even the ``(name, ver)`` pair is ambiguous (it shouldn't be\n",
      "     |         but it's not impossible) the numeric index must be used to index\n",
      "     |         the duplicate HDU.\n",
      "     |      \n",
      "     |         When ``key`` is an HDU object, this function returns the\n",
      "     |         index of that HDU object in the ``HDUList``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      index : int\n",
      "     |         The index of the HDU in the `HDUList`.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |         If ``key`` is an HDU object and it is not found in the ``HDUList``.\n",
      "     |      \n",
      "     |      KeyError\n",
      "     |         If an HDU specified by the ``key`` that is an extension number,\n",
      "     |         extension name, or a tuple of extension name and version is not\n",
      "     |         found in the ``HDUList``.\n",
      "     |  \n",
      "     |  info(self, output=None)\n",
      "     |      Summarize the info of the HDUs in this `HDUList`.\n",
      "     |      \n",
      "     |      Note that this function prints its results to the console---it\n",
      "     |      does not return a value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      output : file-like or bool, optional\n",
      "     |          A file-like object to write the output to.  If `False`, does not\n",
      "     |          output to a file and instead returns a list of tuples representing\n",
      "     |          the HDU info.  Writes to ``sys.stdout`` by default.\n",
      "     |  \n",
      "     |  insert(self, index, hdu)\n",
      "     |      Insert an HDU into the `HDUList` at the given ``index``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : int\n",
      "     |          Index before which to insert the new HDU.\n",
      "     |      \n",
      "     |      hdu : BaseHDU\n",
      "     |          The HDU object to insert\n",
      "     |  \n",
      "     |  pop(self, index=-1)\n",
      "     |      Remove an item from the list and return it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : int, str, tuple of (string, int), optional\n",
      "     |          An integer value of ``index`` indicates the position from which\n",
      "     |          ``pop()`` removes and returns an HDU. A string value or a tuple\n",
      "     |          of ``(string, int)`` functions as a key for identifying the\n",
      "     |          HDU to be removed and returned. If ``key`` is a tuple, it is\n",
      "     |          of the form ``(key, ver)`` where ``ver`` is an ``EXTVER``\n",
      "     |          value that must match the HDU being searched for.\n",
      "     |      \n",
      "     |          If the key is ambiguous (e.g. there are multiple 'SCI' extensions)\n",
      "     |          the first match is returned.  For a more precise match use the\n",
      "     |          ``(name, ver)`` pair.\n",
      "     |      \n",
      "     |          If even the ``(name, ver)`` pair is ambiguous the numeric index\n",
      "     |          must be used to index the duplicate HDU.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hdu : BaseHDU\n",
      "     |          The HDU object at position indicated by ``index`` or having name\n",
      "     |          and version specified by ``index``.\n",
      "     |  \n",
      "     |  readall(self)\n",
      "     |      Read data of all HDUs into memory.\n",
      "     |  \n",
      "     |  update_extend(self)\n",
      "     |      Make sure that if the primary header needs the keyword ``EXTEND`` that\n",
      "     |      it has it and it is correct.\n",
      "     |  \n",
      "     |  writeto(self, fileobj, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Write the `HDUList` to a new file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : str, file-like or `pathlib.Path`\n",
      "     |          File to write to.  If a file object, must be opened in a\n",
      "     |          writeable mode.\n",
      "     |      \n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` if ``False`` and the output file exists. Default is\n",
      "     |          ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards\n",
      "     |          to the headers of all HDU's written to the file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromfile(fileobj, mode=None, memmap=None, save_backup=False, cache=True, lazy_load_hdus=True, ignore_missing_simple=False, **kwargs) from builtins.type\n",
      "     |      Creates an `HDUList` instance from a file-like object.\n",
      "     |      \n",
      "     |      The actual implementation of ``fitsopen()``, and generally shouldn't\n",
      "     |      be used directly.  Use :func:`open` instead (and see its\n",
      "     |      documentation for details of the parameters accepted by this method).\n",
      "     |  \n",
      "     |  fromstring(data, **kwargs) from builtins.type\n",
      "     |      Creates an `HDUList` instance from a string or other in-memory data\n",
      "     |      buffer containing an entire FITS file.  Similar to\n",
      "     |      :meth:`HDUList.fromfile`, but does not accept the mode or memmap\n",
      "     |      arguments, as they are only relevant to reading from a file on disk.\n",
      "     |      \n",
      "     |      This is useful for interfacing with other libraries such as CFITSIO,\n",
      "     |      and may also be useful for streaming applications.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, buffer-like, etc.\n",
      "     |          A string or other memory buffer containing an entire FITS file.\n",
      "     |          Buffer-like objects include :class:`~bytes`, :class:`~bytearray`,\n",
      "     |          :class:`~memoryview`, and :class:`~numpy.ndarray`.\n",
      "     |          It should be noted that if that memory is read-only (such as a\n",
      "     |          Python string) the returned :class:`HDUList`'s data portions will\n",
      "     |          also be read-only.\n",
      "     |      \n",
      "     |      kwargs : dict\n",
      "     |          Optional keyword arguments.  See\n",
      "     |          :func:`astropy.io.fits.open` for details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hdul : HDUList\n",
      "     |          An :class:`HDUList` object representing the in-memory FITS file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.list:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iadd__(self, value, /)\n",
      "     |      Implement self+=value.\n",
      "     |  \n",
      "     |  __imul__(self, value, /)\n",
      "     |      Implement self*=value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the list.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  __sizeof__(self, /)\n",
      "     |      Return the size of the list in memory, in bytes.\n",
      "     |  \n",
      "     |  clear(self, /)\n",
      "     |      Remove all items from list.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  extend(self, iterable, /)\n",
      "     |      Extend list by appending elements from the iterable.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  remove(self, value, /)\n",
      "     |      Remove first occurrence of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  reverse(self, /)\n",
      "     |      Reverse *IN PLACE*.\n",
      "     |  \n",
      "     |  sort(self, /, *, key=None, reverse=False)\n",
      "     |      Sort the list in ascending order and return None.\n",
      "     |      \n",
      "     |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the\n",
      "     |      order of two equal elements is maintained).\n",
      "     |      \n",
      "     |      If a key function is given, apply it once to each list item and sort them,\n",
      "     |      ascending or descending, according to their function values.\n",
      "     |      \n",
      "     |      The reverse flag can be set to sort in descending order.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.list:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.list:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.list:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Header(builtins.object)\n",
      "     |  Header(cards=[], copy=False)\n",
      "     |  \n",
      "     |  FITS header class.  This class exposes both a dict-like interface and a\n",
      "     |  list-like interface to FITS headers.\n",
      "     |  \n",
      "     |  The header may be indexed by keyword and, like a dict, the associated value\n",
      "     |  will be returned.  When the header contains cards with duplicate keywords,\n",
      "     |  only the value of the first card with the given keyword will be returned.\n",
      "     |  It is also possible to use a 2-tuple as the index in the form (keyword,\n",
      "     |  n)--this returns the n-th value with that keyword, in the case where there\n",
      "     |  are duplicate keywords.\n",
      "     |  \n",
      "     |  For example::\n",
      "     |  \n",
      "     |      >>> header['NAXIS']\n",
      "     |      0\n",
      "     |      >>> header[('FOO', 1)]  # Return the value of the second FOO keyword\n",
      "     |      'foo'\n",
      "     |  \n",
      "     |  The header may also be indexed by card number::\n",
      "     |  \n",
      "     |      >>> header[0]  # Return the value of the first card in the header\n",
      "     |      'T'\n",
      "     |  \n",
      "     |  Commentary keywords such as HISTORY and COMMENT are special cases: When\n",
      "     |  indexing the Header object with either 'HISTORY' or 'COMMENT' a list of all\n",
      "     |  the HISTORY/COMMENT values is returned::\n",
      "     |  \n",
      "     |      >>> header['HISTORY']\n",
      "     |      This is the first history entry in this header.\n",
      "     |      This is the second history entry in this header.\n",
      "     |      ...\n",
      "     |  \n",
      "     |  See the Astropy documentation for more details on working with headers.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Although FITS keywords must be exclusively upper case, retrieving an item\n",
      "     |  in a `Header` object is case insensitive.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __contains__(self, keyword)\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Two Headers are equal only if they have the exact same string\n",
      "     |      representation.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __iadd__(self, other)\n",
      "     |  \n",
      "     |  __init__(self, cards=[], copy=False)\n",
      "     |      Construct a `Header` from an iterable and/or text file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cards : list of `Card`, optional\n",
      "     |          The cards to initialize the header with. Also allowed are other\n",
      "     |          `Header` (or `dict`-like) objects.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.2\n",
      "     |              Allowed ``cards`` to be a `dict`-like object.\n",
      "     |      \n",
      "     |      copy : bool, optional\n",
      "     |      \n",
      "     |          If ``True`` copies the ``cards`` if they were another `Header`\n",
      "     |          instance.\n",
      "     |          Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  add_blank(self, value='', before=None, after=None)\n",
      "     |      Add a blank card.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : str, optional\n",
      "     |          Text to be added.\n",
      "     |      \n",
      "     |      before : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |      \n",
      "     |      after : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |  \n",
      "     |  add_comment(self, value, before=None, after=None)\n",
      "     |      Add a ``COMMENT`` card.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : str\n",
      "     |          Text to be added.\n",
      "     |      \n",
      "     |      before : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |      \n",
      "     |      after : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |  \n",
      "     |  add_history(self, value, before=None, after=None)\n",
      "     |      Add a ``HISTORY`` card.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : str\n",
      "     |          History text to be added.\n",
      "     |      \n",
      "     |      before : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |      \n",
      "     |      after : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |  \n",
      "     |  append(self, card=None, useblanks=True, bottom=False, end=False)\n",
      "     |      Appends a new keyword+value card to the end of the Header, similar\n",
      "     |      to `list.append`.\n",
      "     |      \n",
      "     |      By default if the last cards in the Header have commentary keywords,\n",
      "     |      this will append the new keyword before the commentary (unless the new\n",
      "     |      keyword is also commentary).\n",
      "     |      \n",
      "     |      Also differs from `list.append` in that it can be called with no\n",
      "     |      arguments: In this case a blank card is appended to the end of the\n",
      "     |      Header.  In the case all the keyword arguments are ignored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      card : str, tuple\n",
      "     |          A keyword or a (keyword, value, [comment]) tuple representing a\n",
      "     |          single header card; the comment is optional in which case a\n",
      "     |          2-tuple may be used\n",
      "     |      \n",
      "     |      useblanks : bool, optional\n",
      "     |          If there are blank cards at the end of the Header, replace the\n",
      "     |          first blank card so that the total number of cards in the Header\n",
      "     |          does not increase.  Otherwise preserve the number of blank cards.\n",
      "     |      \n",
      "     |      bottom : bool, optional\n",
      "     |          If True, instead of appending after the last non-commentary card,\n",
      "     |          append after the last non-blank card.\n",
      "     |      \n",
      "     |      end : bool, optional\n",
      "     |          If True, ignore the useblanks and bottom options, and append at the\n",
      "     |          very end of the Header.\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      Remove all cards from the header.\n",
      "     |  \n",
      "     |  copy(self, strip=False)\n",
      "     |      Make a copy of the :class:`Header`.\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |          `copy.copy` and `copy.deepcopy` on a `Header` will call this\n",
      "     |          method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      strip : bool, optional\n",
      "     |         If `True`, strip any headers that are specific to one of the\n",
      "     |         standard HDU types, so that this header can be used in a different\n",
      "     |         HDU.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      `Header`\n",
      "     |          A new :class:`Header` instance.\n",
      "     |  \n",
      "     |  count(self, keyword)\n",
      "     |      Returns the count of the given keyword in the header, similar to\n",
      "     |      `list.count` if the Header object is treated as a list of keywords.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to count instances of in the header\n",
      "     |  \n",
      "     |  extend(self, cards, strip=True, unique=False, update=False, update_first=False, useblanks=True, bottom=False, end=False)\n",
      "     |      Appends multiple keyword+value cards to the end of the header, similar\n",
      "     |      to `list.extend`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cards : iterable\n",
      "     |          An iterable of (keyword, value, [comment]) tuples; see\n",
      "     |          `Header.append`.\n",
      "     |      \n",
      "     |      strip : bool, optional\n",
      "     |          Remove any keywords that have meaning only to specific types of\n",
      "     |          HDUs, so that only more general keywords are added from extension\n",
      "     |          Header or Card list (default: `True`).\n",
      "     |      \n",
      "     |      unique : bool, optional\n",
      "     |          If `True`, ensures that no duplicate keywords are appended;\n",
      "     |          keywords already in this header are simply discarded.  The\n",
      "     |          exception is commentary keywords (COMMENT, HISTORY, etc.): they are\n",
      "     |          only treated as duplicates if their values match.\n",
      "     |      \n",
      "     |      update : bool, optional\n",
      "     |          If `True`, update the current header with the values and comments\n",
      "     |          from duplicate keywords in the input header.  This supersedes the\n",
      "     |          ``unique`` argument.  Commentary keywords are treated the same as\n",
      "     |          if ``unique=True``.\n",
      "     |      \n",
      "     |      update_first : bool, optional\n",
      "     |          If the first keyword in the header is 'SIMPLE', and the first\n",
      "     |          keyword in the input header is 'XTENSION', the 'SIMPLE' keyword is\n",
      "     |          replaced by the 'XTENSION' keyword.  Likewise if the first keyword\n",
      "     |          in the header is 'XTENSION' and the first keyword in the input\n",
      "     |          header is 'SIMPLE', the 'XTENSION' keyword is replaced by the\n",
      "     |          'SIMPLE' keyword.  This behavior is otherwise dumb as to whether or\n",
      "     |          not the resulting header is a valid primary or extension header.\n",
      "     |          This is mostly provided to support backwards compatibility with the\n",
      "     |          old ``Header.fromTxtFile`` method, and only applies if\n",
      "     |          ``update=True``.\n",
      "     |      \n",
      "     |      useblanks, bottom, end : bool, optional\n",
      "     |          These arguments are passed to :meth:`Header.append` while appending\n",
      "     |          new cards to the header.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Similar to :meth:`dict.get`--returns the value associated with keyword\n",
      "     |      in the header, or a default value if the keyword is not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : str\n",
      "     |          A keyword that may or may not be in the header.\n",
      "     |      \n",
      "     |      default : optional\n",
      "     |          A default value to return if the keyword is not found in the\n",
      "     |          header.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value: str, number, complex, bool, or ``astropy.io.fits.card.Undefined``\n",
      "     |          The value associated with the given keyword, or the default value\n",
      "     |          if the keyword is not in the header.\n",
      "     |  \n",
      "     |  index(self, keyword, start=None, stop=None)\n",
      "     |      Returns the index if the first instance of the given keyword in the\n",
      "     |      header, similar to `list.index` if the Header object is treated as a\n",
      "     |      list of keywords.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to look up in the list of all keywords in the header\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |          The lower bound for the index\n",
      "     |      \n",
      "     |      stop : int, optional\n",
      "     |          The upper bound for the index\n",
      "     |  \n",
      "     |  insert(self, key, card, useblanks=True, after=False)\n",
      "     |      Inserts a new keyword+value card into the Header at a given location,\n",
      "     |      similar to `list.insert`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : int, str, or tuple\n",
      "     |          The index into the list of header keywords before which the\n",
      "     |          new keyword should be inserted, or the name of a keyword before\n",
      "     |          which the new keyword should be inserted.  Can also accept a\n",
      "     |          (keyword, index) tuple for inserting around duplicate keywords.\n",
      "     |      \n",
      "     |      card : str, tuple\n",
      "     |          A keyword or a (keyword, value, [comment]) tuple; see\n",
      "     |          `Header.append`\n",
      "     |      \n",
      "     |      useblanks : bool, optional\n",
      "     |          If there are blank cards at the end of the Header, replace the\n",
      "     |          first blank card so that the total number of cards in the Header\n",
      "     |          does not increase.  Otherwise preserve the number of blank cards.\n",
      "     |      \n",
      "     |      after : bool, optional\n",
      "     |          If set to `True`, insert *after* the specified index or keyword,\n",
      "     |          rather than before it.  Defaults to `False`.\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      Like :meth:`dict.items`.\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      Like :meth:`dict.keys`--iterating directly over the `Header`\n",
      "     |      instance has the same behavior.\n",
      "     |  \n",
      "     |  pop(self, *args)\n",
      "     |      Works like :meth:`list.pop` if no arguments or an index argument are\n",
      "     |      supplied; otherwise works like :meth:`dict.pop`.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      Similar to :meth:`dict.popitem`.\n",
      "     |  \n",
      "     |  remove(self, keyword, ignore_missing=False, remove_all=False)\n",
      "     |      Removes the first instance of the given keyword from the header similar\n",
      "     |      to `list.remove` if the Header object is treated as a list of keywords.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword of which to remove the first instance in the header.\n",
      "     |      \n",
      "     |      ignore_missing : bool, optional\n",
      "     |          When True, ignores missing keywords.  Otherwise, if the keyword\n",
      "     |          is not present in the header a KeyError is raised.\n",
      "     |      \n",
      "     |      remove_all : bool, optional\n",
      "     |          When True, all instances of keyword will be removed.\n",
      "     |          Otherwise only the first instance of the given keyword is removed.\n",
      "     |  \n",
      "     |  rename_keyword(self, oldkeyword, newkeyword, force=False)\n",
      "     |      Rename a card's keyword in the header.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      oldkeyword : str or int\n",
      "     |          Old keyword or card index\n",
      "     |      \n",
      "     |      newkeyword : str\n",
      "     |          New keyword\n",
      "     |      \n",
      "     |      force : bool, optional\n",
      "     |          When `True`, if the new keyword already exists in the header, force\n",
      "     |          the creation of a duplicate keyword. Otherwise a\n",
      "     |          `ValueError` is raised.\n",
      "     |  \n",
      "     |  set(self, keyword, value=None, comment=None, before=None, after=None)\n",
      "     |      Set the value and/or comment and/or position of a specified keyword.\n",
      "     |      \n",
      "     |      If the keyword does not already exist in the header, a new keyword is\n",
      "     |      created in the specified position, or appended to the end of the header\n",
      "     |      if no position is specified.\n",
      "     |      \n",
      "     |      This method is similar to :meth:`Header.update` prior to Astropy v0.1.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          It should be noted that ``header.set(keyword, value)`` and\n",
      "     |          ``header.set(keyword, value, comment)`` are equivalent to\n",
      "     |          ``header[keyword] = value`` and\n",
      "     |          ``header[keyword] = (value, comment)`` respectively.\n",
      "     |      \n",
      "     |          New keywords can also be inserted relative to existing keywords\n",
      "     |          using, for example::\n",
      "     |      \n",
      "     |              >>> header.insert('NAXIS1', ('NAXIS', 2, 'Number of axes'))\n",
      "     |      \n",
      "     |          to insert before an existing keyword, or::\n",
      "     |      \n",
      "     |              >>> header.insert('NAXIS', ('NAXIS1', 4096), after=True)\n",
      "     |      \n",
      "     |          to insert after an existing keyword.\n",
      "     |      \n",
      "     |          The only advantage of using :meth:`Header.set` is that it\n",
      "     |          easily replaces the old usage of :meth:`Header.update` both\n",
      "     |          conceptually and in terms of function signature.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          A header keyword\n",
      "     |      \n",
      "     |      value : str, optional\n",
      "     |          The value to set for the given keyword; if None the existing value\n",
      "     |          is kept, but '' may be used to set a blank value\n",
      "     |      \n",
      "     |      comment : str, optional\n",
      "     |          The comment to set for the given keyword; if None the existing\n",
      "     |          comment is kept, but ``''`` may be used to set a blank comment\n",
      "     |      \n",
      "     |      before : str, int, optional\n",
      "     |          Name of the keyword, or index of the `Card` before which this card\n",
      "     |          should be located in the header.  The argument ``before`` takes\n",
      "     |          precedence over ``after`` if both specified.\n",
      "     |      \n",
      "     |      after : str, int, optional\n",
      "     |          Name of the keyword, or index of the `Card` after which this card\n",
      "     |          should be located in the header.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      Similar to :meth:`dict.setdefault`.\n",
      "     |  \n",
      "     |  strip(self)\n",
      "     |      Strip cards specific to a certain kind of header.\n",
      "     |      \n",
      "     |      Strip cards like ``SIMPLE``, ``BITPIX``, etc. so the rest of\n",
      "     |      the header can be used to reconstruct another kind of header.\n",
      "     |  \n",
      "     |  tofile(self, fileobj, sep='', endcard=True, padding=True, overwrite=False)\n",
      "     |      Writes the header to file or file-like object.\n",
      "     |      \n",
      "     |      By default this writes the header exactly as it would be written to a\n",
      "     |      FITS file, with the END card included and padding to the next multiple\n",
      "     |      of 2880 bytes.  However, aspects of this may be controlled.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : path-like or file-like, optional\n",
      "     |          Either the pathname of a file, or an open file handle or file-like\n",
      "     |          object.\n",
      "     |      \n",
      "     |      sep : str, optional\n",
      "     |          The character or string with which to separate cards.  By default\n",
      "     |          there is no separator, but one could use ``'\\\\n'``, for example, to\n",
      "     |          separate each card with a new line\n",
      "     |      \n",
      "     |      endcard : bool, optional\n",
      "     |          If `True` (default) adds the END card to the end of the header\n",
      "     |          string\n",
      "     |      \n",
      "     |      padding : bool, optional\n",
      "     |          If `True` (default) pads the string with spaces out to the next\n",
      "     |          multiple of 2880 characters\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` if ``False`` and the output file exists. Default is\n",
      "     |          ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  tostring(self, sep='', endcard=True, padding=True)\n",
      "     |      Returns a string representation of the header.\n",
      "     |      \n",
      "     |      By default this uses no separator between cards, adds the END card, and\n",
      "     |      pads the string with spaces to the next multiple of 2880 bytes.  That\n",
      "     |      is, it returns the header exactly as it would appear in a FITS file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sep : str, optional\n",
      "     |          The character or string with which to separate cards.  By default\n",
      "     |          there is no separator, but one could use ``'\\\\n'``, for example, to\n",
      "     |          separate each card with a new line\n",
      "     |      \n",
      "     |      endcard : bool, optional\n",
      "     |          If True (default) adds the END card to the end of the header\n",
      "     |          string\n",
      "     |      \n",
      "     |      padding : bool, optional\n",
      "     |          If True (default) pads the string with spaces out to the next\n",
      "     |          multiple of 2880 characters\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          A string representing a FITS header.\n",
      "     |  \n",
      "     |  totextfile(self, fileobj, endcard=False, overwrite=False)\n",
      "     |      Write the header as text to a file or a file-like object.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          >>> Header.tofile(fileobj, sep='\\n', endcard=False,\n",
      "     |          ...               padding=False, overwrite=overwrite)\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      tofile\n",
      "     |  \n",
      "     |  update(self, *args, **kwargs)\n",
      "     |      Update the Header with new keyword values, updating the values of\n",
      "     |      existing keywords and appending new keywords otherwise; similar to\n",
      "     |      `dict.update`.\n",
      "     |      \n",
      "     |      `update` accepts either a dict-like object or an iterable.  In the\n",
      "     |      former case the keys must be header keywords and the values may be\n",
      "     |      either scalar values or (value, comment) tuples.  In the case of an\n",
      "     |      iterable the items must be (keyword, value) tuples or (keyword, value,\n",
      "     |      comment) tuples.\n",
      "     |      \n",
      "     |      Arbitrary arguments are also accepted, in which case the update() is\n",
      "     |      called again with the kwargs dict as its only argument.  That is,\n",
      "     |      \n",
      "     |      ::\n",
      "     |      \n",
      "     |          >>> header.update(NAXIS1=100, NAXIS2=100)\n",
      "     |      \n",
      "     |      is equivalent to::\n",
      "     |      \n",
      "     |          header.update({'NAXIS1': 100, 'NAXIS2': 100})\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          As this method works similarly to `dict.update` it is very\n",
      "     |          different from the ``Header.update()`` method in Astropy v0.1.\n",
      "     |          Use of the old API was\n",
      "     |          **deprecated** for a long time and is now removed. Most uses of the\n",
      "     |          old API can be replaced as follows:\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header[keyword] = value\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value, comment=comment)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header[keyword] = (value, comment)\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value, before=before_keyword)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header.insert(before_keyword, (keyword, value))\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value, after=after_keyword)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header.insert(after_keyword, (keyword, value),\n",
      "     |                              after=True)\n",
      "     |      \n",
      "     |          See also :meth:`Header.set` which is a new method that provides an\n",
      "     |          interface similar to the old ``Header.update()`` and may help make\n",
      "     |          transition a little easier.\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      Like :meth:`dict.values`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromfile(fileobj, sep='', endcard=True, padding=True) from builtins.type\n",
      "     |      Similar to :meth:`Header.fromstring`, but reads the header string from\n",
      "     |      a given file-like object or filename.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : str, file-like\n",
      "     |          A filename or an open file-like object from which a FITS header is\n",
      "     |          to be read.  For open file handles the file pointer must be at the\n",
      "     |          beginning of the header.\n",
      "     |      \n",
      "     |      sep : str, optional\n",
      "     |          The string separating cards from each other, such as a newline.  By\n",
      "     |          default there is no card separator (as is the case in a raw FITS\n",
      "     |          file).\n",
      "     |      \n",
      "     |      endcard : bool, optional\n",
      "     |          If True (the default) the header must end with an END card in order\n",
      "     |          to be considered valid.  If an END card is not found an\n",
      "     |          `OSError` is raised.\n",
      "     |      \n",
      "     |      padding : bool, optional\n",
      "     |          If True (the default) the header will be required to be padded out\n",
      "     |          to a multiple of 2880, the FITS header block size.  Otherwise any\n",
      "     |          padding, or lack thereof, is ignored.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      `Header`\n",
      "     |          A new `Header` instance.\n",
      "     |  \n",
      "     |  fromkeys(iterable, value=None) from builtins.type\n",
      "     |      Similar to :meth:`dict.fromkeys`--creates a new `Header` from an\n",
      "     |      iterable of keywords and an optional default value.\n",
      "     |      \n",
      "     |      This method is not likely to be particularly useful for creating real\n",
      "     |      world FITS headers, but it is useful for testing.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      iterable\n",
      "     |          Any iterable that returns strings representing FITS keywords.\n",
      "     |      \n",
      "     |      value : optional\n",
      "     |          A default value to assign to each keyword; must be a valid type for\n",
      "     |          FITS keywords.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      `Header`\n",
      "     |          A new `Header` instance.\n",
      "     |  \n",
      "     |  fromstring(data, sep='') from builtins.type\n",
      "     |      Creates an HDU header from a byte string containing the entire header\n",
      "     |      data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str or bytes\n",
      "     |         String or bytes containing the entire header.  In the case of bytes\n",
      "     |         they will be decoded using latin-1 (only plain ASCII characters are\n",
      "     |         allowed in FITS headers but latin-1 allows us to retain any invalid\n",
      "     |         bytes that might appear in malformatted FITS files).\n",
      "     |      \n",
      "     |      sep : str, optional\n",
      "     |          The string separating cards from each other, such as a newline.  By\n",
      "     |          default there is no card separator (as is the case in a raw FITS\n",
      "     |          file).  In general this is only used in cases where a header was\n",
      "     |          printed as text (e.g. with newlines after each card) and you want\n",
      "     |          to create a new `Header` from it by copy/pasting.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> from astropy.io.fits import Header\n",
      "     |      >>> hdr = Header({'SIMPLE': True})\n",
      "     |      >>> Header.fromstring(hdr.tostring()) == hdr\n",
      "     |      True\n",
      "     |      \n",
      "     |      If you want to create a `Header` from printed text it's not necessary\n",
      "     |      to have the exact binary structure as it would appear in a FITS file,\n",
      "     |      with the full 80 byte card length.  Rather, each \"card\" can end in a\n",
      "     |      newline and does not have to be padded out to a full card length as\n",
      "     |      long as it \"looks like\" a FITS header:\n",
      "     |      \n",
      "     |      >>> hdr = Header.fromstring(\"\"\"\\\n",
      "     |      ... SIMPLE  =                    T / conforms to FITS standard\n",
      "     |      ... BITPIX  =                    8 / array data type\n",
      "     |      ... NAXIS   =                    0 / number of array dimensions\n",
      "     |      ... EXTEND  =                    T\n",
      "     |      ... \"\"\", sep='\\n')\n",
      "     |      >>> hdr['SIMPLE']\n",
      "     |      True\n",
      "     |      >>> hdr['BITPIX']\n",
      "     |      8\n",
      "     |      >>> len(hdr)\n",
      "     |      4\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      `Header`\n",
      "     |          A new `Header` instance.\n",
      "     |  \n",
      "     |  fromtextfile(fileobj, endcard=False) from builtins.type\n",
      "     |      Read a header from a simple text file or file-like object.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          >>> Header.fromfile(fileobj, sep='\\n', endcard=False,\n",
      "     |          ...                 padding=False)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      fromfile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  cards\n",
      "     |      The underlying physical cards that make up this Header; it can be\n",
      "     |      looked at, but it should not be modified directly.\n",
      "     |  \n",
      "     |  comments\n",
      "     |      View the comments associated with each keyword, if any.\n",
      "     |      \n",
      "     |      For example, to see the comment on the NAXIS keyword:\n",
      "     |      \n",
      "     |          >>> header.comments['NAXIS']\n",
      "     |          number of data axes\n",
      "     |      \n",
      "     |      Comments can also be updated through this interface:\n",
      "     |      \n",
      "     |          >>> header.comments['NAXIS'] = 'Number of data axes'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class ImageHDU(_ImageBaseHDU, astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "     |  ImageHDU(data=None, header=None, name=None, do_not_scale_image_data=False, uint=True, scale_back=None, ver=None)\n",
      "     |  \n",
      "     |  FITS image extension HDU class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ImageHDU\n",
      "     |      _ImageBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, do_not_scale_image_data=False, uint=True, scale_back=None, ver=None)\n",
      "     |      Construct an image HDU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array\n",
      "     |          The data in the HDU.\n",
      "     |      \n",
      "     |      header : `~astropy.io.fits.Header`\n",
      "     |          The header to be used (as a template).  If ``header`` is\n",
      "     |          `None`, a minimal header will be provided.\n",
      "     |      \n",
      "     |      name : str, optional\n",
      "     |          The name of the HDU, will be the value of the keyword\n",
      "     |          ``EXTNAME``.\n",
      "     |      \n",
      "     |      do_not_scale_image_data : bool, optional\n",
      "     |          If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "     |          when read. (default: False)\n",
      "     |      \n",
      "     |      uint : bool, optional\n",
      "     |          Interpret signed integer data where ``BZERO`` is the\n",
      "     |          central value and ``BSCALE == 1`` as unsigned integer\n",
      "     |          data.  For example, ``int16`` data with ``BZERO = 32768``\n",
      "     |          and ``BSCALE = 1`` would be treated as ``uint16`` data.\n",
      "     |          (default: True)\n",
      "     |      \n",
      "     |      scale_back : bool, optional\n",
      "     |          If `True`, when saving changes to a file that contained scaled\n",
      "     |          image data, restore the data to the original type and reapply the\n",
      "     |          original BSCALE/BZERO values.  This could lead to loss of accuracy\n",
      "     |          if scaling back to integer values after performing floating point\n",
      "     |          operations on the data.  Pseudo-unsigned integers are automatically\n",
      "     |          rescaled unless scale_back is explicitly set to `False`.\n",
      "     |          (default: None)\n",
      "     |      \n",
      "     |      ver : int > 0 or None, optional\n",
      "     |          The ver of the HDU, will be the value of the keyword ``EXTVER``.\n",
      "     |          If not given or None, it defaults to the value of the ``EXTVER``\n",
      "     |          card of the ``header`` or 1.\n",
      "     |          (default: None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      _ImageBaseHDU is sort of an abstract class for HDUs containing image\n",
      "     |      data (as opposed to table data) and should never be used directly.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=None, bzero=None)\n",
      "     |      Scale image data by using ``BSCALE``/``BZERO``.\n",
      "     |      \n",
      "     |      Call to this method will scale `data` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in the HDU's header.  This method should only\n",
      "     |      be used right before writing to the output file, as the data will be\n",
      "     |      scaled and is therefore not very usable after the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy\n",
      "     |          dtype name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'``\n",
      "     |          etc.).  If is `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          How to scale the data: ``\"old\"`` uses the original ``BSCALE`` and\n",
      "     |          ``BZERO`` values from when the data was read/created (defaulting to\n",
      "     |          1 and 0 if they don't exist). For integer data only, ``\"minmax\"``\n",
      "     |          uses the minimum and maximum of the data to scale. User-specified\n",
      "     |          ``bscale``/``bzero`` values always take precedence.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          User-specified ``BSCALE`` and ``BZERO`` values\n",
      "     |  \n",
      "     |  update_header(self)\n",
      "     |      Update the header keywords to agree with the data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  section\n",
      "     |      Access a section of the image array without loading the entire array\n",
      "     |      into memory.  The :class:`Section` object returned by this attribute is\n",
      "     |      not meant to be used directly by itself.  Rather, slices of the section\n",
      "     |      return the appropriate slice of the data, and loads *only* that section\n",
      "     |      into memory.\n",
      "     |      \n",
      "     |      Sections are mostly obsoleted by memmap support, but should still be\n",
      "     |      used to deal with very large scaled images.  See the\n",
      "     |      :ref:`data-sections` section of the Astropy documentation for more\n",
      "     |      details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |      Image/array data as a `~numpy.ndarray`.\n",
      "     |      \n",
      "     |      Please remember that the order of axes on an Numpy array are opposite\n",
      "     |      of the order specified in the FITS file.  For example for a 2D image\n",
      "     |      the \"rows\" or y-axis are the first dimension, and the \"columns\" or\n",
      "     |      x-axis are the second dimension.\n",
      "     |      \n",
      "     |      If the data is scaled using the BZERO and BSCALE parameters, this\n",
      "     |      attribute returns the data scaled to its physical values unless the\n",
      "     |      file was opened with ``do_not_scale_image_data=True``.\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  standard_keyword_comments = {'BITPIX': 'array data type', 'GCOUNT': 'n...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self)\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self)\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file-like\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class PrimaryHDU(_ImageBaseHDU)\n",
      "     |  PrimaryHDU(data=None, header=None, do_not_scale_image_data=False, ignore_blank=False, uint=True, scale_back=None)\n",
      "     |  \n",
      "     |  FITS primary HDU class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PrimaryHDU\n",
      "     |      _ImageBaseHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, do_not_scale_image_data=False, ignore_blank=False, uint=True, scale_back=None)\n",
      "     |      Construct a primary HDU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array or ``astropy.io.fits.hdu.base.DELAYED``, optional\n",
      "     |          The data in the HDU.\n",
      "     |      \n",
      "     |      header : `~astropy.io.fits.Header`, optional\n",
      "     |          The header to be used (as a template).  If ``header`` is `None`, a\n",
      "     |          minimal header will be provided.\n",
      "     |      \n",
      "     |      do_not_scale_image_data : bool, optional\n",
      "     |          If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "     |          when read. (default: False)\n",
      "     |      \n",
      "     |      ignore_blank : bool, optional\n",
      "     |          If `True`, the BLANK header keyword will be ignored if present.\n",
      "     |          Otherwise, pixels equal to this value will be replaced with\n",
      "     |          NaNs. (default: False)\n",
      "     |      \n",
      "     |      uint : bool, optional\n",
      "     |          Interpret signed integer data where ``BZERO`` is the\n",
      "     |          central value and ``BSCALE == 1`` as unsigned integer\n",
      "     |          data.  For example, ``int16`` data with ``BZERO = 32768``\n",
      "     |          and ``BSCALE = 1`` would be treated as ``uint16`` data.\n",
      "     |          (default: True)\n",
      "     |      \n",
      "     |      scale_back : bool, optional\n",
      "     |          If `True`, when saving changes to a file that contained scaled\n",
      "     |          image data, restore the data to the original type and reapply the\n",
      "     |          original BSCALE/BZERO values.  This could lead to loss of accuracy\n",
      "     |          if scaling back to integer values after performing floating point\n",
      "     |          operations on the data.  Pseudo-unsigned integers are automatically\n",
      "     |          rescaled unless scale_back is explicitly set to `False`.\n",
      "     |          (default: None)\n",
      "     |  \n",
      "     |  update_header(self)\n",
      "     |      Update the header keywords to agree with the data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      _ImageBaseHDU is sort of an abstract class for HDUs containing image\n",
      "     |      data (as opposed to table data) and should never be used directly.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=None, bzero=None)\n",
      "     |      Scale image data by using ``BSCALE``/``BZERO``.\n",
      "     |      \n",
      "     |      Call to this method will scale `data` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in the HDU's header.  This method should only\n",
      "     |      be used right before writing to the output file, as the data will be\n",
      "     |      scaled and is therefore not very usable after the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy\n",
      "     |          dtype name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'``\n",
      "     |          etc.).  If is `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          How to scale the data: ``\"old\"`` uses the original ``BSCALE`` and\n",
      "     |          ``BZERO`` values from when the data was read/created (defaulting to\n",
      "     |          1 and 0 if they don't exist). For integer data only, ``\"minmax\"``\n",
      "     |          uses the minimum and maximum of the data to scale. User-specified\n",
      "     |          ``bscale``/``bzero`` values always take precedence.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          User-specified ``BSCALE`` and ``BZERO`` values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  section\n",
      "     |      Access a section of the image array without loading the entire array\n",
      "     |      into memory.  The :class:`Section` object returned by this attribute is\n",
      "     |      not meant to be used directly by itself.  Rather, slices of the section\n",
      "     |      return the appropriate slice of the data, and loads *only* that section\n",
      "     |      into memory.\n",
      "     |      \n",
      "     |      Sections are mostly obsoleted by memmap support, but should still be\n",
      "     |      used to deal with very large scaled images.  See the\n",
      "     |      :ref:`data-sections` section of the Astropy documentation for more\n",
      "     |      details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |      Image/array data as a `~numpy.ndarray`.\n",
      "     |      \n",
      "     |      Please remember that the order of axes on an Numpy array are opposite\n",
      "     |      of the order specified in the FITS file.  For example for a 2D image\n",
      "     |      the \"rows\" or y-axis are the first dimension, and the \"columns\" or\n",
      "     |      x-axis are the second dimension.\n",
      "     |      \n",
      "     |      If the data is scaled using the BZERO and BSCALE parameters, this\n",
      "     |      attribute returns the data scaled to its physical values unless the\n",
      "     |      file was opened with ``do_not_scale_image_data=True``.\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  standard_keyword_comments = {'BITPIX': 'array data type', 'GCOUNT': 'n...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self)\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self)\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Write the HDU to a new file. This is a convenience method to\n",
      "     |      provide a user easier output interface if only one HDU needs\n",
      "     |      to be written to a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : path-like or file-like\n",
      "     |          Output FITS file.  If the file object is already opened, it must\n",
      "     |          be opened in a writeable mode.\n",
      "     |      \n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` if ``False`` and the output file exists. Default is\n",
      "     |          ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards\n",
      "     |          to the header of the HDU when written to the file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file-like\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Section(builtins.object)\n",
      "     |  Section(hdu)\n",
      "     |  \n",
      "     |  Image section.\n",
      "     |  \n",
      "     |  Slices of this object load the corresponding section of an image array from\n",
      "     |  the underlying FITS file on disk, and applies any BSCALE/BZERO factors.\n",
      "     |  \n",
      "     |  Section slices cannot be assigned to, and modifications to a section are\n",
      "     |  not saved back to the underlying file.\n",
      "     |  \n",
      "     |  See the :ref:`data-sections` section of the Astropy documentation for more\n",
      "     |  details.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, hdu)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class StreamingHDU(builtins.object)\n",
      "     |  StreamingHDU(name, header)\n",
      "     |  \n",
      "     |  A class that provides the capability to stream data to a FITS file\n",
      "     |  instead of requiring data to all be written at once.\n",
      "     |  \n",
      "     |  The following pseudocode illustrates its use::\n",
      "     |  \n",
      "     |      header = astropy.io.fits.Header()\n",
      "     |  \n",
      "     |      for all the cards you need in the header:\n",
      "     |          header[key] = (value, comment)\n",
      "     |  \n",
      "     |      shdu = astropy.io.fits.StreamingHDU('filename.fits', header)\n",
      "     |  \n",
      "     |      for each piece of data:\n",
      "     |          shdu.write(data)\n",
      "     |  \n",
      "     |      shdu.close()\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      # Support the 'with' statement\n",
      "     |  \n",
      "     |  __exit__(self, type, value, traceback)\n",
      "     |  \n",
      "     |  __init__(self, name, header)\n",
      "     |      Construct a `StreamingHDU` object given a file name and a header.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : path-like or file-like\n",
      "     |          The file to which the header and data will be streamed. If opened,\n",
      "     |          the file object must be opened in a writeable binary mode such as\n",
      "     |          'wb' or 'ab+'.\n",
      "     |      \n",
      "     |      header : `Header` instance\n",
      "     |          The header object associated with the data to be written\n",
      "     |          to the file.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The file will be opened and the header appended to the end of\n",
      "     |      the file.  If the file does not already exist, it will be\n",
      "     |      created, and if the header represents a Primary header, it\n",
      "     |      will be written to the beginning of the file.  If the file\n",
      "     |      does not exist and the provided header is not a Primary\n",
      "     |      header, a default Primary HDU will be inserted at the\n",
      "     |      beginning of the file and the provided header will be added as\n",
      "     |      the first extension.  If the file does already exist, but the\n",
      "     |      provided header represents a Primary header, the header will\n",
      "     |      be modified to an image extension header and appended to the\n",
      "     |      end of the file.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close the physical FITS file.\n",
      "     |  \n",
      "     |  write(self, data)\n",
      "     |      Write the given data to the stream.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : ndarray\n",
      "     |          Data to stream to the file.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      writecomplete : int\n",
      "     |          Flag that when `True` indicates that all of the required\n",
      "     |          data has been written to the stream.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only the amount of data specified in the header provided to the class\n",
      "     |      constructor may be written to the stream.  If the provided data would\n",
      "     |      cause the stream to overflow, an `OSError` exception is\n",
      "     |      raised and the data is not written. Once sufficient data has been\n",
      "     |      written to the stream to satisfy the amount specified in the header,\n",
      "     |      the stream is padded to fill a complete FITS block and no more data\n",
      "     |      will be accepted. An attempt to write more data after the stream has\n",
      "     |      been filled will raise an `OSError` exception. If the\n",
      "     |      dtype of the input data does not match what is expected by the header,\n",
      "     |      a `TypeError` exception is raised.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Return the size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TableHDU(_TableBaseHDU)\n",
      "     |  TableHDU(data=None, header=None, name=None, ver=None, character_as_bytes=False)\n",
      "     |  \n",
      "     |  FITS ASCII table extension HDU class.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : array or `FITS_rec`\n",
      "     |      Data to be used.\n",
      "     |  header : `Header`\n",
      "     |      Header to be used.\n",
      "     |  name : str\n",
      "     |      Name to be populated in ``EXTNAME`` keyword.\n",
      "     |  ver : int > 0 or None, optional\n",
      "     |      The ver of the HDU, will be the value of the keyword ``EXTVER``.\n",
      "     |      If not given or None, it defaults to the value of the ``EXTVER``\n",
      "     |      card of the ``header`` or 1.\n",
      "     |      (default: None)\n",
      "     |  character_as_bytes : bool\n",
      "     |      Whether to return bytes for string columns. By default this is `False`\n",
      "     |      and (unicode) strings are returned, but this does not respect memory\n",
      "     |      mapping and loads the whole column in memory when accessed.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TableHDU\n",
      "     |      _TableBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      _TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, ver=None, character_as_bytes=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      This is an abstract type that implements the shared functionality of\n",
      "     |      the ASCII and Binary Table HDU types, which should be used instead of\n",
      "     |      this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the table HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  update(self)\n",
      "     |      Update header keywords to reflect recent changes of columns.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from _TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, character_as_bytes=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs` -like\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      character_as_bytes : bool\n",
      "     |          Whether to return bytes for string columns when accessed from the\n",
      "     |          HDU. By default this is `False` and (unicode) strings are returned,\n",
      "     |          but for large tables this may use up a lot of memory.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self)\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self)\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file-like\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``\"+warn\"``, or ``\"+exception\"``\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Undefined(builtins.object)\n",
      "     |  Undefined value.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class VerifyError(builtins.Exception)\n",
      "     |  Verify exception class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VerifyError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    append(filename, data, header=None, checksum=False, verify=True, **kwargs)\n",
      "        Append the header/data to FITS file if filename exists, create if not.\n",
      "        \n",
      "        If only ``data`` is supplied, a minimal header is created.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            File to write to.  If opened, must be opened for update (rb+) unless it\n",
      "            is a new file, then it must be opened for append (ab+).  A file or\n",
      "            `~gzip.GzipFile` object opened for update will be closed after return.\n",
      "        \n",
      "        data : array, :class:`~astropy.table.Table`, or `~astropy.io.fits.Group`\n",
      "            The new data used for appending.\n",
      "        \n",
      "        header : `Header` object, optional\n",
      "            The header associated with ``data``.  If `None`, an appropriate header\n",
      "            will be created for the data object supplied.\n",
      "        \n",
      "        checksum : bool, optional\n",
      "            When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards to the header\n",
      "            of the HDU when written to the file.\n",
      "        \n",
      "        verify : bool, optional\n",
      "            When `True`, the existing FITS file will be read in to verify it for\n",
      "            correctness before appending.  When `False`, content is simply appended\n",
      "            to the end of the file.  Setting ``verify`` to `False` can be much\n",
      "            faster.\n",
      "        \n",
      "        kwargs\n",
      "            Additional arguments are passed to:\n",
      "        \n",
      "            - `~astropy.io.fits.writeto` if the file does not exist or is empty.\n",
      "              In this case ``output_verify`` is the only possible argument.\n",
      "            - `~astropy.io.fits.open` if ``verify`` is True or if ``filename``\n",
      "              is a file object.\n",
      "            - Otherwise no additional arguments can be used.\n",
      "    \n",
      "    delval(filename, keyword, *args, **kwargs)\n",
      "        Delete all instances of keyword from a header in a FITS file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        \n",
      "        filename : path-like or file-like\n",
      "            Name of the FITS file, or file object If opened, mode must be update\n",
      "            (rb+).  An opened file object or `~gzip.GzipFile` object will be closed\n",
      "            upon return.\n",
      "        \n",
      "        keyword : str, int\n",
      "            Keyword name or index\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.\n",
      "            See `getdata` for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function automatically specifies ``do_not_scale_image_data\n",
      "            = True`` when opening the file so that values can be retrieved from the\n",
      "            unmodified header.\n",
      "    \n",
      "    getdata(filename, *args, header=None, lower=None, upper=None, view=None, **kwargs)\n",
      "        Get the data from an extension of a FITS file (and optionally the\n",
      "        header).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            File to get data from.  If opened, mode must be one of the\n",
      "            following rb, rb+, or ab+.\n",
      "        \n",
      "        ext\n",
      "            The rest of the arguments are for extension specification.\n",
      "            They are flexible and are best illustrated by examples.\n",
      "        \n",
      "            No extra arguments implies the primary header::\n",
      "        \n",
      "                getdata('in.fits')\n",
      "        \n",
      "            .. note::\n",
      "                Exclusive to ``getdata``: if extension is not specified\n",
      "                and primary header contains no data, ``getdata`` attempts\n",
      "                to retrieve data from first extension.\n",
      "        \n",
      "            By extension number::\n",
      "        \n",
      "                getdata('in.fits', 0)      # the primary header\n",
      "                getdata('in.fits', 2)      # the second extension\n",
      "                getdata('in.fits', ext=2)  # the second extension\n",
      "        \n",
      "            By name, i.e., ``EXTNAME`` value (if unique)::\n",
      "        \n",
      "                getdata('in.fits', 'sci')\n",
      "                getdata('in.fits', extname='sci')  # equivalent\n",
      "        \n",
      "            Note ``EXTNAME`` values are not case sensitive\n",
      "        \n",
      "            By combination of ``EXTNAME`` and EXTVER`` as separate\n",
      "            arguments or as a tuple::\n",
      "        \n",
      "                getdata('in.fits', 'sci', 2)  # EXTNAME='SCI' & EXTVER=2\n",
      "                getdata('in.fits', extname='sci', extver=2)  # equivalent\n",
      "                getdata('in.fits', ('sci', 2))  # equivalent\n",
      "        \n",
      "            Ambiguous or conflicting specifications will raise an exception::\n",
      "        \n",
      "                getdata('in.fits', ext=('sci',1), extname='err', extver=2)\n",
      "        \n",
      "        header : bool, optional\n",
      "            If `True`, return the data and the header of the specified HDU as a\n",
      "            tuple.\n",
      "        \n",
      "        lower, upper : bool, optional\n",
      "            If ``lower`` or ``upper`` are `True`, the field names in the\n",
      "            returned data object will be converted to lower or upper case,\n",
      "            respectively.\n",
      "        \n",
      "        view : ndarray, optional\n",
      "            When given, the data will be returned wrapped in the given ndarray\n",
      "            subclass by calling::\n",
      "        \n",
      "               data.view(view)\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        array : ndarray or `~numpy.recarray` or `~astropy.io.fits.Group`\n",
      "            Type depends on the type of the extension being referenced.\n",
      "        \n",
      "            If the optional keyword ``header`` is set to `True`, this\n",
      "            function will return a (``data``, ``header``) tuple.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        IndexError\n",
      "            If no data is found in searched extensions.\n",
      "    \n",
      "    getheader(filename, *args, **kwargs)\n",
      "        Get the header from an extension of a FITS file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            File to get header from.  If an opened file object, its mode\n",
      "            must be one of the following rb, rb+, or ab+).\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.  See the\n",
      "            `getdata` documentation for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        header : `Header` object\n",
      "    \n",
      "    getval(filename, keyword, *args, **kwargs)\n",
      "        Get a keyword's value from a header in a FITS file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            Name of the FITS file, or file object (if opened, mode must be\n",
      "            one of the following rb, rb+, or ab+).\n",
      "        \n",
      "        keyword : str\n",
      "            Keyword name\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.\n",
      "            See `getdata` for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function automatically specifies ``do_not_scale_image_data\n",
      "            = True`` when opening the file so that values can be retrieved from the\n",
      "            unmodified header.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        keyword value : str, int, or float\n",
      "    \n",
      "    info(filename, output=None, **kwargs)\n",
      "        Print the summary information on a FITS file.\n",
      "        \n",
      "        This includes the name, type, length of header, data shape and type\n",
      "        for each extension.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            FITS file to obtain info from.  If opened, mode must be one of\n",
      "            the following: rb, rb+, or ab+ (i.e. the file must be readable).\n",
      "        \n",
      "        output : file, bool, optional\n",
      "            A file-like object to write the output to.  If ``False``, does not\n",
      "            output to a file and instead returns a list of tuples representing the\n",
      "            HDU info.  Writes to ``sys.stdout`` by default.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function sets ``ignore_missing_end=True`` by default.\n",
      "    \n",
      "    open = fitsopen(name, mode='readonly', memmap=None, save_backup=False, cache=True, lazy_load_hdus=None, ignore_missing_simple=False, **kwargs)\n",
      "        Factory function to open a FITS file and return an `HDUList` object.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        name : str, file-like or `pathlib.Path`\n",
      "            File to be opened.\n",
      "        \n",
      "        mode : str, optional\n",
      "            Open mode, 'readonly', 'update', 'append', 'denywrite', or\n",
      "            'ostream'. Default is 'readonly'.\n",
      "        \n",
      "            If ``name`` is a file object that is already opened, ``mode`` must\n",
      "            match the mode the file was opened with, readonly (rb), update (rb+),\n",
      "            append (ab+), ostream (w), denywrite (rb)).\n",
      "        \n",
      "        memmap : bool, optional\n",
      "            Is memory mapping to be used? This value is obtained from the\n",
      "            configuration item ``astropy.io.fits.Conf.use_memmap``.\n",
      "            Default is `True`.\n",
      "        \n",
      "        save_backup : bool, optional\n",
      "            If the file was opened in update or append mode, this ensures that\n",
      "            a backup of the original file is saved before any changes are flushed.\n",
      "            The backup has the same name as the original file with \".bak\" appended.\n",
      "            If \"file.bak\" already exists then \"file.bak.1\" is used, and so on.\n",
      "            Default is `False`.\n",
      "        \n",
      "        cache : bool, optional\n",
      "            If the file name is a URL, `~astropy.utils.data.download_file` is used\n",
      "            to open the file.  This specifies whether or not to save the file\n",
      "            locally in Astropy's download cache. Default is `True`.\n",
      "        \n",
      "        lazy_load_hdus : bool, optional\n",
      "            To avoid reading all the HDUs and headers in a FITS file immediately\n",
      "            upon opening.  This is an optimization especially useful for large\n",
      "            files, as FITS has no way of determining the number and offsets of all\n",
      "            the HDUs in a file without scanning through the file and reading all\n",
      "            the headers. Default is `True`.\n",
      "        \n",
      "            To disable lazy loading and read all HDUs immediately (the old\n",
      "            behavior) use ``lazy_load_hdus=False``.  This can lead to fewer\n",
      "            surprises--for example with lazy loading enabled, ``len(hdul)``\n",
      "            can be slow, as it means the entire FITS file needs to be read in\n",
      "            order to determine the number of HDUs.  ``lazy_load_hdus=False``\n",
      "            ensures that all HDUs have already been loaded after the file has\n",
      "            been opened.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "        \n",
      "        uint : bool, optional\n",
      "            Interpret signed integer data where ``BZERO`` is the central value and\n",
      "            ``BSCALE == 1`` as unsigned integer data.  For example, ``int16`` data\n",
      "            with ``BZERO = 32768`` and ``BSCALE = 1`` would be treated as\n",
      "            ``uint16`` data. Default is `True` so that the pseudo-unsigned\n",
      "            integer convention is assumed.\n",
      "        \n",
      "        ignore_missing_end : bool, optional\n",
      "            Do not raise an exception when opening a file that is missing an\n",
      "            ``END`` card in the last header. Default is `False`.\n",
      "        \n",
      "        ignore_missing_simple : bool, optional\n",
      "            Do not raise an exception when the SIMPLE keyword is missing.\n",
      "            Default is `False`.\n",
      "        \n",
      "            .. versionadded:: 4.2\n",
      "        \n",
      "        checksum : bool, str, optional\n",
      "            If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card values\n",
      "            (when present in the HDU header) match the header and data of all HDU's\n",
      "            in the file.  Updates to a file that already has a checksum will\n",
      "            preserve and update the existing checksums unless this argument is\n",
      "            given a value of 'remove', in which case the CHECKSUM and DATASUM\n",
      "            values are not checked, and are removed when saving changes to the\n",
      "            file. Default is `False`.\n",
      "        \n",
      "        disable_image_compression : bool, optional\n",
      "            If `True`, treats compressed image HDU's like normal binary table\n",
      "            HDU's.  Default is `False`.\n",
      "        \n",
      "        do_not_scale_image_data : bool, optional\n",
      "            If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "            when read.  Default is `False`.\n",
      "        \n",
      "        character_as_bytes : bool, optional\n",
      "            Whether to return bytes for string columns, otherwise unicode strings\n",
      "            are returned, but this does not respect memory mapping and loads the\n",
      "            whole column in memory when accessed. Default is `False`.\n",
      "        \n",
      "        ignore_blank : bool, optional\n",
      "            If `True`, the BLANK keyword is ignored if present.\n",
      "            Default is `False`.\n",
      "        \n",
      "        scale_back : bool, optional\n",
      "            If `True`, when saving changes to a file that contained scaled image\n",
      "            data, restore the data to the original type and reapply the original\n",
      "            BSCALE/BZERO values. This could lead to loss of accuracy if scaling\n",
      "            back to integer values after performing floating point operations on\n",
      "            the data. Default is `False`.\n",
      "        \n",
      "        output_verify : str\n",
      "            Output verification option.  Must be one of ``\"fix\"``,\n",
      "            ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "            ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "            ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "            (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        hdulist : `HDUList`\n",
      "            `HDUList` containing all of the header data units in the file.\n",
      "    \n",
      "    printdiff(inputa, inputb, *args, **kwargs)\n",
      "        Compare two parts of a FITS file, including entire FITS files,\n",
      "        FITS `HDUList` objects and FITS ``HDU`` objects.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        inputa : str, `HDUList` object, or ``HDU`` object\n",
      "            The filename of a FITS file, `HDUList`, or ``HDU``\n",
      "            object to compare to ``inputb``.\n",
      "        \n",
      "        inputb : str, `HDUList` object, or ``HDU`` object\n",
      "            The filename of a FITS file, `HDUList`, or ``HDU``\n",
      "            object to compare to ``inputa``.\n",
      "        \n",
      "        ext, extname, extver\n",
      "            Additional positional arguments are for extension specification if your\n",
      "            inputs are string filenames (will not work if\n",
      "            ``inputa`` and ``inputb`` are ``HDU`` objects or `HDUList` objects).\n",
      "            They are flexible and are best illustrated by examples.  In addition\n",
      "            to using these arguments positionally you can directly call the\n",
      "            keyword parameters ``ext``, ``extname``.\n",
      "        \n",
      "            By extension number::\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits', 0)      # the primary HDU\n",
      "                printdiff('inA.fits', 'inB.fits', 2)      # the second extension\n",
      "                printdiff('inA.fits', 'inB.fits', ext=2)  # the second extension\n",
      "        \n",
      "            By name, i.e., ``EXTNAME`` value (if unique). ``EXTNAME`` values are\n",
      "            not case sensitive:\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits', 'sci')\n",
      "                printdiff('inA.fits', 'inB.fits', extname='sci')  # equivalent\n",
      "        \n",
      "            By combination of ``EXTNAME`` and ``EXTVER`` as separate\n",
      "            arguments or as a tuple::\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits', 'sci', 2)    # EXTNAME='SCI'\n",
      "                                                               # & EXTVER=2\n",
      "                printdiff('inA.fits', 'inB.fits', extname='sci', extver=2)\n",
      "                                                               # equivalent\n",
      "                printdiff('inA.fits', 'inB.fits', ('sci', 2))  # equivalent\n",
      "        \n",
      "            Ambiguous or conflicting specifications will raise an exception::\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits',\n",
      "                          ext=('sci', 1), extname='err', extver=2)\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `~astropy.io.fits.FITSDiff`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The primary use for the `printdiff` function is to allow quick print out\n",
      "        of a FITS difference report and will write to ``sys.stdout``.\n",
      "        To save the diff report to a file please use `~astropy.io.fits.FITSDiff`\n",
      "        directly.\n",
      "    \n",
      "    register_hdu(hducls) method of astropy.io.fits.hdu.base._BaseHDUMeta instance\n",
      "    \n",
      "    setval(filename, keyword, *args, value=None, comment=None, before=None, after=None, savecomment=False, **kwargs)\n",
      "        Set a keyword's value from a header in a FITS file.\n",
      "        \n",
      "        If the keyword already exists, it's value/comment will be updated.\n",
      "        If it does not exist, a new card will be created and it will be\n",
      "        placed before or after the specified location.  If no ``before`` or\n",
      "        ``after`` is specified, it will be appended at the end.\n",
      "        \n",
      "        When updating more than one keyword in a file, this convenience\n",
      "        function is a much less efficient approach compared with opening\n",
      "        the file for update, modifying the header, and closing the file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            Name of the FITS file, or file object If opened, mode must be update\n",
      "            (rb+).  An opened file object or `~gzip.GzipFile` object will be closed\n",
      "            upon return.\n",
      "        \n",
      "        keyword : str\n",
      "            Keyword name\n",
      "        \n",
      "        value : str, int, float, optional\n",
      "            Keyword value (default: `None`, meaning don't modify)\n",
      "        \n",
      "        comment : str, optional\n",
      "            Keyword comment, (default: `None`, meaning don't modify)\n",
      "        \n",
      "        before : str, int, optional\n",
      "            Name of the keyword, or index of the card before which the new card\n",
      "            will be placed.  The argument ``before`` takes precedence over\n",
      "            ``after`` if both are specified (default: `None`).\n",
      "        \n",
      "        after : str, int, optional\n",
      "            Name of the keyword, or index of the card after which the new card will\n",
      "            be placed. (default: `None`).\n",
      "        \n",
      "        savecomment : bool, optional\n",
      "            When `True`, preserve the current comment for an existing keyword.  The\n",
      "            argument ``savecomment`` takes precedence over ``comment`` if both\n",
      "            specified.  If ``comment`` is not specified then the current comment\n",
      "            will automatically be preserved  (default: `False`).\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.\n",
      "            See `getdata` for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function automatically specifies ``do_not_scale_image_data\n",
      "            = True`` when opening the file so that values can be retrieved from the\n",
      "            unmodified header.\n",
      "    \n",
      "    table_to_hdu(table, character_as_bytes=False)\n",
      "        Convert an `~astropy.table.Table` object to a FITS\n",
      "        `~astropy.io.fits.BinTableHDU`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        table : astropy.table.Table\n",
      "            The table to convert.\n",
      "        character_as_bytes : bool\n",
      "            Whether to return bytes for string columns when accessed from the HDU.\n",
      "            By default this is `False` and (unicode) strings are returned, but for\n",
      "            large tables this may use up a lot of memory.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        table_hdu : `~astropy.io.fits.BinTableHDU`\n",
      "            The FITS binary table HDU.\n",
      "    \n",
      "    tabledump(filename, datafile=None, cdfile=None, hfile=None, ext=1, overwrite=False)\n",
      "        Dump a table HDU to a file in ASCII format.  The table may be\n",
      "        dumped in three separate files, one containing column definitions,\n",
      "        one containing header parameters, and one for table data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            Input fits file.\n",
      "        \n",
      "        datafile : path-like or file-like, optional\n",
      "            Output data file.  The default is the root name of the input\n",
      "            fits file appended with an underscore, followed by the\n",
      "            extension number (ext), followed by the extension ``.txt``.\n",
      "        \n",
      "        cdfile : path-like or file-like, optional\n",
      "            Output column definitions file.  The default is `None`,\n",
      "            no column definitions output is produced.\n",
      "        \n",
      "        hfile : path-like or file-like, optional\n",
      "            Output header parameters file.  The default is `None`,\n",
      "            no header parameters output is produced.\n",
      "        \n",
      "        ext : int\n",
      "            The number of the extension containing the table HDU to be\n",
      "            dumped.\n",
      "        \n",
      "        overwrite : bool, optional\n",
      "            If ``True``, overwrite the output file if it exists. Raises an\n",
      "            ``OSError`` if ``False`` and the output file exists. Default is\n",
      "            ``False``.\n",
      "        \n",
      "            .. versionchanged:: 1.3\n",
      "               ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The primary use for the `tabledump` function is to allow editing in a\n",
      "        standard text editor of the table data and parameters.  The\n",
      "        `tableload` function can be used to reassemble the table from the\n",
      "        three ASCII files.\n",
      "        \n",
      "        \n",
      "        - **datafile:** Each line of the data file represents one row of table\n",
      "          data.  The data is output one column at a time in column order.  If\n",
      "          a column contains an array, each element of the column array in the\n",
      "          current row is output before moving on to the next column.  Each row\n",
      "          ends with a new line.\n",
      "        \n",
      "          Integer data is output right-justified in a 21-character field\n",
      "          followed by a blank.  Floating point data is output right justified\n",
      "          using 'g' format in a 21-character field with 15 digits of\n",
      "          precision, followed by a blank.  String data that does not contain\n",
      "          whitespace is output left-justified in a field whose width matches\n",
      "          the width specified in the ``TFORM`` header parameter for the\n",
      "          column, followed by a blank.  When the string data contains\n",
      "          whitespace characters, the string is enclosed in quotation marks\n",
      "          (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "          the field is replaced by a new line character.\n",
      "        \n",
      "          For column data containing variable length arrays ('P' format), the\n",
      "          array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "          integer length of the array for that row, left-justified in a\n",
      "          21-character field, followed by a blank.\n",
      "        \n",
      "          .. note::\n",
      "        \n",
      "              This format does *not* support variable length arrays using the\n",
      "              ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "              means is that this file format cannot support VLA columns in\n",
      "              tables stored in files that are over 2 GB in size.\n",
      "        \n",
      "          For column data representing a bit field ('X' format), each bit\n",
      "          value in the field is output right-justified in a 21-character field\n",
      "          as 1 (for true) or 0 (for false).\n",
      "        \n",
      "        - **cdfile:** Each line of the column definitions file provides the\n",
      "          definitions for one column in the table.  The line is broken up into\n",
      "          8, sixteen-character fields.  The first field provides the column\n",
      "          name (``TTYPEn``).  The second field provides the column format\n",
      "          (``TFORMn``).  The third field provides the display format\n",
      "          (``TDISPn``).  The fourth field provides the physical units\n",
      "          (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "          multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "          value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "          field provides the scale factor (``TSCALn``).  The eighth field\n",
      "          provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "          used to represent the case where no value is provided.\n",
      "        \n",
      "        - **hfile:** Each line of the header parameters file provides the\n",
      "          definition of a single HDU header card as represented by the card\n",
      "          image.\n",
      "    \n",
      "    tableload(datafile, cdfile, hfile=None)\n",
      "        Create a table from the input ASCII files.  The input is from up\n",
      "        to three separate files, one containing column definitions, one\n",
      "        containing header parameters, and one containing column data.  The\n",
      "        header parameters file is not required.  When the header\n",
      "        parameters file is absent a minimal header is constructed.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        datafile : path-like or file-like\n",
      "            Input data file containing the table data in ASCII format.\n",
      "        \n",
      "        cdfile : path-like or file-like\n",
      "            Input column definition file containing the names, formats,\n",
      "            display formats, physical units, multidimensional array\n",
      "            dimensions, undefined values, scale factors, and offsets\n",
      "            associated with the columns in the table.\n",
      "        \n",
      "        hfile : path-like or file-like, optional\n",
      "            Input parameter definition file containing the header\n",
      "            parameter definitions to be associated with the table.\n",
      "            If `None`, a minimal header is constructed.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The primary use for the `tableload` function is to allow the input of\n",
      "        ASCII data that was edited in a standard text editor of the table\n",
      "        data and parameters.  The tabledump function can be used to create the\n",
      "        initial ASCII files.\n",
      "        \n",
      "        \n",
      "        - **datafile:** Each line of the data file represents one row of table\n",
      "          data.  The data is output one column at a time in column order.  If\n",
      "          a column contains an array, each element of the column array in the\n",
      "          current row is output before moving on to the next column.  Each row\n",
      "          ends with a new line.\n",
      "        \n",
      "          Integer data is output right-justified in a 21-character field\n",
      "          followed by a blank.  Floating point data is output right justified\n",
      "          using 'g' format in a 21-character field with 15 digits of\n",
      "          precision, followed by a blank.  String data that does not contain\n",
      "          whitespace is output left-justified in a field whose width matches\n",
      "          the width specified in the ``TFORM`` header parameter for the\n",
      "          column, followed by a blank.  When the string data contains\n",
      "          whitespace characters, the string is enclosed in quotation marks\n",
      "          (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "          the field is replaced by a new line character.\n",
      "        \n",
      "          For column data containing variable length arrays ('P' format), the\n",
      "          array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "          integer length of the array for that row, left-justified in a\n",
      "          21-character field, followed by a blank.\n",
      "        \n",
      "          .. note::\n",
      "        \n",
      "              This format does *not* support variable length arrays using the\n",
      "              ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "              means is that this file format cannot support VLA columns in\n",
      "              tables stored in files that are over 2 GB in size.\n",
      "        \n",
      "          For column data representing a bit field ('X' format), each bit\n",
      "          value in the field is output right-justified in a 21-character field\n",
      "          as 1 (for true) or 0 (for false).\n",
      "        \n",
      "        - **cdfile:** Each line of the column definitions file provides the\n",
      "          definitions for one column in the table.  The line is broken up into\n",
      "          8, sixteen-character fields.  The first field provides the column\n",
      "          name (``TTYPEn``).  The second field provides the column format\n",
      "          (``TFORMn``).  The third field provides the display format\n",
      "          (``TDISPn``).  The fourth field provides the physical units\n",
      "          (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "          multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "          value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "          field provides the scale factor (``TSCALn``).  The eighth field\n",
      "          provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "          used to represent the case where no value is provided.\n",
      "        \n",
      "        - **hfile:** Each line of the header parameters file provides the\n",
      "          definition of a single HDU header card as represented by the card\n",
      "          image.\n",
      "    \n",
      "    unregister_hdu(hducls) method of astropy.io.fits.hdu.base._BaseHDUMeta instance\n",
      "    \n",
      "    update(filename, data, *args, **kwargs)\n",
      "        Update the specified extension with the input data/header.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            File to update.  If opened, mode must be update (rb+).  An opened file\n",
      "            object or `~gzip.GzipFile` object will be closed upon return.\n",
      "        \n",
      "        data : array, `~astropy.table.Table`, or `~astropy.io.fits.Group`\n",
      "            The new data used for updating.\n",
      "        \n",
      "        header : `Header` object, optional\n",
      "            The header associated with ``data``.  If `None`, an appropriate header\n",
      "            will be created for the data object supplied.\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are flexible: the 3rd argument can be the\n",
      "            header associated with the data.  If the 3rd argument is not a\n",
      "            `Header`, it (and other positional arguments) are assumed to be the\n",
      "            extension specification(s).  Header and extension specs can also be\n",
      "            keyword arguments.  For example::\n",
      "        \n",
      "                update(file, dat, hdr, 'sci')  # update the 'sci' extension\n",
      "                update(file, dat, 3)  # update the 3rd extension\n",
      "                update(file, dat, hdr, 3)  # update the 3rd extension\n",
      "                update(file, dat, 'sci', 2)  # update the 2nd SCI extension\n",
      "                update(file, dat, 3, header=hdr)  # update the 3rd extension\n",
      "                update(file, dat, header=hdr, ext=5)  # update the 5th extension\n",
      "        \n",
      "        **kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "    \n",
      "    writeto(filename, data, header=None, output_verify='exception', overwrite=False, checksum=False)\n",
      "        Create a new FITS file using the supplied data/header.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : path-like or file-like\n",
      "            File to write to.  If opened, must be opened in a writable binary\n",
      "            mode such as 'wb' or 'ab+'.\n",
      "        \n",
      "        data : array or `~numpy.recarray` or `~astropy.io.fits.Group`\n",
      "            data to write to the new file\n",
      "        \n",
      "        header : `Header` object, optional\n",
      "            the header associated with ``data``. If `None`, a header\n",
      "            of the appropriate type is created for the supplied data. This\n",
      "            argument is optional.\n",
      "        \n",
      "        output_verify : str\n",
      "            Output verification option.  Must be one of ``\"fix\"``, ``\"silentfix\"``,\n",
      "            ``\"ignore\"``, ``\"warn\"``, or ``\"exception\"``.  May also be any\n",
      "            combination of ``\"fix\"`` or ``\"silentfix\"`` with ``\"+ignore\"``,\n",
      "            ``+warn``, or ``+exception\" (e.g. ``\"fix+warn\"``).  See :ref:`verify`\n",
      "            for more info.\n",
      "        \n",
      "        overwrite : bool, optional\n",
      "            If ``True``, overwrite the output file if it exists. Raises an\n",
      "            ``OSError`` if ``False`` and the output file exists. Default is\n",
      "            ``False``.\n",
      "        \n",
      "            .. versionchanged:: 1.3\n",
      "               ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "        \n",
      "        checksum : bool, optional\n",
      "            If `True`, adds both ``DATASUM`` and ``CHECKSUM`` cards to the\n",
      "            headers of all HDU's written to the file.\n",
      "\n",
      "DATA\n",
      "    BITPIX2DTYPE = {-64: 'float64', -32: 'float32', 8: 'uint8', 16: 'int16...\n",
      "    DELAYED = <astropy.io.fits.hdu.base._Delayed object>\n",
      "    DTYPE2BITPIX = {'float32': -32, 'float64': -64, 'int16': 16, 'int32': ...\n",
      "    __all__ = ['Conf', 'conf', 'Card', 'Undefined', 'Column', 'ColDefs', '...\n",
      "    conf = <astropy.io.fits.Conf object>\n",
      "\n",
      "FILE\n",
      "    /home/mrabus/miniconda3/envs/py3/lib/python3.9/site-packages/astropy/io/fits/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbe5c5-0d6e-4f3d-a0c3-db7c2410e870",
   "metadata": {},
   "source": [
    "Ahora vamos a leer el archivo fits y imprimir sus datos generales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d289011-d56d-4ea6-8900-32a8fdc99491",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitshdu = fits.open( os.path.join(datapath,fitsimage) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9997f366-80ea-4796-922d-bcdebc2bebeb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/mrabus/DECam_data/c4d_210418_025650_ori.fits.fz\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU     150   ()      \n",
      "  1  S1            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  2  S2            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  3  S3            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  4  N1            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  5  N2            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  6  N3            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  7  S8            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  8  S9            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      "  9  S14           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 10  S15           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 11  S20           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 12  S25           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 13  N8            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 14  N9            1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 15  N14           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 16  N15           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 17  N20           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 18  N25           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 19  S10           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 20  S11           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 21  S12           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 22  S13           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 23  S18           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 24  S19           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 25  S16           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 26  S17           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 27  S21           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 28  S22           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 29  S23           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 30  S24           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 31  S26           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 32  S27           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 33  S28           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 34  S29           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 35  S30           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 36  S31           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 37  N4            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 38  N5            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 39  N6            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 40  N7            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 41  S4            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 42  S5            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 43  S6            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 44  S7            1 CompImageHDU    100   (2160, 4146)   int16   \n",
      " 45  N10           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 46  N11           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 47  N12           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 48  N13           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 49  N18           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 50  N19           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 51  N16           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 52  N17           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 53  N21           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 54  N22           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 55  N23           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 56  N24           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 57  N26           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 58  N27           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 59  N28           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 60  N29           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 61  N30           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 62  N31           1 CompImageHDU    102   (2160, 4146)   int16   \n",
      " 63  FS1           1 CompImageHDU     98   (2160, 2098)   int16   \n",
      " 64  FS2           1 CompImageHDU     98   (2160, 2098)   int16   \n",
      " 65  FS3           1 CompImageHDU     98   (2160, 2098)   int16   \n",
      " 66  FS4           1 CompImageHDU    114   (2160, 2098)   int16   \n",
      " 67  FN1           1 CompImageHDU     98   (2160, 2098)   int16   \n",
      " 68  FN2           1 CompImageHDU     98   (2160, 2098)   int16   \n",
      " 69  FN3           1 CompImageHDU     98   (2160, 2098)   int16   \n",
      " 70  FN4           1 CompImageHDU    100   (2160, 2098)   int16   \n"
     ]
    }
   ],
   "source": [
    "fitshdu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a01f5-7e4c-47d6-b58d-7397e9fb7d15",
   "metadata": {},
   "source": [
    "Veamos que un fits tiene diferentes unidades, que llaman HDU (\"Header Data Units\"). La unidad 0 tiene generalmente solo una cabecera con informacion de todos los chips.\n",
    "Despues de la unidad 0, cada otra unidad tienen una cabecera mas sus datos correspondientes.\n",
    "\n",
    "![Header](markdown-img/Fitsfile_schematic.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37d9c4a-ee90-4e80-aeb0-a46ba0d4cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "header0 = fits.getheader( os.path.join(datapath,fitsimage), ext=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624b14a6-6b4e-4399-8a4c-b8be92c512df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIMPLE  =                    T / conforms to FITS standard                      \n",
       "BITPIX  =                    8 / array data type                                \n",
       "NAXIS   =                    0 / number of array dimensions                     \n",
       "EXTEND  =                    T                                                  \n",
       "NEXTEND =                   70 / Number of extensions                           \n",
       "PROCTYPE= 'raw     '           / Data processing level                          \n",
       "PRODTYPE= 'image   '           / Data product type                              \n",
       "DETSIZE = '[1:29400,1:29050]'  / Detector size                                  \n",
       "PIXSCAL1=                 0.27 / [arcsec/pixel] Pixel scale, axis 1             \n",
       "PIXSCAL2=                 0.27 / [arcsec/pixel] Pixel scale, axis 2             \n",
       "FILENAME= 'DECam_00986163.fits' / Filename                                      \n",
       "OBS-LONG=    70.81489000000001 / [deg] Observatory east longitude               \n",
       "TELESCOP= 'CTIO 4.0-m telescope' / Telescope name                               \n",
       "OBSERVAT= 'CTIO    '           / Observatory name                               \n",
       "OBS-LAT =            -30.16606 / [deg] Observatory latitude                     \n",
       "OBS-ELEV=               2215.0 / [m] Observatory elevation                      \n",
       "INSTRUME= 'DECam   '           / Instrument used to obtain these data           \n",
       "EXPREQ  =                130.0 / [s] Requested exposure duration                \n",
       "EXPTIME =                130.0 / [s] Exposure duration                          \n",
       "DARKTIME=          131.2279398 / [s] Dark time                                  \n",
       "OBSID   = 'ct4m20210418t025650' / Unique Observation ID                         \n",
       "DATE-OBS= '2021-04-18T02:56:50.868320' / DateTime of observation start (UTC)    \n",
       "TIME-OBS= '02:56:50.868320'    / Time of observation start (UTC)                \n",
       "MJD-OBS =       59322.12281098 / MJD of observation start                       \n",
       "OPENSHUT= '2021-04-18T02:56:51.037250' / Time when shutter opened (UTC)         \n",
       "RADESYS = 'FK5     '           / Telescope coordinate system                    \n",
       "TIMESYS = 'UTC     '           / Time system                                    \n",
       "EXPNUM  =               986163 / DECam exposure number                          \n",
       "OBJECT  = 'COSMOS-3'           / Object name                                    \n",
       "OBSTYPE = 'object  '           / Observation type                               \n",
       "CAMSHUT = 'Open    '           / Camera shutter at exposure start               \n",
       "PROGRAM = 'Deep Drilling in the Time Domain with DECam' / Current observing orog\n",
       "OBSERVER= 'M. Graham'          / Observer name(s)                               \n",
       "PROPOSER= 'Graham  '           / Proposal Principle Investigator                \n",
       "DTPI    = 'Graham  '           / Proposal Principle Investigator (iSTB)         \n",
       "PROPID  = '2021A-0113'         / Proposal ID                                    \n",
       "EXCLUDED= '' / DECam components not used for this frame                         \n",
       "SEQID   = 'COSMOS-DDF-SEQ-B'   / Sequence name                                  \n",
       "SEQNUM  =                    1 / Number of image in sequence                    \n",
       "AOS     =                    T / AOS data available if true                     \n",
       "BCAM    =                    F / BCAM data available if true                    \n",
       "GUIDER  =                    1 / Guider (0-absent,1-ok,2-lost star,3-los        \n",
       "SKYSTAT =                    T / Cloud camera (RASICAM) available if true       \n",
       "FILTER  = 'i DECam SDSS c0003 7835.0 1470.0' / Unique filter identifier         \n",
       "FILTPOS = 'cassette_3'         / Filter position in FCM                         \n",
       "INSTANCE= 'DECam_20210417'     / SISPI instance name                            \n",
       "ERRORS  = 'None    '           / SISPI readout errors                           \n",
       "TELEQUIN=               2000.0 / Equinox of telescope coordinates               \n",
       "TELSTAT = 'Track   '           / Telescope tracking status                      \n",
       "RA      = '10:03:07.200'       / [HH:MM:SS] Target RA                           \n",
       "DEC     = '01:45:00.000'       / [DD:MM:SS] Target DEC                          \n",
       "TELRA   = '10:03:07.477'       / [HH:MM:SS] Telescope RA                        \n",
       "TELDEC  = '01:45:00.000'       / [DD:MM:SS] Telescope DEC                       \n",
       "HA      = '01:54:56.010'       / [HH:MM:SS] Telescope hour angle                \n",
       "ZD      =                41.93 / [deg] Telescope zenith distance                \n",
       "AZ      =             314.1669 / [deg] Telescope azimuth angle                  \n",
       "DOMEAZ  =              315.155 / [deg] Dome azimuth angle                       \n",
       "ZPDELRA =            -138.9716 / [arcsec] Telescope zeropoint adjustment (RA)   \n",
       "ZPDELDEC=                -22.3 / [arcsec] Telescope zeropoint adjustment (DEC)  \n",
       "TELFOCUS= '1021.42,-989.78,2630.00,-89.91,-55.77,-0.00' / DECam hexapod settings\n",
       "VSUB    =                    T / True if CCD substrate voltage is on            \n",
       "GSKYPHOT=                    T / RASICAM global sky clear flag                  \n",
       "LSKYPHOT=                    F / RASICAM local sky clear flag                   \n",
       "WINDSPD =               17.703 / [m/s] Wind speed                               \n",
       "WINDDIR =                 33.0 / [deg] Wind direction (from North)              \n",
       "HUMIDITY=                 32.0 / [%] Ambient relative humidity (outside)        \n",
       "PRESSURE=                780.0 / [Torr] Barometric pressure (outside)           \n",
       "DIMMSEE = 'NaN     '           / [arcsec] DIMM Seeing                           \n",
       "DIMM2SEE=                0.644 / [arcsec] DIMM2 Seeing                          \n",
       "MASS2   =                  0.3 /  MASS(2) FSEE                                  \n",
       "ASTIG1  =                -0.02 / 4MAPS correction 1                             \n",
       "ASTIG2  =                 0.13 / 4MAPS correction 2                             \n",
       "OUTTEMP =                 13.1 / [deg C] Outside temperature                    \n",
       "AIRMASS =                 1.34 / Airmass                                        \n",
       "GSKYVAR =                0.027 / RASICAM global sky standard deviation          \n",
       "GSKYHOT =  0.08500000000000001 / RASICAM global sky fraction above threshold    \n",
       "LSKYVAR = 'NaN     '           / RASICAM local sky standard deviation           \n",
       "LSKYHOT = 'NaN     '           / RASICAM local sky fraction above threshold     \n",
       "LSKYPOW = 'NaN     '           / RASICAM local sky normalized power             \n",
       "MSURTEMP=               12.925 / [deg C] Mirror surface average temperature     \n",
       "MAIRTEMP=                 13.0 / [deg C] Mirror temperature above surface       \n",
       "UPTRTEMP=               12.846 / [deg C] Upper truss average temperature        \n",
       "LWTRTEMP= 'NaN     '           / [deg C] Lower truss average temperature        \n",
       "PMOSTEMP=                 12.6 / [deg C] Mirror top surface temperature         \n",
       "UTN-TEMP=                12.74 / [deg C] Upper truss temperature north          \n",
       "UTS-TEMP=               12.545 / [deg C] Upper truss temperature south          \n",
       "UTW-TEMP=                13.11 / [deg C] Upper truss temperature west           \n",
       "UTE-TEMP=                12.99 / [deg C] Upper truss temperature east           \n",
       "PMN-TEMP=                 12.8 / [deg C] Mirror north edge temperature          \n",
       "PMS-TEMP=                 13.0 / [deg C] Mirror south edge temperature          \n",
       "PMW-TEMP=                 12.9 / [deg C] Mirror west edge temperature           \n",
       "PME-TEMP=                 13.0 / [deg C] Mirror east edge temperature           \n",
       "DOMELOW =                13.44 / [deg C] Low dome temperature                   \n",
       "DOMEHIGH=                 13.0 / [deg C] High dome temperature                  \n",
       "DOMEFLOR=                 10.2 / [deg C] Dome floor temperature                 \n",
       "G-MEANX =              -0.0263 / [arcsec] Guider x-axis mean offset             \n",
       "G-MEANY =               0.0391 / [arcsec] Guider y-axis mean offset             \n",
       "DONUTFS4= '[1.89,1.44,-8.75,0.00,0.01,-0.08,0.25,0.03,-0.49,]' / Mean Wavefront \n",
       "DONUTFS3= '[0.29,0.57,8.76,0.11,-0.25,-0.03,0.01,0.05,-0.36,]' / Mean Wavefront \n",
       "DONUTFS2= '[1.15,1.76,-8.73,0.26,0.09,-0.21,0.13,0.42,-0.07,]' / Mean Wavefront \n",
       "DONUTFS1= '[0.92,0.36,8.73,0.46,0.05,0.08,-0.05,0.25,0.08,]' / Mean Wavefront fo\n",
       "G-FLXVAR=          7936722.059 / [arcsec] Guider mean guide star flux variances \n",
       "G-MEANXY= -0.00082299999999999 / [arcsec2] Guider (xy) 2nd moment mean offset   \n",
       "DONUTFN1= '[0.96,0.71,-8.84,-0.13,0.05,-0.13,-0.13,0.32,-0.26,]' / Mean Wavefron\n",
       "DONUTFN2= '[2.04,1.02,9.23,-0.07,0.14,-0.00,-0.02,0.44,-0.10,]' / Mean Wavefront\n",
       "DONUTFN3= '[1.49,1.05,-8.77,0.06,-0.03,-0.04,-0.21,0.12,0.33,]' / Mean Wavefront\n",
       "DONUTFN4= '[3.20,1.49,8.67,0.09,-0.25,0.02,-0.04,-0.04,0.24,]' / Mean Wavefront \n",
       "HIERARCH time_recorded = '2021-04-18T02:59:23.751097'                           \n",
       "G-FEEDBK= '10, 5   '           / [%] Guider feedback (HA, dec)                  \n",
       "G-CCDNUM=                    3 / Number of guide CCDs that remained active      \n",
       "DOXT    =                 0.02 / [arcsec] X-theta from donut analysis           \n",
       "G-MAXX  =               0.1645 / [arcsec] Guider x-axis maximum offset          \n",
       "FADZ    =                -6.26 / [um] FA Delta focus.                           \n",
       "FADY    =               300.54 / [um] FA Delta Y.                               \n",
       "FADX    =               103.27 / [um] FA Delta X.                               \n",
       "G-MODE  = 'auto    '           / Guider operation mode                          \n",
       "FAYT    =                -2.88 / [arcsec] FA Delta Y-theta.                     \n",
       "DODZ    =                -6.26 / [um] Delta-Z from donut analysis               \n",
       "DODY    =                -1.49 / [um] Y-decenter from donut analysis            \n",
       "DODX    =                -1.05 / [um] X-decenter from donut analysis            \n",
       "MULTIEXP=                    F / Frame contains multiple exposures if true      \n",
       "SKYUPDAT= '2021-04-18T02:56:19' / Time of last RASICAM exposure (UTC)           \n",
       "G-SEEING=                1.688 / [arcsec] Guider average seeing                 \n",
       "G-TRANSP=                0.871 / Guider average sky transparency                \n",
       "G-MEANY2=             0.009603 / [arcsec2] Guider (y) 2nd moment mean offset    \n",
       "DOYT    =                 -0.1 / [arcsec] Y-theta from donut analysis           \n",
       "G-LATENC=                1.313 / [s] Guider avg. latency between exposures      \n",
       "LUTVER  = 'not available'      / Hexapod Lookup Table version                   \n",
       "FAXT    =                -0.48 / [arcsec] FA Delta X-theta.                     \n",
       "G-MAXY  =               0.3982 / [arcsec] Guider y-axis maximum offset          \n",
       "G-MEANX2=             0.008529 / [arcsec2] Guider (x) 2nd moment mean offset    \n",
       "SISPIVER= 'trunk   '           / SISPI software version                         \n",
       "CONSTVER= 'DECAM:91'           / SISPI constants version                        \n",
       "HDRVER  = '13      '           / DECam fits header version                      \n",
       "CHECKVER= 'complement'         / Checksum software version                      \n",
       "COMMENT DECAT COSMOS DDF                                                        \n",
       "COMMENT MODIFIED:DATE-OBS,DTPI,INSTRUME,OBSERVAT,OBSID,OBSTYPE,PROCTYPE,PRODTYPE\n",
       "COMMENT ,PROPID,SIMPLE,TELESCOP,TIME-OBS                                        \n",
       "CHECKSUM= 'VgP5XdN2VdN2VdN2'   / HDU checksum updated 2021-04-19T09:19:35       \n",
       "DATASUM = '0       '           / data unit checksum updated 2021-04-19T09:19:35 \n",
       "DTNSANAM= 'c4d_210418_025650_ori.fits.fz'                                       \n",
       "DTSITE  = 'ct      '                                                            \n",
       "DTCALDAT= '2021-04-17'                                                          \n",
       "ODATEOBS= '2021-04-18T02:56:50.868320'                                          \n",
       "DTTELESC= 'ct4m    '                                                            \n",
       "DTINSTRU= 'decam   '                                                            \n",
       "DTACQNAM= '/data_local/images/DTS/2021A-0113/DECam_00986163.fits.fz'            \n",
       "DTPROPID= '2021A-0113'                                                          \n",
       "HISTORY Applied DTCALDATfromDATEOBSchile which added/modified fields (set()). Ol\n",
       "HISTORY d values were:                                                          "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5371b-7e6a-436a-99dc-b735270dd139",
   "metadata": {},
   "source": [
    "Ahora vamos a revisar la unidad 4, empezando con la cabecera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282afe6d-8b7b-40f5-a602-bced3a85c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "header4 = fits.getheader( os.path.join(datapath,fitsimage), ext=8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5489f-87e4-4082-bfb8-d23ae054a769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "header4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c1ec0-abfa-406f-8618-f6f773644426",
   "metadata": {},
   "source": [
    "Notamos que la cabecera de la unidad 4 es diferente. Porque es mas especifico para la ccd 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390e92ef-bb55-46e9-9586-5427031b7280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccd4 = fits.getdata( os.path.join(datapath,fitsimage), ext=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ffea12-4139-4aa8-8295-5e286a089447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18182,  8245,  7660, ...,  6713,  6346, 17029],\n",
       "       [ 3713,  3336,  3024, ...,  2329,  2627,  2998],\n",
       "       [ 3658,  3283,  2971, ...,  2285,  2588,  2954],\n",
       "       ...,\n",
       "       [ 3465,  3086,  2778, ...,  2126,  2422,  2793],\n",
       "       [ 3464,  3087,  2779, ...,  2124,  2423,  2794],\n",
       "       [ 3464,  3085,  2777, ...,  2123,  2421,  2795]], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccd4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d458812-1f64-44e1-9262-736c3d3736d1",
   "metadata": {},
   "source": [
    "Los datos es simplement un array con valores.\n",
    "![CCD](markdown-img/CCD-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd5d784-6d8b-461d-affe-13f4a0e91e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7feaa576ff70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "image1 = ax.imshow(ccd4, cmap='gray') #cmap='gray' significa blanco y negro\n",
    "fig.colorbar(image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007aa81-ae3e-496e-b7dd-c075c28609ec",
   "metadata": {},
   "source": [
    "En el siguiente paso hacemos un zoom a una region. Un zoom significa simplemente que solo hacemos un plot de parte del array. En el caso abajo en x desde 1500 hasta 1700 e y desde 1500 hasta 1700."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36870c9c-80a7-4ebe-a338-4951f9745f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "image2 = ax.imshow(ccd4[1700:2000,1800:2000], cmap='gray') #cmap='gray' significa blanco y negro\n",
    "fig.colorbar(image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd018f0-5f36-48bc-8bc5-f41b7e341b7d",
   "metadata": {},
   "source": [
    "Ahora mejoramos la vizualicioncion un poco. Igual como en la tele o monitor hay ajustes como el brillo y contraste. Lo mismo podemos hacer al plotear los imagenes. Existen diferentes intervalos para normaliza y visualizar una imagen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1daaf77-4f0a-4814-8214-2beca707e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los paquetes que hacen estos calculos:\n",
    "from astropy.visualization import ImageNormalize\n",
    "from astropy.visualization import simple_norm, MinMaxInterval, PercentileInterval, ZScaleInterval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09cf6a-21e8-4216-8be0-7019c188d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ZScaleInterval()\n",
    "norm = ImageNormalize(ccd4, interval=ZScaleInterval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96fec1-8954-4155-bf37-cbeedef20572",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot3 = ax.imshow(ccd4, cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3ac62-a2b7-4bdf-a0cb-837ba477e503",
   "metadata": {},
   "source": [
    "Ahora se ve la imagen con mucho mas detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b77586-bab3-417f-9663-0e508364107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot4 = ax.imshow(ccd4[2200:2800,1000:1500], cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80edf9-5ec6-46a0-922d-6d99e46e9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot5 = ax.imshow(ccd4[2600:2700,1300:1400], cmap='gray', origin='lower', norm=norm,)\n",
    "fig.colorbar(plot5)\n",
    "ax.hlines(y=80, xmin=0, xmax=99, linewidth=1, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e9dfd-7841-4725-8be1-5ca52f525db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot5 = ax.plot(ccd4[2658,1300:1400], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37940b-db00-4e63-81a1-51b5a4c10aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
